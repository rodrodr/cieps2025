[
  {
    "objectID": "AT00_preprocesa.html",
    "href": "AT00_preprocesa.html",
    "title": "Preprocesamiento de textos",
    "section": "",
    "text": "Una vez tengamos los archivos descargados y guardados en la nube o en una carpeta en el disco duro de nuestro ordenador, podemos ir un paso m√°s all√° para abrirlos en R, extraer informaci√≥n y limpiarlos si resulta necesario. En esta secci√≥n, veremos c√≥mo abrir archivos con distintos formatos (txt, PDF, docx entre otros) y extraer texto de PDFs sin tratar y limpiar los archivos antes de pasar a la siguiente fase de organizaci√≥n de los corpora.\nEste peque√±o apartado tiene tres secciones. La primera abre archivos de texto en R que ser√°n luego empleados para la creaci√≥n de un todo coherente, relativamente comparable, que se someter√° al an√°lisis (corpus). La segunda realiza un OCR en archivos en formato PDF para, luego, extraer el texto. Finalmente, la tercera utiliza un conjunto de funciones de para la limpieza y b√∫squeda sistem√°tica de texto, as√≠ como introduce las expresiones regulares."
  },
  {
    "objectID": "AT00_preprocesa.html#introducci√≥n",
    "href": "AT00_preprocesa.html#introducci√≥n",
    "title": "Preprocesamiento de textos",
    "section": "",
    "text": "Una vez tengamos los archivos descargados y guardados en la nube o en una carpeta en el disco duro de nuestro ordenador, podemos ir un paso m√°s all√° para abrirlos en R, extraer informaci√≥n y limpiarlos si resulta necesario. En esta secci√≥n, veremos c√≥mo abrir archivos con distintos formatos (txt, PDF, docx entre otros) y extraer texto de PDFs sin tratar y limpiar los archivos antes de pasar a la siguiente fase de organizaci√≥n de los corpora.\nEste peque√±o apartado tiene tres secciones. La primera abre archivos de texto en R que ser√°n luego empleados para la creaci√≥n de un todo coherente, relativamente comparable, que se someter√° al an√°lisis (corpus). La segunda realiza un OCR en archivos en formato PDF para, luego, extraer el texto. Finalmente, la tercera utiliza un conjunto de funciones de para la limpieza y b√∫squeda sistem√°tica de texto, as√≠ como introduce las expresiones regulares."
  },
  {
    "objectID": "AT00_preprocesa.html#abrir-archivos-de-textos",
    "href": "AT00_preprocesa.html#abrir-archivos-de-textos",
    "title": "Preprocesamiento de textos",
    "section": "Abrir archivos de textos",
    "text": "Abrir archivos de textos\nEl primer paso de cualquier an√°lisis de texto consiste en abrir los textos en el R para su posterior procesamiento y an√°lisis. Afortunadamente, existe una serie de opciones que facilitan mucho la apertura de una cantidad grande de textos de un solo golpe, sin la necesidad de ir de uno en uno.\nLa funci√≥n readtext() del paquete hom√≥nimo lee desde archivos de textos a PDFs, documentos de Word y otros formatos como planillas de Excel o json. No solo lee un archivo de cada vez, sino todav√≠a mejor. Basta con suministrar el camino hasta la carpeta y la funci√≥n trata de importar todos los archivos ah√≠ contenidos de un golpe.\nEn la secci√≥n sobre web scraping hemos bajado el texto completo de m√°s de 800 libros en espa√±ol disponibles en los servidores del Proyecto Gutenberg. Los hemos guardado todos en la carpeta ‚ÄúGut_txt/Archivos/‚Äù. Ahora podemos abrirlos de una vez en R utilizando la funci√≥n readtext(). Veamos c√≥mo se hace:\n\n\nCode\n# Abre el paquete readtext\nlibrary(readtext)\nlibrary(reactable)\n\nli &lt;- c(\"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/Ficcion/Cervantes-Quijote.txt\",\n        \"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/Ficcion/Anonimo-Lazarillo_de_Tormes.txt\",\n        \"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/Ficcion/Pirandello-Seis_Personajes.txt\",\n        \"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/Ficcion/Sarmiento-Argentina.txt\",\n        \"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/Ficcion/Sarmiento-Facundo.txt\")\n\n# Abre todos los archivos\ngt &lt;- readtext(li)\n\n# Visualiza\nreactable(gt, wrap=F, resizable = T)\n\n\n\n\n\n\n\n\nEl mismo procedimiento se puede llevar a cabo con archivos PDF que ya han sido sometidos a un OCR o desde un primer momento son digitales. Como vemos abajo, el c√≥digo es exactamente el mismo. Lo √∫nico que cambia es la direcci√≥n de la carpeta, que en esta ocasi√≥n contiene solamente archivos PDF:\n\n\nCode\n# Carga los paquetes\nlibrary(readtext)\nlibrary(reactable)\n\n# Extrae los textos de todos los archivos en la carpeta\ngt &lt;- readtext(\"../Carpeta/PDFs/\")\n\n# Visualiza los 10 primeros\nreactable(gt[1:10,], wrap=F, resizable = T)\n\n\n\nComo en el caso anterior, el R genera un data.frame con dos variables: doc_id, conteniendo el nombre del archivo, y text con el texto completo. Este nuevo objeto ser√° utilizado luego para la creaci√≥n de objeto de tipo corpus en la tercera parte de esta secci√≥n."
  },
  {
    "objectID": "AT00_preprocesa.html#ocr-y-extracci√≥n-de-texto",
    "href": "AT00_preprocesa.html#ocr-y-extracci√≥n-de-texto",
    "title": "Preprocesamiento de textos",
    "section": "OCR y extracci√≥n de texto",
    "text": "OCR y extracci√≥n de texto\nSin embargo, el mundo ser√≠a un lugar m√°s aburrido si las cosas siempre fueran tan sencillas. En muchos casos, nos encontraremos con archivos PDF escaneados con una resoluci√≥n baja y sin reconocimiento de caracteres. En estos casos, nos vemos forzados a procesar los archivos antes de poder llevar a cabo cualquier an√°lisis.\nEn R, el paquete tesseract permite realizar el reconocimiento √≥ptico de caracteres (OCR, en su acr√≥nimo original en ingl√©s) en m√∫ltiples archivos y en distintas lenguas. Combinado con el paquete pdftools, permiten extraer el texto desde fuentes dif√≠ciles de tratar.\nUtilizaremos los mismos PDFs para realizar el OCR y luego extraer los textos. El an√°lisis se dividir√° en dos partes. En la primera, generaremos una lista de los archivos a ser procesados y descargaremos el modelo de OCR para espa√±ol.\n\n\nCode\n# Carga los paquetes\nlibrary(tesseract)\nlibrary(pdftools)\n\n# Genera la lista de todos los PDFs\nfl &lt;- list.files(\"../Carpeta/PDFs/\")\n\n# Baja el modelo para realizar el \n# OCR en espaniol (solo una vez)\ntesseract_download(\"spa\")\n\n# Establece el espaniol como \n# lengua para el OCR\nesp &lt;- tesseract(\"spa\")\n\n\nEn la segunda parte, utilizaremos un bucle for para ir de archivo en archivo, realizar el OCR, extraer el texto y guardarlo en un nuevo formato (.txt) en una nueva carpeta.\n\n\nCode\n# Para cada PDF\nfor (i in 1:length(fl)){\n  \n  # Informa el avace\n  print(paste0(i, \" of \", length(fl)))\n  \n  # Extrae el nombre del archivo\n  ls &lt;- unlist(strsplit(fl[i],\"/\"))\n  ls &lt;- gsub(\".pdf\",\"\", ls)\n  ls &lt;- ls[length(ls)]\n  \n  # Realiza el OCR\n  text &lt;- tesseract::ocr(\n    paste0(\"../Carpeta/PDFs/\",fl[i]), \n    engine = esp)\n  \n  # Guarda el resultado en formato texto \n  write(text, paste0(\"../Carpeta/PDFs/OCR_txt/\",ls,\".txt\"))\n  \n}\n\n\nAhora podemos averiguar los resultados obtenidos por medio de la funci√≥n readtext() utilizando el mismo c√≥digo que hemos visto antes:\n\n\nCode\n# Carga los paquetes\nlibrary(readtext)\nlibrary(reactable)\n\n# Extrae los textos de todos los archivos en la carpeta\ngt &lt;- readtext(\"../Carpeta/PDFs/OCR_txt/\")\n\n# Visualiza los 10 primeros\nreactable(gt[1:10,], wrap=F, resizable = T)"
  },
  {
    "objectID": "AT00_preprocesa.html#manipulaci√≥n-y-limpieza-de-textos",
    "href": "AT00_preprocesa.html#manipulaci√≥n-y-limpieza-de-textos",
    "title": "Preprocesamiento de textos",
    "section": "Manipulaci√≥n y limpieza de textos",
    "text": "Manipulaci√≥n y limpieza de textos\nLa limpieza de los datos resulta fundamental para obtener un an√°lisis adecuado de los textos. Se trata de un proceso laborioso, pero muy importante para la obtenci√≥n de datos comparables. A√∫na un conjunto de tareas concretas de manipulaci√≥n que incluye: remover espacios en blanco, tildes, saltos de l√≠nea innecesarios o la extracci√≥n de datos o metadatos.\nLo que veremos aqu√≠ es un conjunto de t√©cnicas que se pueden adaptar a textos de distinta estructura y naturaleza. No existe una soluci√≥n universal de tratamiento de datos que funcione igual para tweets o para textos legales. En el caso de los primeros, habr√° que tratar los elementos no textuales o los ‚Äúemojis‚Äù antes de analizar el contenido. En los segundos, suele haber mucho ruido por la repetici√≥n de los encabezados de p√°gina por su publicaci√≥n en archivos PDF.\nAdem√°s, cada estructura nos brindar√° oportunidades distintas de extracci√≥n y an√°lisis de los datos. Por ejemplo, textos legales suelen ser muy estructurados y contienen la identificaci√≥n de actores, t√≠tulos, cap√≠tulos, etc. Podemos utilizar tales informaciones como ‚Äúmarcadores‚Äù o ‚Äúetiquetas‚Äù a la hora de extraer datos de forma sistem√°tica. Por esa raz√≥n, resulta muy √∫til empezar por la sencilla tarea de explorar y describir cu√°l es la estructura del texto. ¬øSe trata de un texto uniforme o segmentado (divisiones de cap√≠tulos, partes, t√≠tulos, art√≠culos o cualquier otra)? ¬øEl texto tiene un formato digital desde el principio o tenemos que tratar encabezados u otros elementos comunes en PDFs y documentos Word? ¬øEl texto abre con todas las letras legibles o aparecen s√≠mblos raros en las tildes? O sea, ¬øest√° en la codificaci√≥n de caracteres adecuada o tengo que abrirlo utilizando una codificaci√≥n espec√≠fica (‚ÄúLATIN1‚Äù es la m√°s com√∫n para los que trabajamos textos en espa√±ol)? La funci√≥n stri_enc_list() del paquete stringi proporciona un listado completo de las codificaciones.\nEn esta parte del laboratorio, veremos algunas t√©cnicas de manipulaci√≥n de textos que permiten prepararlos para el an√°lisis. Dividiremos el contenido en tres secciones. La primera examina las funciones de manipulaci√≥n de texto de R y de los paquetes stringr y stringi. La segunda introduce brevemente las expresiones regulares, que representan un recurso muy √∫til para la identificaci√≥n de patrones en textos. Finalmente, la tercera aplica el contenido de las dos anteriores en los textos que empleamos de ejemplo: los libros en espa√±ol del Proyecto Gutenmberg y los decretos presidenciales de Paraguay.\n\nCuenta, busca, extrae, divide, combina, sustituye, compara\nExiste un n√∫mero amplio de funciones en R para la manipulaci√≥n de texto. Podemos hacer casi cualquier operaci√≥n desde buscar expresiones concretas hasta combinar textos o transformarlos en otras estructuras. Aqu√≠ exploraremos algunas tareas b√°sicas muy √∫tiles para trabajar con textos en R.\n\nCuenta\nUna tarea de an√°lisis de texto consiste en contar las veces que determinados temas, contenidos o conceptos aparecen. Esto se puede hacer utilizando ciertas palabras o diccionarios que ayudan a definir el peso de un t√≥pico en el conjunto de elementos de un texto.\nPor ejemplo, ¬øcu√°ntas veces aparecen palabras que empiezan con ‚Äúdemo‚Äù en una variable? La funci√≥n stri_count() del paquete stringi retorna el n√∫mero de texto que un patr√≥n cualquiera (en nuestro caso ‚Äúdemo‚Äù) aparece en un texto o en una variable.\n\n\nCode\n# Crea una variable de texto\ntx &lt;- \"La democracia es la forma de gobierno originada a partir del demos, o pueblo.\"\n\n# Carga el paquete stringr\nlibrary(stringi)\n\n# Cuenta las palabras que contienen \"demo\"\nstri_count(tx, regex = \"demo\")\n\n\n[1] 2\n\n\nCode\n# Ahora con una variable\ntx &lt;- c(\"democracia\",\"demostenes democr√°tico\",\"nada\",\"demora\")\n\n# Cuenta las palabras que contienen \"demo\"\n# para cada elemento\nstri_count(tx, regex = \"demo\")\n\n\n[1] 1 2 0 1\n\n\nComo vemos, en el primer caso, el R nos ha retornado las dos veces en las que alguna palabra conteniendo ‚Äúdemo‚Äù aparec√≠a en la frase. En el segundo, dos elementos llaman la atenci√≥n. Primero, ya no es el total de veces en general, sino que el n√∫mero se divide por observaci√≥n de la variable. Segundo, debemos tener cuidado con la ra√≠z que utilizamos para evitar ambiguedades y generar falsos positivos. Por ejemplo, demostenes y demora no tienen ninguna relaci√≥n con democracia.\nOtra forma de contar que puede ser √∫til en algunos procesos de manipulaci√≥n de texto. Por ejemplo, los c√≥digos INE de los municipios de Espa√±a incluyen dos caracteres iniciales con el c√≥digo de la provincia y luego tres caracteres con el orden alfab√©tico del municipio. As√≠ que Almer√≠a tiene el c√≥digo ‚Äú04‚Äù y est√° en el 13¬∫ puesto en orden alfab√©tico. No obstante, muchas veces, ciertas agencias informan el c√≥digo como ‚Äú04013‚Äù mientras otras lo informan como ‚Äú4013‚Äù. Sin tratamiento, esto resulta un problema a la hora de comparar los datos.\nLa funci√≥n stri_length() del paquete stringi soluciona el problema al contar cu√°ntos caracteres hay en cada observaci√≥n de una variable de texto. A partir de ese dato, podemos identificar cu√°les elementos debemos tratar. En el ejemplo abajo a√±adimos un 0 al texto solo para aquellos c√≥digos que son menores de 5 caracteres. De ese modo, uniformizamos el sistema de acuerdo con el est√°ndar definido por el INE:\n\n\nCode\n# Crea una variable con los c√≥digos INE para los municipios de\n# Almer√≠a, Barcelona, Madrid, Salamanca y Zamora\ntx &lt;- c(\"4013\",\"8019\",\"28079\",\"37274\",\"49275\")\n\n# Carga el paquete\nlibrary(stringi)\n\n# Cuenta los caracteres\nstri_length(tx)\n\n\n[1] 4 4 5 5 5\n\n\nCode\n# Incluye un cero en el codigo del municipio\ntx[stri_length(tx)&lt;5] &lt;- paste0(\"0\", tx[stri_length(tx)&lt;5]) \n\n# Inspecciona los resultados\ntx\n\n\n[1] \"04013\" \"08019\" \"28079\" \"37274\" \"49275\"\n\n\n\n\nBusca\nEn otras ocasiones, lo que deseamos es saber cu√°les elementos del texto contienen ciertas ideas o palabras-clave que buscamos. En ese caso, se trata de identificar o si dichas expresiones se encuentran o no en el texto o, al reves, aquellos textos que contienen la palabra.\nPor ejemplo, ¬øcu√°les elementos de una variable contienen la palabra ministerio o ministro? La funci√≥n stri_detect() del paquete stringi lleva a cabo dicha tarea.\n\n\nCode\n# Crea una variable con distinto contenido\ntx &lt;- c(\"ministro de telecomunicaciones\",\n        \"secretaria adjunto de la presidencia\", \n        \"ministerio de agricultura\", \n        \"director de la polic√≠a nacional\",\n        \"ministerio de seguridad social\",\n        \"ministra de educaci√≥n\",\n        \"secretar√≠a nacional de derechos humanos\",\n        \"director√≠a de asuntos exteriores\")\n\n# Carga el paquete sgtringi\nlibrary(stringi)\n\n# Detecta cu√°les elementos contienen ministro o ministerio\nstri_detect(tx, regex = \"minist\")\n\n\n[1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE\n\n\nCode\n# Podemos seleccionarlos si queremos\ntx[stri_detect(tx, regex = \"minist\")]\n\n\n[1] \"ministro de telecomunicaciones\" \"ministerio de agricultura\"     \n[3] \"ministerio de seguridad social\" \"ministra de educaci√≥n\"         \n\n\nComo se puede observar, el R retorna los elementos de la variable que contienen el patr√≥n ‚Äúminist‚Äù. En la primera forma es solamente una indicando TRUE o FALSE. En la segunda, hemos pedido que nos regrese el texto completo de cada observaci√≥n.\nEjercicio: Pod√©is ejercitar el nuevo conocimiento intentando buscar ‚Äúsecretario‚Äù o ‚Äúsecretar√≠a‚Äù y ‚Äúdirector‚Äù o ‚Äúdiretor√≠a‚Äù.\n\n\nExtrae\nEn otras ocasiones, queremos extraer los patrones para, por ejemplo, contar el n√∫mero de veces que ocurren. En el siguiente ejemplo, extraeremos del discurso de investidura de Pedro S√°nchez todas las palabras empezadas por igual (igualdad, igualitario, etc.) y por libert (libertad, libertades). Esto es posible gracias a la funci√≥n stri_extract_all() del paquete stringi.\n\n\nCode\n# Carga el paquete readtext\nlibrary(readtext)\n\n# Lee el discurso de investidura de Pedro S√°nchez de 2020\ntx &lt;- readtext(\"https://github.com/rodrodr/tenet_texts/raw/refs/heads/main/spa.inaugural/15_XIV_Leg_Sanchez.txt\")\n\n# Carga el paquete stringi\nlibrary(stringi)\n\n# Extrae las palabras con raiz igual\nfr &lt;- unlist(stri_extract_all(tx, regex = \"igual[a-z]+\"))\n\n# Cuenta la frecuencia\ntable(fr)\n\n\nfr\n  igualdad igualdades    iguales igualmente \n        26          2          2          1 \n\n\nCode\n# Extrae las palabras con raiz libert\nfr &lt;- unlist(stri_extract_all(tx, regex = \"libert[a-z]+\"))\n\n# Cuenta la frecuencia\ntable(fr)\n\n\nfr\n  libertad libertades \n        15          3 \n\n\nSe ve como hay una frecuencia mayor de palabras relacionadas a la igualdad que a la libertad, aunque estas √∫ltimas tambi√©n est√©n presentes en una proporci√≥n no muy inferior.\n\n\nDivide\nOtra tarea de manipulaci√≥n de textos consiste en dividirlos seg√∫n diferentes criterios que requieren cada an√°lisis. Por ejemplo, una tarea muy com√∫n consiste en fragmentar los textos en palabras, algo que se denomina tokenization. Hay dos funciones en el paquete stringi que nos permiten dividir un texto: stri_split(), que utiliza un patr√≥n para dividirlo y stri_split_fixed() que limita el n√∫mero de fragmentos. Veamos un ejemplo:\n\n\nCode\n# Crea una variable de texto\ntx &lt;- \"Pepi, Luci, Bom y otras chicas del mont√≥n.\"\n\n# Carga el paquete stringr\nlibrary(stringi)\n\n# Separa utilizando la coma\nstri_split(tx, regex =\",\")\n\n\n[[1]]\n[1] \"Pepi\"                            \" Luci\"                          \n[3] \" Bom y otras chicas del mont√≥n.\"\n\n\nCode\n# Separa utilizando la coma, pero en solo dos fragmentos\nstri_split_fixed(str = tx, pattern = \", \", n = 2)\n\n\n[[1]]\n[1] \"Pepi\"                                \n[2] \"Luci, Bom y otras chicas del mont√≥n.\"\n\n\nCode\n# Un poco m√°s avanzado - separa utilizando tanto la coma\n# como la y\nstri_split(tx, regex =\"[,y]\")\n\n\n[[1]]\n[1] \"Pepi\"                      \" Luci\"                    \n[3] \" Bom \"                     \" otras chicas del mont√≥n.\"\n\n\n\n\nCombina\nEn algunas ocasiones, necesitamos combinar distintos textos para trabajar con t√©rminos compuestos, bigramas o cualquier otra finalidad. El c√≥digo abajo nos ense√±a c√≥mo hacerlo utilizando la funci√≥n stri_join() del paquete stringi.\n\n\nCode\n# Crea una variable de cantidades\nval &lt;- c(1, 2, 3, 4)\n\n# Crea una variable de texto\ntx &lt;- c(\"coche\", \"bicicletas\", \"hijos\", \"libros\")\n\n# Carga el paquete stringr\nlibrary(stringi)\n\n# Combina los dos textos \nstri_join(val, tx, sep=\" \", collapse=\", \")\n\n\n[1] \"1 coche, 2 bicicletas, 3 hijos, 4 libros\"\n\n\n\n\nSustituye\nLa sustituci√≥n resulta muy √∫til para trabajar textos cuando se require el reemplazo de un valor por otro. Imaginemos que eres profesor y tienes una clase de 130 estudiantes. Como eres atento, les enviar√°s un informe con las notas por correo electr√≥nico. Ya tienes un archivo Excel con sus nombres y calificaciones. No obstante, resulta muy trabajoso escribir a cada uno copiando y pegando el mismo texto.\nLa funci√≥n stri_replace, del paquete que ya conoc√©is, permite reemplazar los datos como nombre y nota y facilitar el trabajo de redacci√≥n. Luego, se pueden utilizar otros paquetes como el gmailr para enviar los correos de forma automatizada (este √∫ltimo paso no lo haremos aqu√≠).\n\n\nCode\n# Crea una variable de texto\ntx &lt;- \"EstimadART NOMBRE,\\n\\nEspero que este correo le encuentre bien.\\n\\nComo prometido, env√≠o la calificaci√≥n de la asignatura.\\nSu nota final ha sido NOTA.EMOJI\\n\\nReciba un cordial saludo,\\n\\nRodrigo\\n\\n\"\n\n# Pongamos unos emojis solo para divertirnos.\nemo &lt;- c(\"\\U1F937\",\"\\U1F64C\",\"\\U1F44D\",\"\\U1F947\")\n\n# Crea una lista de nombres\nnm &lt;- c(\"Pepe\", \"Manuel\",\"Mar√≠a\",\"Lola\")\n\n# Lista de notas\nnota &lt;- c(0, 5, 7.5, 8)\n\n# Art√≠culo definido\nart &lt;- c(\"o\",\"o\",\"a\",\"a\")\n\n# Carga el paquete stringr\nlibrary(stringi)\n\n# Reemplaza el nombre\nst &lt;- stri_replace(tx, nm, regex =\"NOMBRE\")\n\n# Reemplaza el art√≠culo definido\nst &lt;- stri_replace(st, art, regex =\"ART\")\n\n# Reemplaza el emoji\nst &lt;- stri_replace(st, emo, regex =\"EMOJI\")\n\n# Ahora reemplaza la nota\nst &lt;- stri_replace(st, nota, regex =\"NOTA\")\n\n# Imprime los resultados\ncat(st)\n\n\nEstimado Pepe,\n\nEspero que este correo le encuentre bien.\n\nComo prometido, env√≠o la calificaci√≥n de la asignatura.\nSu nota final ha sido 0.ü§∑\n\nReciba un cordial saludo,\n\nRodrigo\n\n Estimado Manuel,\n\nEspero que este correo le encuentre bien.\n\nComo prometido, env√≠o la calificaci√≥n de la asignatura.\nSu nota final ha sido 5.üôå\n\nReciba un cordial saludo,\n\nRodrigo\n\n Estimada Mar√≠a,\n\nEspero que este correo le encuentre bien.\n\nComo prometido, env√≠o la calificaci√≥n de la asignatura.\nSu nota final ha sido 7.5.üëç\n\nReciba un cordial saludo,\n\nRodrigo\n\n Estimada Lola,\n\nEspero que este correo le encuentre bien.\n\nComo prometido, env√≠o la calificaci√≥n de la asignatura.\nSu nota final ha sido 8.ü•á\n\nReciba un cordial saludo,\n\nRodrigo\n\n\n\n\nCompara\nOtra tarea muy √∫til consiste en comparar textos y determinar su similitud. Imaginemos que comparamos direcciones, o nombres de personas o entidades en fuentes que pueden contener errores ortogr√°ficos o de digitaci√≥n. En esos casos, resulta fundamental poder medir el grado de similitud o diferencia para tomar una decisi√≥n sobre si se trata de la misma entidad o no.\nEl paquete stringdist posee diversas funciones orientadas a esta finalidad. Que permiten comparar desde dos textos entre s√≠ hasta m√∫ltiple textos entre ellos.\nIlustremos c√≥mo hacerlo utilizando dos textos literarios. En junio de 1580 muere en Lisboa el poeta Luis de Cam√µes. En septiembre de este mismo a√±o, Madrid asiste a la llegada al mundo de otro inmenso escritor, Francisco de Quevedo. Cualquier nativo o hablante fluyente de portugu√©s o espa√±ol no puede dejar de sorprenderse por la similitud entre dos sonetos de ambos autores sobre el amor. Incluso, en algunas estrofas, la redacci√≥n es id√©ntica.\nEl objetivo del c√≥digo abajo resulta comparar ambos sonetos, estrofa por estrofa, y determinar el grado de similitud entre ellas. Nos restringiremos aqu√≠ solamente a algoritmos de similitud que comparan palabras sin atenernos a su funci√≥n sint√°ctica o la carga sem√°ntica que conlleva. Por lo tanto, se trata de un an√°lisis sencillo de la estructura de las estrofas.\n\n\nCode\n# Soneto del amor (Luis de Cam√µes, 1598 - p√≥stumo)\ncam1598 &lt;- c(\"amor es fuego que arde sin verse\",\n            \"es herida que duele y no se siente\",\n            \"es un contentamiento descontento\",\n            \"es dolor que lastima sin doler\",\n            \"es un no querer mas que bien querer\",\n            \"es andar solitario entre la gente\",\n            \"es nunca contentarse de contento\",\n            \"es un cuidar que gana en perderse\",\n            \"es querer estar aprisionado por voluntad\",\n            \"es servir a quien vence, el vencedor\",\n            \"es tener con quien nos mata, lealtad\",\n            \"pero c√≥mo causar puede su favor\",\n            \"en los corazones humanos amistad\",\n            \"si tan contrario a si mismo es el amor\")\n  \n# Soneto del amor (Francisco de Quevedo, 1670 - p√≥stumo)  \nqev1670 &lt;- c(\"es yelo abrasador, es fuego helado\", \n            \"es herida que duele y no se siente\",\n            \"es un so√±ado bien, un mal presente\",\n            \"es un breve descanso muy cansado\",\n            \"es un descuido que nos da cuidado\",\n            \"un cobarde, con nombre de valiente\",\n            \"un andar solitario entre la gente\",\n            \"un amar solamente ser amado\",\n            \"es una libertad encarcelada\",\n            \"que dura hasta el postrero parasismo\",\n            \"enfermedad que crece si es curada\",\n            \"este es el nino amor, este es su abismo\",\n            \"mirad cual amistad tendra con nada\",\n            \"el que en todo es contrario de si mismo\")  \n\n\n# Carga los paquetes stringdist - para calcular la similitud \n# y reshape2 - para cambiar el formato de un data.frame\nlibrary(stringdist)\nlibrary(reshape2)\n\n# Calcula la matriz de similitud entre los dos textos\n# La matriz permitir√° identificar estrofas incluso si\n# se ha cambiado el orden.\nrd &lt;- round(stringsimmatrix(cam1598, \n                            qev1670, \n                            method = \"lcs\"),2)\n\n# Establece los nombres del las lineas como de Cam√µes\n# y el nombre de las columnas como de Quevedo\nrownames(rd) &lt;- cam1598\ncolnames(rd) &lt;- qev1670\n\n# Transforma la matriz en un data.frame\ndrd &lt;- melt(rd)\n\n# Da nombre a las variables\nnames(drd) &lt;- c(\"Camoes\",\"Quevedo\",\"Similitud\")\n\n# Selecciona solamente los resultados cuya \n# similitud resulta superior a 50%.\ndrd &lt;- drd[drd$Similitud&gt;0.5,]\n\n# Ordena las estrofas restantes de la m√°s\n# similar a la menos\ndrd &lt;- drd[order(drd$Similitud, decreasing = T),]\n\n# Inspecciona los resultados\nreactable(data = drd, resizable = T, striped = T)\n\n\n\n\n\n\n\n\nSe puede ver que, al menos cuatro estrofas de las 14 (28,6%) son muy similares. Resulta claro que esos dos textos presentan un fuerte parentesco e indican que Quevedo ha sido lector de Cam√µes. Este mismo m√©todo puede ser aplicado para cualquier otro tipo de texto. El aspecto crucial es la elecci√≥n de la unidad de comparaci√≥n b√°sica. En este ejemplo, la estrofa se emple√≥ como unidad de an√°lisis. En otras fuentes quiz√°s p√°rrafos o cuasi-frases sean las m√°s indicadas. Siempre hay que explorar diferentes posibilidades y m√©todos antes de aplicar un algoritmo a un n√∫mero amplio de casos.\n\n\n\nExpresiones regulares\nLas expresiones regulares son formas de sintaxis que permiten encontrar patrones en textos. Resultan tremendamente √∫tiles a la hora de eliminar espacios en blanco, remover puntuaci√≥n o acentos. Permite, adem√°s, encontrar palabras o n√∫meros seg√∫n patrones concretos. Su uso nos facilita buscar informaci√≥n, eliminar secciones que no nos sirven y evitar errores.\nPor ejemplo, el c√≥digo abajo remueve los dobles espacios en blanco del texto:\n\n\nCode\n# Crea una variable con muchos espacios\ntx &lt;- \"Este    texto      tiene    muchos espacios en      blanco.\"\n\n# Sustituye los m√∫ltiples espacios por solo uno \ngsub(\"\\\\s+\",\" \", tx)\n\n\n[1] \"Este texto tiene muchos espacios en blanco.\"\n\n\nCode\n# Sustituye dos espacios por uno \ngsub(\"\\\\s{2}\",\" \", tx)\n\n\n[1] \"Este  texto   tiene  muchos espacios en   blanco.\"\n\n\nLa funci√≥n gsub() sirve para reemplazar textos en una variable. En el primer ejemplo, la expresi√≥n regular \\\\s+ indica al R que busque cualquier secuencia de texto en la que haya un espacio en blanco o m√°s y la reemplaza por solo un espacio. En la segunda, \\\\s{2} busca dos espacios y los sustituye por uno. Como vemos, los resultados son distintos porque hemos solicitado que R hiciera b√∫squedas diferentes.\nImaginemos que hay una variable de texto y necesitamos encontrar todos los n√∫meros contenidos en ella. La funci√≥n str_extract_all() del paquete stringi permite extraer informaci√≥n de una variable de texto. Si la combinamos con la expresi√≥n regular \\\\d+ (d√≠gitos num√©ricos), el resultado es un conjunto de n√∫meros.\n\n\nCode\n# Crea una variable textos conteniendo n√∫meros\ntx &lt;- c(\"Tengo 10 euros y debo 1000.\",\n        \"De los 18 equipos, sono 1 puede llegar a campe√≥n.\", \n        \"M√°s vale 8 que 80.\")\n\n# Carga el paquete\nlibrary(stringi)\n\n# Extrae los n√∫meros \nstri_extract_all(tx, regex = \"\\\\d+\")\n\n\n[[1]]\n[1] \"10\"   \"1000\"\n\n[[2]]\n[1] \"18\" \"1\" \n\n[[3]]\n[1] \"8\"  \"80\"\n\n\nEn el ejemplo abajo, se utiliza otra expresi√≥n regular [A-Z] (may√∫sculas), luego *[a-z]** (seguida de min√∫sculas) para encontrar y extraer las palabras iniciadas en may√∫sculas en el texto.\n\n\nCode\n# Carga el paquete\nlibrary(stringi)\n\n# Crea un texto de ejemplo\ntx &lt;- \"Aqui pondremos algunos Ministerios, la Presidencia y el presidente.\"\n\n## Extrae del texto expresiones con mayusculas\nstri_extract_all(tx,regex = \"[A-Z][a-z]*\")\n\n\n[[1]]\n[1] \"Aqui\"        \"Ministerios\" \"Presidencia\"\n\n\nTambi√©n se puede dividir un texto utilizando un caracter o palabra. La funci√≥n stri_split() fragmenta una variable de texto a partir de un patr√≥n que puede ser un caracter, como un espacio, una palabra, o un s√≠mbolo, como el de salto de linea.\n\n\nCode\n# Carga el paquete\nlibrary(stringi)\n\n## Define el texto a ser dividido\ntx &lt;- c(\"Esta es la primera frase.\\nEsta es la segunda frase.\")\n\n## Divide utilizando salto de linea\nstri_split(tx, regex = \"\\n\")\n\n\n[[1]]\n[1] \"Esta es la primera frase.\" \"Esta es la segunda frase.\"\n\n\nCode\n## Divide utilizando espacio\nstri_split(tx, regex = \" \")\n\n\n[[1]]\n[1] \"Esta\"         \"es\"           \"la\"           \"primera\"      \"frase.\\nEsta\"\n[6] \"es\"           \"la\"           \"segunda\"      \"frase.\"      \n\n\n¬øYa has intentado comparar los t√©rminos con o sin tildes? Acentuaci√≥n y puntuaci√≥n representan obst√°culos comunes para la comparaci√≥n de textos, especialmente cuando se aplican t√©cnicas como la de bag-of-words. En estos casos, aqu√≠, aqui y aqu√≠. son consideradas palabras distintas. Para ello, hace falta remover la puntuaci√≥n y los acentos para poder compararlas y encontrar su semejanza.\n\n\nCode\n# Carga el paquete\nlibrary(stringi)\n\n## Declara el texto\ntx &lt;- c(\"Jos√©, Mar√≠a y Elena quieren ir a la fiesta de ensue√±o. Pero, ¬øde qu√© fiesta hablas, Pepe?\")\n\n# Elimina la puntuacion\nstri_replace_all(tx, regex = \"[:punct:]\",\"\")\n\n\n[1] \"Jos√© Mar√≠a y Elena quieren ir a la fiesta de ensue√±o Pero de qu√© fiesta hablas Pepe\"\n\n\nCode\n# Elimina todos los acentos\nstri_trans_general(tx, \"Latin-ASCII\")\n\n\n[1] \"Jose, Maria y Elena quieren ir a la fiesta de ensueno. Pero, ?de que fiesta hablas, Pepe?\"\n\n\nEstos ejemplos constituyen una peque√±a introducci√≥n a las expresiones regulares. Hay un mundo de referencias a ser exploradas y hace falta tener siempre a mano un conjunto de chuletas para ayudarnos a buscar patrones de texto dependiendo del tipo de texto que estamos utilizando en cada momento.\nReferencias adicionales\nExiste un enorme material disponible sobre expresiones regulares, os recomiendo los siguientes:\n\nWickam - ‚ÄúStrings‚Äù En R for Data Science\n‚ÄúRegular Expressions‚Äù en la documentaci√≥n del paquete stringr\n‚ÄúRegular Expressions‚Äù en el laboratorio LADAU\nRegular Expressions 101 es una p√°gina obligatoria para aquellos que quieran emplear expresiones regulares.\n\nTambi√©n vale la pena consultar las referencias de los dos paquetes m√°s importantes para la manipulaci√≥n de datos en R, el stringr y el stringi:\n\nstringi: Fast and Portable Character String Processing in R\nstringr"
  },
  {
    "objectID": "AT01_explora_inductivo.html",
    "href": "AT01_explora_inductivo.html",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "",
    "text": "Este tutorial hace parte del libro ‚ÄúAn√°lisis de textos pol√≠ticos con R‚Äù que est√° en fase de desarrollo."
  },
  {
    "objectID": "AT01_explora_inductivo.html#introducci√≥n",
    "href": "AT01_explora_inductivo.html#introducci√≥n",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\nLa Teogon√≠a de Hes√≠odo describe el paso del Caos -el estado de desorden originario- hacia un orden divino por medio de un cat√°logo de nacimientos y creaci√≥n de diferentes dioses y seres mitol√≥gicos. Los fil√≥sofos presocr√°ticos, por otra parte, intentaban explicar el origen del mundo a partir de un principio ordenador fundamental (·ºÄœÅœáŒÆ), una idea clave a partir de la cu√°l se derivaba todo lo dem√°s. En la primera visi√≥n, el mundo se delinea a partir de una serie de eventos sucesivos y caprichos de los dioses en su lucha por protagonismo. No existe un principio claro, sino que tal empresa depende de actos de voluntad, poder y negociaci√≥n entre los participantes. En la segunda, existe una ley inexorable que estructura nuestra realidad y cabe al pensador desvelarla por medio de la raz√≥n.\nEn lo que tange al an√°lisis de textos tambi√©n podemos encontrar dos acercamientos an√°logos. Uno puede adentrar en sus ‚Äúmisterios‚Äù desprove√≠do de nociones anteriores y explorar los patrones y estructuras que puedan emerger sin el auxilio de gu√≠as previos que orienten tal aventura. El otro modo consiste en tener un norte claro desde el principio y emplear nociones e hip√≥tesis como lentes que orientan el examen de los documentos. Al primero lo llamamos inductivo y al segundo deductivo.\nCada una de esas maneras de mirar hacia los textos subraya una forma alternativa de aprender. El m√©todo inductivo conduce a un viaje errante, sin destino cierto, pero plagado de sorpresas y nuevos descubrimientos. El deductivo, por su parte, supone un destino y un rumbo a la vista, permite pocos desv√≠os. Aunque est√© abierto a la serendipia, los principios de partida y los objetivos suelen ser definidos de antemano.\nSe consideran antag√≥nicos solamente bajo sus formas t√≠picas o ideales. En el trabajo de an√°lisis, sin embargo, resulta muy poco frecuente examinar cualquier documento sin nociones previas o al menos cierta intuici√≥n de qu√© se podr√≠a encontrar. Tampoco abundan trabajos que germinan provistos de un cat√°logo meticuloso de los instrumentos adecuados y rutas correctas hacia los objetivos. La ciencia es una labor errante. Conocer a partir de textos es un proceso iterativo, que supone m√∫ltiples acercamientos sucesivos, idas y venidas constantes. La combinaci√≥n de ambos acercamientos, aunque predomine uno de ellos, resulta inevitable.\nEsta parte del trabajo se centra en algunas estrategias inductivas para el an√°lisis de textos. Se ha decidido solamente emplear aqu√≠ m√©todos que no requieran la lectura previa de los textos por dos razones. La primera es did√°ctica y evitar confundir tales m√©todos con otros de car√°cter deductivo. La segunda, igualmente importante, consiste en se√±alar la utilidad del m√©todo inductivo para la generaci√≥n de hip√≥tesis, desarrollo de diccionarios e identificaci√≥n de temas en corpus formados por un elevado n√∫mero de documentos. Se trata de una combinaci√≥n entre una introducci√≥n metodol√≥gica y su aplicaci√≥n pr√°ctica inmediata. Empezaremos con la apertura de los textos, la creaci√≥n de un corpus para luego aplicar distintas t√©cnicas preparatorias que ayudar√°n a viabilizar el an√°lisis."
  },
  {
    "objectID": "AT01_explora_inductivo.html#primeros-pasos",
    "href": "AT01_explora_inductivo.html#primeros-pasos",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "Primeros pasos",
    "text": "Primeros pasos\n\nCreaccion de un corpus\nUna vez los documentos han sido preparados y pre-procesados, pueden ser abiertos en R. La funci√≥n readtext del paquete con el mismo nombre permite importar (o ‚Äúabrir‚Äù) textos individuales o carpetas enteras. Los documentos pueden ser de diferentes formatos: txt, doc(x), pdf, html, csv, tab, tsv, xml, xls(x), json, odt, o rtf. Se trata de una funci√≥n muy √∫til para importar vol√∫menes grandes de texto.\n\n\nCode\n# Obtiene una lista de archivos en\n# una carpeta online de Github\nlibrary(jsonlite)\n\nurl &lt;- \"https://api.github.com/repos/rodrodr/tenet_texts/contents/spa.inaugural\"\n\nnm &lt;- read_json(url)\nnm &lt;- list2DF(nm)\nnm &lt;- sort(as.character(unlist(nm[8,])))\n\n# Carga el paquete\nlibrary(readtext)\n\n# Importa los textos\ntx &lt;- readtext(nm)\n\n# Ordena por nombre de archivo\ntx &lt;- tx[order(tx$doc_id),]\n\n# Visualiza los resultados\nreactable::reactable(tx,\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\n\nComo se puede observar, se cargan 15 discursos de investidura de los Presidentes de gobierno de Espa√±a desde 1979 hasta la actualidad. Se trata de un objeto de tipo data.frame con dos columnas: doc_id, en general el nombre del archivo, y text, que contiene el texto integral. Este formato servir√° de base y resulta obligatorio para la transformaci√≥n de esos textos en un objeto de tipo corpus perteneciente al paquete quanteda, base o infraestructura de la mayor parte de los an√°lisis realizados durante todo el curso.\nAdem√°s de doc_id y text, el data.frame, uno puede a√±adir m√°s variables que ayuden a contextualizar los documentos y suministren informaci√≥n √∫til para el posterior an√°lisis. No obstante, hay que tener claro que la funci√≥n readtext solamente genera las dos primeras variables. Los metadatos adicionales deben ser a√±adidos a posteriori, sea justo despu√©s de la importaci√≥n o, luego, como documentaci√≥n del corpus, como veremos m√°s adelante.\nEl hecho de que utilicemos textos guardados en una carpeta en la nube hace con que el c√≥digo arriba sea un poco m√°s complejo del que ser√≠a necesario. En el caso de que los archivos est√©n en el disco duro bastar√≠a con informar el camino hacia la carpeta:\n\n\nCode\n# Carga el paquete\nlibrary(readtext)\n\n# Importa los textos\ntx &lt;- readtext(\"/Escritorio/Carpeta/\")\n\n# Ordena por nombre de archivo\ntx &lt;- tx[order(tx$doc_id),]\n\n# Visualiza los resultados\nreactable::reactable(tx,\n                     resizable = T, \n                     wrap = F)\n\n\nUna vez abiertos los datos, existen dos opciones. La primera es tratar los datos para extraer metadatos o agregar/fragmentar los textos en otras unidades de observaci√≥n (como los tweets de un mismo partido, o fragmentar un libro por cap√≠tulos). La segunda consiste en transformar el data.frame en un objeto corpus y seguir con el an√°lisis:\n\n\nCode\n# Carga el paquete quanteda\nlibrary(quanteda)\n\n# Transforma los textos en corpus\ncp &lt;- corpus(tx)\n\n# Visualiza los resultados\nreactable::reactable(summary(cp),\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\n\nAl explorar el objeto corpus por medio de la funci√≥n summary(cp), vemos un conjunto de variables descriptivas: Text, nombre del documento; Types, se√±ala el n√∫mero de palabras y s√≠mbolos √∫nicos en el documento; Tokens, n√∫mero total de palabras y s√≠mbolos; y Sentences, cantidad de frases en el texto.\n\n\nAdicionar metadatos\nEl siguiente paso consiste en adicionar m√°s informaci√≥n contextual (metadatos) sobre los textos. Tales informaciones resultar√°n de mucha utilidad en las siguientes etapas de an√°lisis, puesto que permitir√°n agregar las informaciones seg√∫n distintas caracter√≠sticas. Por ejemplo, podemos decidir agrupar los textos seg√∫n presidente (y no gesti√≥n o legislatura). Tambi√©n podr√≠amos organizar el an√°lisis seg√∫n partido del presidente o por su ideolog√≠a.\nCuanto mayor la documentaci√≥n de los textos, mayores las posibilidades de reagrupar, fragmentar o reordenar los textos seg√∫n distintas categor√≠as anal√≠ticas. Adem√°s, se posibilitan distintas comparaciones entre grupos y entre √©stos con el patr√≥n general.\nLa funci√≥n docvars posibilita crear nuevas variables contextuales o de metadatos en un corpus. Su sintaxe resulta muy sencilla:\ndocvars(corpus,‚Äúvariable name‚Äù ) &lt;- variable con el contenido.\n\n\nCode\ndocvars(cp, \"Presidente\") &lt;- c(\"Adolfo Su√°rez\",\n                               \"Leopoldo Calvo Sotelo\",\n                               \"Felipe Gonz√°lez\",\n                               \"Felipe Gonz√°lez\",\n                               \"Felipe Gonz√°lez\",\n                               \"Felipe Gonz√°lez\",\n                               \"Jos√© Mar√≠a Aznar\",\n                               \"Jos√© Mar√≠a Aznar\",\n                               \"Jos√© Luis Zapatero\",\n                               \"Jos√© Luis Zapatero\",\n                               \"Mariano Rajoy\",\n                               \"Mariano Rajoy\",\n                               \"Mariano Rajoy\",\n                               \"Pedro S√°nchez\",\n                               \"Pedro S√°nchez\")\n\ndocvars(cp, \"Nombramiento\") &lt;- c(\"1979-03-31\",\n                                 \"1981-02-26\",\n                                 \"1982-12-02\",\n                                 \"1986-06-23\",\n                                 \"1989-12-05\",\n                                 \"1993-07-09\",\n                                 \"1996-05-04\",\n                                 \"2000-04-26\",\n                                 \"2004-04-17\",\n                                 \"2008-04-11\",\n                                 \"2011-12-20\",\n                                 \"2015-12-21\",\n                                 \"2016-10-30\",\n                                 \"2018-06-01\",\n                                 \"2020-01-07\")\n\n\ndocvars(cp, \"Cese\") &lt;- c(\"1981-02-26\",\n                         \"1982-12-02\",\n                         \"1986-06-23\",\n                         \"1989-10-30\",\n                         \"1993-06-07\",\n                         \"1996-03-04\",\n                         \"2000-03-13\",\n                         \"2004-03-15\",\n                         \"2008-03-10\",\n                         \"2011-11-21\",\n                         \"2015-12-21\",\n                         \"2016-10-29\",\n                         \"2018-06-01\",\n                         \"2019-04-29\",\n                         NA)\n\n\ndocvars(cp, \"Partido\") &lt;- c(\"UCD\", \"UCD\", \"PSOE\", \n                            \"PSOE\", \"PSOE\",\"PSOE\",\"PP\",\n                            \"PP\",\"PSOE\",\"PSOE\",\n                            \"PP\",\"PP\",\"PP\",\n                            \"PSOE\",\"PSOE\")\n\n\n\ndocvars(cp, \"Ideolog√≠a\") &lt;- c(\"Derecha\", \"Derecha\", \"Izquierda\", \n                            \"Izquierda\", \"Izquierda\",\"Izquierda\",\n                            \"Derecha\", \"Derecha\", \"Izquierda\",\n                            \"Izquierda\", \"Derecha\", \"Derecha\", \n                            \"Derecha\", \"Izquierda\", \"Izquierda\")\n\n\n# Visualiza los resultados\nreactable::reactable(summary(cp),\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\nComo se puede observar en la tabla arriba, se han a√±adido las variables con el nombre del presidente, fecha de nombramiento, cese, el partido pol√≠tico al que pertenec√≠a y la ideolog√≠a de la mayor parte de los miembros de los partidos. Estas categor√≠as permitir√°n separar en la fase de an√°lisis diferentes perfiles de grupo como, por ejemplo, los conceptos o expresiones m√°s utilizados por l√≠deres de derecha e izquierda o por cada partido.\n\n\nTransformar un corpus\nOtra opci√≥n consiste en reorganizar el texto seg√∫n nuevas unidades de an√°lisis. A veces, algunos aspectos del discurso se desvelan de modo m√°s claro cuando las informaci√≥n se organiza desde una perspectiva distinta. Esa pseudo-alteridad se puede alcanzar a veces por mirar a un mismo texto desde otro √°ngulo. ¬øQu√© cambios se pueden observar en la importancia de los conceptos cuando organizamos los textos seg√∫n partido o ideolog√≠a y no m√°s de acuerdo con cada una de las legislaturas? ¬øAparece algo nuevo? ¬øExisten contradicciones o patrones distintos frente a lo que hab√≠amos percibido en el an√°lisis anterior?\nSe pueden adoptar dos estrategias fundamentales. La primera consiste en fragmentar los textos en unidades menores como p√°rrafos o sentencias, por ejemplo. La segunda trata de agregar los textos a partir de caracter√≠sticas comunes, como juntar todos los documentos de una misma ideolog√≠a. Adem√°s, se pueden combinar entre s√≠. Podemos juntar todos los textos por partido y luego fragmentarlos por frase. De cualquier forma, el cambio en la unidad de observaci√≥n debe tener un prop√≥sito anal√≠tico claro. ¬øQu√© se quiere aprender al estructurar los textos de una manera determinada?\nEmpecemos con la fragmentaci√≥n. Utilicemos el corpus de discursos de inauguraci√≥n de los presidentes de gobierno espa√±oles y dividamos el corpus por p√°rrafo. Esto se puede hacer con la funci√≥n corpus_reshape de quanteda.\n\n\nCode\n# Reorganiza el corpus segun frases\ncs &lt;- corpus_reshape(x = cp, to = \"sentences\")\n\n# Visualiza los 100 primeros resultados\nreactable::reactable(summary(cs),\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\n\nPara agregar los textos, hay que dar un paso atr√°s y aunar los textos de un mismo grupo en un √∫nico documento. Para ello, podemos convertir el corpus documentado en un objeto de tipo data.frame y, luego, agregar los textos y volver a crear un corpus con la nueva unidad de observaci√≥n. Utilizaremos ahora los presidentes como unidad.\n\n\nCode\n# Convierte el corpus documentado en un data.frame\ntd &lt;- convert(cp, to=\"data.frame\")\n\n# Unifica los textos en un solo documento a partir\n# de las funciones aggregate (que agrega por grupos)\n# y paste0, que colapsa textos.\n# Hemos decidido utilizar dos separadores de linea (\\n\\n)\n# para indicar la separacion entre un texto y otro\ntd &lt;- aggregate(list(text=td$text), by=list(Presidente=td$Presidente,\n                                      Partido=td$Partido,\n                                      Ideologia=td$Ideolog√≠a),\n                                paste0,\n                                collapse=\"\\n\\n\")\n\n# vuelve a crear un corpus con el nuevo\n# objeto agregado\ncx &lt;- corpus(td)\n\n# Visualiza los 100 primeros resultados\nreactable::reactable(summary(cx),\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\n\nAhora mismo tenemos solamente siete documentos en el corpus. Corresponden a la nueva unidad de agregaci√≥n: Presidente. Con dichas informaciones, la comparaci√≥n se hace entre estilos discursivos de los l√≠deres, m√°s que un per√≠odo sobre otro. Har√≠amos lo mismo para los partidos o la ideolog√≠a. Incluso podr√≠amos utilizar un corpus para cada unidad y comparar los resultados."
  },
  {
    "objectID": "AT01_explora_inductivo.html#el-arte-de-contar-palabras",
    "href": "AT01_explora_inductivo.html#el-arte-de-contar-palabras",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "El arte de contar palabras",
    "text": "El arte de contar palabras\nUna vez terminada la preparaci√≥n del corpus, toca empezar el an√°lisis. El modo m√°s sencillo consiste en identificar qu√© palabras, conceptos o t√©rminos aparecen con mayor frecuencia y averiguar si hay diferencias sustantivas en su uso entre los documentos del corpus. Se trata de un m√©todo de an√°lisis aplicable tanto a conjuntos peque√±os de textos, que pueden ser le√≠dos con antelaci√≥n por el investigador, como a grandes repositorios imposibles de leer sin un proceso previo de an√°lisis, clasificaci√≥n y muestreo.\nEn esta parte del trabajo trataremos de cuatro temas relacionados con el recuento directo de palabras. El primero abarca las t√©cnicas de preparaci√≥n y c√°lculo de frecuencias de palabras, tanto para el corpus como un todo como para cada documento o grupo en particular. El segundo repite las operaciones, pero en lugar de palabras completas, se emplear√°n sus ra√≠ces (stemming). El tercero describe la ponderaci√≥n de las frecuencias por su ocurrencia en todos los documentos. El cuarto se dedica a visualizaciones, como las nubes de palabras.\n\nFrecuencia de palabras\nEl primer paso para contar palabras o expresiones consiste en tokenizar el corpus y, a continuaci√≥n, crear una matriz documento-atributo (dfm, en su acr√≥nimo en ingl√©s). Se trata de un procedimiento sencillo que fragmenta cada texto en palabras, n-gramas (conjunto de n-palabras que aparecen juntas como en el bigrama ‚Äúeconom√≠a pol√≠tica‚Äù, por ejemplo) o incluso frases.\n\n\nCode\n# Crea un objeto de tipo tokens por palabra\ntk &lt;- tokens(cp)\n\n# Crea un objeto dfm\nfm &lt;- dfm(tk)\n\n# Buscamos las 10 palabras m√°s frecuentes\ntopfeatures(fm)\n\n\n   de     ,    la     .     y   que    en    el     a   los \n11069 10122  7334  5247  5183  5026  4537  4097  3222  2974 \n\n\nComo podemos ver, no aprendemos nada de la pol√≠tica espa√±ola mirando hacia los 10 t√©rminos m√°s frecuentes. Todos son conectores o puntuaci√≥n que se repiten sistem√°ticamente en cualquier texto. Probablemente, ‚Äúde‚Äù, ‚Äúque‚Äù, ‚Äúy‚Äù, ‚Äúla‚Äù, as√≠ como la coma o el punto y aparte ser√°n las palabras y los s√≠mbolos m√°s comunes en cualquier texto escrito en espa√±ol. Tales palablas se conocen como stop words o ‚Äúpalabras vac√≠as‚Äù de contenido que suelen ser muy frecuentes en cualquier idioma. Para evitar que ellas supongan un problema, lo mejor es quitarlas del medio y recrear la matriz de frecuencias.\n\n\nCode\n# Crea un objeto de tipo tokens por palabra eliminando la punctuacion\ntk &lt;- tokens(cp, remove_punct = T)\n\n# Elimina las stopwords\ntk &lt;- tokens_remove(tk, stopwords(language = \"es\"))\n\n# Crea un objeto dfm\nfm &lt;- dfm(tk)\n\n# Buscamos las 10 palabras m√°s frecuentes\ntopfeatures(fm)\n\n\n gobierno    espa√±a  pol√≠tica  se√±or√≠as    social      pa√≠s  sociedad espa√±oles \n      721       590       483       464       317       289       288       263 \n   empleo   sistema \n      256       253 \n\n\nAhora el panorama ha cambiado. Aparecen nuevos t√©rminos, como ‚Äúgobierno‚Äù, ‚ÄúEspa√±a‚Äù, ‚Äúespa√±oles‚Äù, ‚Äúpol√≠tica‚Äù, ‚Äúsocial‚Äù, ‚Äúsociedad‚Äù, ‚Äúempleo‚Äù o ‚Äúsistema‚Äù. Tambi√©n palabras espec√≠ficas de tratamiento formal en los discursos inaugurales o en intervenciones parlamentarias, como es el caso de ‚Äúse√±or√≠as‚Äù.\nUno puede visualizar la frecuencia de palabras en un corpus por medio de una nube de palabras. Aunque sea un recurso m√°s est√©tico que informativo, sirve para tener una idea somera e inicial del peso relativo de los t√©rminos en un corpus o documento espec√≠fico. El c√≥digo abajo utiliza la funci√≥n wordcloud del paquete hom√≥nimo para generar el gr√°fico:\n\n\nCode\nlibrary(quanteda.textplots)\nlibrary(tenet)\nlibrary(wordcloud)\n\nft &lt;-topfeatures(fm, 50)\n\npar(mar=rep(0,4))\nwordcloud(names(ft), \n          freq = ft, \n          colors = pal$cat.cartocolor.antique.11)\n\n\n\n\n\nAbajo, buscamos las 25 palabras m√°s comunes, calculamos su frecuencia relativa y, adem√°s, creamos dos gr√°ficos para representarlas. Utilizamos la funci√≥n dfm_weight para obtener el peso relativo de los t√©rminos en el corpus. Esta √∫ltima medida ponderada resulta especialmente importante: (a) cuando comparamos su peso en cada uno de los textos y (b) cuando la extensi√≥n de los documentos resulta muy distinta.\n\n\nCode\n# Buscamos las 25 palabras m√°s frecuentes\nft &lt;- topfeatures(fm, n = 25)\n\n# A√±adimos la frecuencia relativa \nfp &lt;- dfm_weight(fm, \"prop\")\n\n# Repite la b√∫squeda para la frecuencia relativa\nfr &lt;- topfeatures(fp, n = 25)\n\n# Convierte los resultados en un data.frame\nxx &lt;- data.frame(Palabra=names(ft), Frec.Abs=ft, Frec.Rel=fr)\n\n# Carga el paquete ggplot2\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\n# Genera un gr√°fico de barras para visualizar la frecuencia de las palabras\np1 &lt;- ggplot(xx, aes(x=Frec.Abs, y=reorder(Palabra, Frec.Abs)))+\n  geom_bar(stat=\"identity\", fill=\"darkgreen\")+\n  theme_classic()+\n  labs(title=\"Frecuencia ABSOLUTA\")+\n  ylab(\"\")+\n  xlab(\"Frecuencia Absoluta\")\n\np2 &lt;- ggplot(xx, aes(x=Frec.Rel, y=reorder(Palabra, Frec.Rel)))+\n  geom_bar(stat=\"identity\", fill=\"orange\")+\n  theme_classic()+\n  labs(title=\"Frecuencia RELATIVA\")+\n  ylab(\"\")+\n  xlab(\"Frecuencia Relativa\")\n\n# La funci√≥n grid.arrange permite posicionar varios gr√°ficos lado a lado o uno en cima del otro\ngrid.arrange(p1,p2, ncol=2)\n\n\n\n\n\nEl pr√≥ximo paso ser√≠a calcular las frecuencias seg√∫n un grupo o atributo del corpus, como el presidente, por ejemplo. El c√≥digo abajo utiliza las funciones dfm_group para generar una matriz de frecuencia y dfm_weight para ponderar las palabras y obtener los valores relativos.\n\n\nCode\n# Crea un objeto dfm\nfg &lt;- dfm_group(fm, groups = quanteda::docvars(cp, \"Presidente\"))\n\n\n# Buscamos las 25 palabras m√°s frecuentes para cada presidente\nft &lt;- topfeatures(fg, n = 25, \n                  groups = quanteda::docvars(fg, \"Presidente\"))\n\n# Genera una frecuencia relativa\nfgw &lt;- dfm_weight(fg, scheme=\"prop\")\n\nftg &lt;- topfeatures(fgw, n = 25, \n                  groups = quanteda::docvars(fg, \"Presidente\"))\n\n# Crea una base de datos a partir de esas informaciones\nnm &lt;- names(ft)\nxx &lt;- data.frame()\nfor(i in 1:length(nm)){\n  xx &lt;- rbind(xx, data.frame(\n                          Presidente=nm[i], \n                          Palabras=names(ft[[i]]), \n                          Freq=as.numeric(ft[[i]]),\n                          Freq.Rel=round(as.numeric(ftg[[i]]),3)))\n}\n\n# Visualiza\nlibrary(htmltools)\n\n# Render a bar chart with a label on the left\nbar_chart &lt;- function(label, width = \"100%\", height = \"1rem\", fill = \"#00bfc4\", background = NULL) {\n  bar &lt;- div(style = list(background = fill, width = width, height = height))\n  chart &lt;- div(style = list(flexGrow = 1, marginLeft = \"0.5rem\", background = background), bar)\n  div(style = list(display = \"flex\", alignItems = \"center\"), label, chart)\n}\n\nlibrary(reactable)\n\nreactable(\n  xx,\n  filterable = T,\n  columns = list(\n    Presidente=colDef(name=\"Presidente\"),\n    Freq = colDef(name = \"Frecuencia\", align = \"left\", cell = function(value) {\n      width &lt;- paste0(value / max(xx$Freq) * 100, \"%\")\n      bar_chart(value, width = width)\n    }),\n    Freq.Rel = colDef(name = \"Frec. Relativa\", align = \"left\", cell = function(value) {\n      width &lt;- paste0(value / max(xx$Freq.Rel) * 100, \"%\")\n      bar_chart(value, width = width, fill=\"red\")\n    })\n  )\n)\n\n\n\n\n\n\n\nPodemos ver en la tabla resultante que una misma expresi√≥n puede tener pesos distintos en los discursos de diferentes presidentes. Por ejemplo, el t√©rmino pol√≠tica tiene un peso de 0.012 en el discurso de Calvo-Sotelo, pero una incidencia seis veces menor en el de Pedro S√°nchez. Algo parecido sucede con la palabra se√±or√≠as, mucho m√°s com√∫n en los documentos de S√°nchez si comparados con los de Felipe Gonz√°lez.\n\n\nRa√≠ces (stemming)\nNo obstante, muchas de las palabras que aparecen en la tabla comparten una misma ra√≠z como, por ejemplo, Espa√±a, espa√±oles, espa√±olas o econ√≥mico, econ√≥mica o econ√≥micas. Contarlas de forma separada, en realidad, puede fragmentar o ocultar un patr√≥n o un tema m√°s relevante bajo un sinf√≠n de peque√±as variantes de un mismo concepto.\nEn esos casos, una t√©cnica muy √∫til es la conversi√≥n de las palabras a sus ra√≠ces (stemming). Este procedimiento sencillo permite justamente evitar que matices entre t√©rminos impidan la identificaci√≥n de un patr√≥n claro dentro del corpus o en algunos de sus textos componentes.\nLa funci√≥n dfm_wordstem extrae la raiz de los t√©rminos de una matriz de frecuencia. Su empleo es muy sencillo, sin embargo, se debe establecer la lengua adecuada de los textos del corpus para que la transformaci√≥n funcione. La funci√≥n establece el ingl√©s por defecto. En nuestro ejemplo, definiremos el par√°metro language como ‚Äúes‚Äù para definir que se trata de espa√±ol.\n\n\nCode\n# Convierte las palabras a sus raices\nfw &lt;- dfm_wordstem(fm, language = \"es\")\n\n# Buscamos las 25 palabras m√°s frecuentes\ntopfeatures(fw, n = 25)\n\n\n    polit   gobiern     se√±or     espa√±    econom    social   espa√±ol       deb \n      769       725       638       591       566       498       491       444 \n     pais    public       hac     mejor      nuev     comun      part desarroll \n      427       403       401       356       355       344       341       308 \n     pued     emple    socied  ciudadan     mayor    reform   autonom    sistem \n      300       290       288       286       285       280       278       276 \n    objet \n      264 \n\n\nLos resultados reducen la variedad, pol√≠tico, pol√≠tica, pol√≠ticas se transforman en polit. Gobierno, gobierna, gobiernan en gobiern. Sin embargo, los resultados pueden mejorar. Espa√±a est√° de un lado como espa√±, mientras que espa√±ol, espa√±oles y espa√±olas se reducen a espa√±ol. Sin embargo, el investigador siempre puede utilizar esos resultados como punto de partida y, en seguida, agregar o corregir lo que crea necesario.\n\n\nN-gramas\nEn varias ocasiones conviene explorar la combinaci√≥n de palabras en b√∫squeda de expresiones comunes o recurrente. Algunos ejemplos claros en la pol√≠tica son ‚Äúseguridad social‚Äù, ‚Äúfuerzas armadas‚Äù, ‚Äúpol√≠ticas p√∫blicas‚Äù, ‚Äúseguridad ciudadana‚Äù, ‚Äúpartido pol√≠tico‚Äù, entre otras. Para ello, utilizamos n-gramas, que son secuencias de n-palabras seguidas. Se llaman as√≠ porque pueden ser dos (bigramas), tres (trigramas) o m√°s t√©rminos sucesivos.\nEn R, se trata de fransformar los tokens en n-gramas utilizando la funci√≥n tokens_ngrams y, a continuaci√≥n, calcular las frecuencias:\n\n\nCode\n# Convierte los tokens en bigramas\ntn &lt;- tokens_ngrams(tk, n=2)\n\n# Crea una matriz de frecuencia\nfk &lt;- dfm(tn)\n\n# Extrae los 25 mas comunes\ntopfeatures(fk, 25)\n\n\n    comunidades_aut√≥nomas             uni√≥n_europea         pol√≠tica_exterior \n                       95                        67                        61 \n          se√±oras_se√±ores               punto_vista         se√±ores_diputados \n                       51                        51                        49 \n        sociedad_espa√±ola        pol√≠tica_econ√≥mica               cuatro_a√±os \n                       48                        45                        43 \n            pr√≥ximos_a√±os          seguridad_social                  cada_vez \n                       41                        41                        40 \n         confianza_c√°mara           creaci√≥n_empleo          se√±or_presidente \n                       40                        40                        39 \n          acci√≥n_gobierno         fuerzas_pol√≠ticas              primer_lugar \n                       38                        38                        36 \nadministraciones_p√∫blicas                  debe_ser     formaci√≥n_profesional \n                       36                        34                        34 \n               si_obtengo              √∫ltimos_a√±os              mismo_tiempo \n                       34                        34                        31 \n        econom√≠a_espa√±ola \n                       30 \n\n\nVarios bigramas interesantes saltan a la vista: comunidades aut√≥nomas, uni√≥n europea, pol√≠tica exterior, pol√≠tica econ√≥mica, seguridad social, creaci√≥n empleo, entre otros. Tambi√©n aparecen f√≥rmulas ret√≥ricas como se√±oras se√±ores, si obtengo, confianza c√°mara, por ejemplo.\nPodemos repetir el mismo procedimiento, pero ahora utilizando tres palabras en lugar de dos para ver qu√© resultados obtenemos. Este juego de ir subiendo el n√∫mero de palabras en la expresi√≥n puede seguir indefinidamente hasta que no aporte ning√∫n dato nuevo o interesante.\n\n\nCode\n# Convierte los tokens en trigramas\ntn &lt;- tokens_ngrams(tk, n=3)\n\n# Crea una matriz de frecuencia\nfk &lt;- dfm(tn)\n\n# Extrae los 25 mas comunes\ntopfeatures(fk, 25)\n\n\n          se√±oras_se√±ores_diputados                si_obtengo_confianza \n                                 48                                  23 \n           obtengo_confianza_c√°mara                pr√≥ximos_cuatro_a√±os \n                                 18                                  17 \n            producto_interior_bruto         comunidad_econ√≥mica_europea \n                                 17                                  15 \n          sistema_p√∫blico_pensiones            se√±or_presidente_se√±oras \n                                 13                                  12 \n         presidente_se√±oras_se√±ores    legislatura_discurso_investidura \n                                 12                                  11 \n          solicito_confianza_c√°mara                 √∫ltimos_cuatro_a√±os \n                                 11                                  11 \n                   idea_espa√±a_pa√≠s            art√≠culo_99_constituci√≥n \n                                 11                                  10 \n            todas_fuerzas_pol√≠ticas           fuerzas_cuerpos_seguridad \n                                  9                                   9 \n           creaci√≥n_puestos_trabajo              si_obtengo_investidura \n                                  9                                   9 \n           espa√±a_necesita_gobierno            sistema_seguridad_social \n                                  9                                   8 \n                gobierno_si_obtengo              sistema_nacional_salud \n                                  8                                   8 \n         se√±ora_presidenta_se√±or√≠as comunidades_aut√≥nomas_ayuntamientos \n                                  8                                   7 \n    todas_administraciones_p√∫blicas \n                                  7 \n\n\nLa obtenci√≥n de la confianza del parlamento aparece en m√°s de una vez. El art√≠culo 99 de la Constituci√≥n espa√±ola (que rije el proceso de voto de confianza en el Presidente) resulta la novedad m√°s clara en ese apartado. No obstante, otros t√©rminos relacionados a las pol√≠ticas p√∫blicas -como producto interior bruto, sistema p√∫blico pensiones, fuerzas cuerpos seguridad- o a la organizaci√≥n administrativa del Estado -comunidades aut√≥nomas ayuntamientos o todas administraciones p√∫blicas- tambi√©n se destacan.\nSi llegamos a aumentar el n a 5, por ejemplo, aparece el I+D+I. En resumen, se trata de un recurso exploratorio bastante interesante para determinar qu√© expresiones compuestas o frases aparecen de forma repetitiva en los textos y que puedan incitar nuevas perspectivas sobre el contenido de los mismos.\n\n\nTF-IDF\nOtro m√©todo de selecci√≥n de t√©rminos relevantes es llamado Term Frequency-Inverse Document Frequency (TF-IDF). La f√≥rmula es intuitiva y premia aquellos casos que aparecen con mucha frecuencia, pero en relativamente pocos documentos, al mismo tiempo que penaliza los que est√°n por todas partes:\n\\[tf/idf = freq_{td} * log(\\frac{D}{d_t}) \\]\nDonde:\nfreqtd es la frecuencia absoluta (o relativa) del t√©rmino t en el cada documento d.\nD corresponde al n√∫mero total de documentos.\ndt representa el n√∫mero de documentos que contienen el t√©rmino t.\nImaginemos un corpus con 10 documentos y dos palabras ‚Äúla‚Äù y ‚Äúpobreza‚Äù, ambas con una frecuencia de 20. La √∫nica diferencia es que ‚Äúla‚Äù aparece en todos los 10 documentos con una frecuencia de 2 en cada uno, mientras que ‚Äúpobreza‚Äù se menciona en solamente dos textos, uno 14 veces y otro 6. Al calcular el tf-idf para cada una, tenemos los siguientes resultados:\n\nPara cada uno de los documentos de ‚Äúla‚Äù: 2*log(10/10) = 0\nPara el primer documento de ‚Äúpobreza‚Äù: 14*log(10/2) = 22,5\nPara el segundo documento de ‚Äúpobreza‚Äù: 6*log(10/2) = 9,7\n\nAl final, se observa que el peso de ‚Äúla‚Äù se anula completamente (tf-idf = 0) tanto por la dispersi√≥n de la frecuencia total como por su aparici√≥n en muchos documentos. Lo inverso ocurre con ‚Äúpobreza‚Äù, que tiene su frecuencia concentrada en dos textos y con mayor preponderancia en uno en concreto (un tf-idf total de 22,5 + 9,7 = 32,2).\nEn l√≠neas generales permite identificar aquellas palabras que aparecen mucho, pero que no tanto para reducir su poder informativo. Por ejemplo, ‚Äúla‚Äù, ‚Äúde‚Äù, ‚Äúel‚Äù o ‚Äúser‚Äù, ‚Äúhacer‚Äù aparecen un n√∫mero elevado de veces. Esta medida permite ponderar su peso por un factor que penaliza el hecho de aparezcan mucho en todos los documentos. El resultado son indicadores m√°s elevados para conceptos que se destacan sin ser preponderantes o muy comunes en todos los elementos del corpus.\n\n\nCode\n# Convierte las palabras a sus raices\nfw &lt;- dfm_tfidf(fm)\n\n# Buscamos las 25 palabras m√°s frecuentes\ntopfeatures(fw, n = 25)\n\n\n     digital consiguiente  progresista      ustedes    coalici√≥n        vista \n    18.94303     18.70318     17.79497     17.11142     16.69924     16.65308 \n       vamos           ss        euros       g√©nero            `      ejemplo \n    15.89324     15.26788     14.72378     14.31364     14.11310     13.92790 \n      se√±ora   presidenta   transici√≥n  l√≥gicamente        pacto  comunitaria \n    13.77675     13.77675     12.73408     12.05466     11.79811     11.48063 \n   ecol√≥gica         digo         acta      pobreza         idea   revoluci√≥n \n    11.37580     11.18352     11.18352     10.97379     10.92005     10.90659 \n        2030 \n    10.50074 \n\n\nVemos que otros t√©rminos aparecen: digital, progresista, coalici√≥n, euros, g√©nero, transici√≥n, pacto, comunitaria, ecol√≥gica, pobreza y 2030. Tales t√©rminos sugieren contenido program√°tico de la pol√≠tica y despiertan mayor inter√©s que el lenguaje m√°s formal que hemos visto hasta ahora. Por otra parte, verbos y expresiones muy peculiares de cada presidente, como el vamos de Pedro S√°nchez o el consiguiente de Felipe Gonz√°lez, saltan a la vista. Tales ejemplos evidenc√≠an c√≥mo la medida tf-idf puede ayudar a singularizar el discurso de un presidente o de un partido pol√≠tico tanto por el contenido pol√≠tico que por las f√≥rmulas ling√º√≠sticas empleadas para dirigirse a los miembros del Poder Legislativo. Adem√°s, como en los ejemplos anteriores, se pueden detallar los resultados por grupo (Presidente, partido, ideolog√≠a, entre otras variables de contexto disponibles).\n\n\nKeyness\nEl keyness es otro m√©todo que compara la distribuci√≥n desigual de t√©rminos entre textos. A partir de un texto de referencia, utiliza m√©todos estad√≠sticos como el chi-cuadrado o la likelihood ratio para determinar cu√°les palabras se acercan m√°s a un documento y las que menos. A partir de esas informaciones podemos encontrar elementos √∫tiles para caracterizar un discurso concreto.\nla funci√≥n textstat_keyness del paquete quanteda.textstats permite calcular el keyness de los t√©rminos de un corpus con relaci√≥n a un documento de referencia concreto. Utilicemos, por ejemplo, los discursos de Pedro S√°nchez como referencia:\n\n\nCode\n# Nueva matriz de fecuencia\npfm &lt;- dfm(tk)\n\n# Atribuimos el nombre del presidente como grupo\npfm &lt;- dfm_group(pfm, groups = quanteda::docvars(pfm, \"Presidente\"))\n\n# Calcula el keyness\nkn &lt;- textstat_keyness(pfm, target = \"Pedro S√°nchez\")\n\n# Visualiza los resultados en una tabla\nreactable(kn, \n          columns = list(\n                    chi2=colDef(\n                            format=colFormat(\n                            digits=2)),\n                    p=colDef(\n                            format=colFormat(\n                            digits=2))))\n\n\n\n\n\n\n\nVemos que las palabras que m√°s se asocian al discurso de S√°nchez son vamos, se√±or√≠as, progresista, digital, avanzar y g√©nero. Las que menos son pol√≠tica, econ√≥mica, esfuerzo, ciudadanos, proceso, exterior y cooperaci√≥n. Podemos tambi√©n compararlas visualmente utilizando la funci√≥n textplot_keyness del paquete quanteda.textplots. En el gr√°fico abajo, se seleccionan las 20 palabras que m√°s y menos caracterizan los textos de Pedro S√°nchez.\n\n\nCode\nlibrary(quanteda.textplots)\n\ntextplot_keyness(kn, color = c(\"red3\",\"blue\"))\n\n\n\n\n\nComo se trata de un gr√°fico basado en la arquitectura ggplot2, se pueden a√±adir elementos como t√≠tulos, temas, nuevos colores y otros elementos visuales.\n\n\nRatio de probabilidades\nEl ratio de probabilidades representa otra forma de visualizar la importancia de determinadas palabras para un texto concreto en el corpus. Este m√©todo compara la frecuencia relativa de una palabra en un texto con su incidencia en todos los documentos. Una odds ratio nos informa la especificidad de cada palabra comparando un texto (o conjunto de textos) frente a los dem√°s. Como suelen existir casos extremos (frecuencias o ratio muy elevadas), se emplean el logaritmo de las ratios para representar los valores. Los valores resultantes pueden ser tanto positivos como negativos. Un valor positivo indica que la palabra es m√°s frecuente en el texto de referencia que en el resto del corpus. Un valor negativo indica justo lo contrario.\nPor ejemplo, en el gr√°fico abajo comparamos los discursos de Pedro S√°nchez con los dem√°s presidentes de gobierno espa√±oles. Vemos que las palabras que m√°s se asocian a S√°nchez son vamos, se√±or√≠as, progresista, digital, avanzar y g√©nero. Las que menos son pol√≠tica, econ√≥mica, esfuerzo, ciudadanos, proceso, exterior y cooperaci√≥n.\n\n\nCode\ncp &lt;- corpus(spa.inaugural)\n\nci &lt;- corpus_group(cp, groups = President)\n\nplotKeyness(corpus = ci, \n            type = \"log\",\n            ref.cat = \"S√°nchez\")                \n\n\n\n\n\n\n\n\n\nLa estructura del gr√°fico sigue el mismo formato de un diagrama de dispersi√≥n tradicional con dos variables continuas. En el eje horizontal (x) se representa el logaritmo de la frecuencia de las palabras. En el vertical (y), el logaritmo de la odds ratio. Las palabras que m√°s se asocian al discurso de S√°nchez son las que se encuentran m√°s a la arriba del gr√°fico. Las que menos, m√°s abajo. Por otra parte, los t√©rminos situados m√°s a la izquierda son menos frecuentes que los de la derecha. El tama√±o de los puntos representa la frecuencia de las palabras en el corpus."
  },
  {
    "objectID": "AT01_explora_inductivo.html#asociaci√≥n-entre-palabras",
    "href": "AT01_explora_inductivo.html#asociaci√≥n-entre-palabras",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "Asociaci√≥n entre palabras",
    "text": "Asociaci√≥n entre palabras\n\nCo-localizaciones\nUn m√©todo para el an√°lisis de los v√≠nculos entre t√©rminos es la co-localizaci√≥n. La funci√≥n textstat_collocations del paquete quanteda.textstats utiliza un modelo log-linear para comparar la incidencia de un grupo de palabras y definir su grado de asociaci√≥n. El coeficiente lambda (\\(\\lambda\\)) representa dicha estimaci√≥n.\nLa co-localizaci√≥n define el grado de asociaci√≥n de otra palabra cerca. As√≠ se puede precedir qu√© palabra viene despu√©s a partir del conjunto que viene antes.\n\n\nCode\n# Genera una lista de 2 palabras que aparecen en secuencia\ncc &lt;- textstat_collocations(tk, size = 2)\n\nreactable(cc, \n          resizable=T, \n          rownames = F, \n          columns = list(\n                        lambda=colDef(format=colFormat(digits=2)),\n                        z=colDef(format=colFormat(digits = 2))))\n\n\n\n\n\n\n\n\n\nCorrelaci√≥n\nLa correlaci√≥n corresponde a un m√©todo cl√°sico de medir la asociaci√≥n entre dos variables. Cuando se trata de la correlaci√≥n entre t√©rminos podemos utilizar diferentes algoritmos. Silge y Robinson (2017), por ejemplo, emplean el coeficiente phi (\\(\\phi\\)) de Yule, un m√©todo de asociaci√≥n a partir de la coincidencia binaria (1/0, S√≠/No) entre palabras en un mismo documento. Como el rho (\\(\\rho\\)) de Pearson, posee un intervalo entre -1 y 1 y se interpreta del mismo modo.\nEsta medida puede resultar √∫til para textos cortos, como tweets o un corpus organizado seg√∫n sentencias. En esos casos, importa menos la cantidad de las palabras que el hecho de que ambas aparezcan en un mismo documento. Se valora la coincidencia de dos conceptos o ideas y tiene poco sentido evaluar su intensidad. La probabilidad de encontrar una palabra con frecuencia superior a 1 en una misma frase u oraci√≥n es peque√±a.\nNo obstante, ese razonamiento tambi√©n revela la principal limitaci√≥n del coeficiente phi. Al tratarse de un test binario, no lleva en cuenta diferencias cuantitativas que pueden observarse en documentos m√°s extensos como libros, cap√≠tulos, entrevistas, leyes, manifiestos o discursos. En estos casos, se requieren m√©todos m√°s precisos que, adem√°s de la presencia o ausencia de los t√©rminos, ponderen la intensidad de asociaci√≥n seg√∫n su frecuencia o rango.\nLa correlaci√≥n de orden de rango (rank-order correlation) o rho (\\(\\rho\\)) de Spearman resulta m√°s indicada para esos casos. Se trata de una medida que ordena los documentos seg√∫n el rango de frecuencia de cada palabra en concreto y compara el grado de similitud o diferencia entre los rangos. La f√≥rmula es la siguiente:\n\\[S\\rho = 1-\\frac{6 \\sum R(X_i)-R(Yi)}{n(n^2-1)}\\]\nDonde:\n\nR(Xi) indica el rango (ranking) de Xi en los valores de X.\nR(Yi) indica el rango (ranking) de Yi en los valores de Y.\nn corresponde al n√∫mero de observaciones. En nuestro caso, indica el n√∫mero de documentos en el corpus.\n\n\nImportantePuesto que la distribuci√≥n de las frecuencias de palabras no es normal, no se recomienda el empleo del rho (\\(\\rho\\)) de Pearson para avaliar su asociaci√≥n. Tampoco resulta indicable el c√°lculo de la correlaci√≥n para un corpus con un n√∫mero muy reducido de documentos (menos de 10, por ejemplo). En tales escenarios, quiz√°s ser√≠a mejor reestructurar el corpus seg√∫n unidades menores -como sentencias o p√°rrafos, por ejemplo- y emplear el phi (\\(\\phi\\)) como alternativa.\n\n\nEl c√≥digo abajo crea una lista con nodos correspondientes a las palabras del corpus y v√≠nculos que expresan la intensidad de su asociaci√≥n y un sociograma representando la asociaci√≥n entre las palabras. Por defecto, el m√©todo empleado es el rho de Spearman.\n\n\nCode\n# Carga el paquete tenet\nlibrary(tenet)\n\n# Crea una lista de correlaciones\nll &lt;- corTerms(cp, \n               min.freq = 100, \n               n.terms = 100)\n\n# Genera el sociograma\ncorNet(ll)\n\n\n\n\n\nCuanto m√°s grandes los puntos, mayor la frecuencia de la palabra en el corpus. El grosor del v√≠nculo revela la intensidad de asociaci√≥n y el color su direcci√≥n. En el ejemplo arriba, correlaciones negativas se representan en rojo y positivas en azul. De ese modo, vemos que pa√≠ses y compromiso se relacionan de forma negativa. Fuerzas y social presentan una correlaci√≥n positiva."
  },
  {
    "objectID": "AT01_explora_inductivo.html#consideraciones-finales",
    "href": "AT01_explora_inductivo.html#consideraciones-finales",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "Consideraciones finales",
    "text": "Consideraciones finales\nEn este documento hemos visto c√≥mo abrir los textos en R y trabajar con distintas t√©cnicas de an√°lisis exploratorio. Nos hemos concentrado en m√©todos inductivos, sin una lectura anterior y profunda que orientara el an√°lisis. Los ejemplos se han concentrado fundamentalmente en entender qu√© t√©rminos ocurren con mayor frecuencia y c√≥mo se asocian entre ellos.\nEste tipo de an√°lisis dista mucho de ser m√≠nimamente aceptable dentro de una perspectiva cualitativista pura. Contar palabras constituye una aproximaci√≥n somera al an√°lisis de textos. No obstante, no tiene el prop√≥sito de reemplazar nada. Su utilidad reside en suministrar recursos y una primera aproximaci√≥n a t√©cnicas m√°s profundas y sofisticadas. Los t√©rminos encontrados aqu√≠ sirven para la creaci√≥n de diccionarios y la codificaci√≥n tem√°tica. Tambi√©n ayudan a desvelar patrones no completamente observables desde una perspectiva cualitativa. Adem√°s, su poder reside en permitir extraer patrones de amplios vol√∫menes de texto, imposibles de leer uno a uno.\nEn la pr√≥xima sesi√≥n utilizaremos t√©cnicas deductivas y otros m√©todos exploratorios para profundizar en el conocimiento de los textos. Trataremos de la codificaci√≥n tem√°tica, la selecci√≥n de textos seg√∫n t√©rminos o atributos para un an√°lisis m√°s detallado y la creaci√≥n de diccionarios como base para tareas de clasificaci√≥n y descubierta."
  },
  {
    "objectID": "AT01_explora_inductivo.html#ejercicios",
    "href": "AT01_explora_inductivo.html#ejercicios",
    "title": "Primeros pasos en el an√°lisis de textos",
    "section": "Ejercicios",
    "text": "Ejercicios\nEjercicio 1. Utilice el data.frame cis.corrupt del paquete tenet para crear un nuevo corpus. Realice el an√°lisis del nuevo corpus utilizando la funci√≥n summary. Guarde el resultado de summary en un data.frame llamado d.\n\n\nSoluci√≥n\n# Carga los paquetes tenet y quanteda\nlibrary(tenet)\nlibrary(quanteda)\n\n# Convierte cis.corrupt en un corpus\ncx &lt;- corpus(cis.corrupt)\n\n# Resume los resultados\nd &lt;- summary(cx, n = nrow(cis.corrupt))\n\n\nEjercicio 2. A√±ada una variable de documentaci√≥n (docvars) al corpus reci√©n creado con la densidad o la diversidad l√©xica de cada texto dividiendo el n√∫mero de types por tokens y multiplicando por 100. Formalmente, este t√©rmino se denomina Type-Token Ratio (TTR). Tambi√©n a√±ada otras dos variables a la documentaci√≥n del corpus: (a) el n√∫mero de palabras por sentencia y (b) el n√∫mero de types por sentencia.\n\n\nSoluci√≥n\n# Calcula el TTR\nd$TTR &lt;- round((d$Types/d$Tokens)*100,1)\n\n# Calcula el n√∫mero de palabras por frase\nd$tokens_sentence &lt;- round(d$Tokens/d$Sentences,1)\n\n# Calcula el n√∫mero de tipos por frase\nd$types_sentence &lt;- round(d$Types/d$Sentences,1)\n\n# A√±ade las tres variables como documentaci√≥n del corpus\ndocvars(cx,\"TTR\") &lt;- d$TTR\ndocvars(cx,\"tokens_sentence\") &lt;- d$tokens_sentence\ndocvars(cx,\"types_sentence\") &lt;- d$types_sentence\n\n\nEjercicio 3. Divida el corpus en tokens bajo la forma de palabras. Excluyas puntuaci√≥n, s√≠mbolos y palabras vac√≠as (stop words). Cree un nuevo objeto con bi-gramas en lugar de solo palabras como tokens. Finalmente, genere una nueva lista de t√©rminos, pero ahora con solamente las ra√≠ces.\n\n\nSoluci√≥n\n# Crea los tokens removiento puntuaci√≥n y s√≠mbolos\ntk &lt;- tokens(cx,\n             remove_punct = T,\n             remove_symbols = T)\n\n# Elimina los stop words\ntk &lt;- tokens_remove(tk, \n                    stopwords(\"es\"))\n\n# Convierte en bi-gramas\ntb &lt;- tokens_ngrams(tk, 2)\n\n# Convierte en ra√≠ces\ntr &lt;- tokens_wordstem(tk, language = \"es\")\n\n\nEjercicio 4. Crea dos matrices de frecuencia: (a) una con las palabras y (b) otra con sus ra√≠ces. Selecciona las 30 palabras m√°s frecuentes en cada una de ellas.\n\n\nSoluci√≥n\n# Crea la matriz de frecuencia para las palabras\nfm &lt;- dfm(tk, tolower = T)\n\n# Crea la matriz de frecuencia para las ra√≠ces\nfr &lt;- dfm(tr, tolower = T)\n\n# Selecciona las 30 palabras m√°s frecuentes\ntopfeatures(fm, 30)\n\n# Selecciona las 30 ra√≠ces m√°s frecuentes\ntopfeatures(fr, 30)\n\n\nEjercicio 5. Crea una matriz de frecuencia para cada grupo demogr√°fico (variable ‚ÄúGrupo.Demografico‚Äù en docvars) y selecciona las 10 palabras m√°s comunes para cada uno de ellos.\n\n\nSoluci√≥n\n# Agrupa la matriz por grupo demogr√°fico\nfg &lt;- dfm_group(fm, groups = docvars(cx, \"Grupo.Demografico\"))\n\n# Selecciona los 10 m√°s frecuentes\ntopfeatures(fg, groups = docvars(fg, \"Grupo.Demografico\"))\n\n\nEjercicio 6. Ahora, utilice la matriz agrupada del ejercicio 5, calcule los TF-IDF de cada palabra y seleccione las 20 palabras m√°s importantes para cada grupo.\n\n\nSoluci√≥n\n# Calcula el TF-IDF\nfi &lt;- dfm_tfidf(fg)\n\n# Selecciona las 20 m√°s frecuentes\ntopfeatures(fi,\n            n = 20,\n            groups = docvars(fg, \"Grupo.Demografico\"))\n\n\nEjercicio 7. Utilice la matriz de frecuencia de los grupos demogr√°ficos para calcular el keyness del corpus (con la funci√≥n textstat_keyness) y crea el gr√°fico utilizando la funci√≥n texplot_keyness. Utilice como referencia el grupo ‚ÄúObreros‚Äù.\n\n\nSoluci√≥n\n# Calcula el keyness\nkn &lt;- textstat_keyness(fg, target = \"Obreros\")\n\n# Carga el paquete\nlibrary(quanteda.textplots)\n\n# Genera el gr√°fico\ntextplot_keyness(kn, color = c(\"red3\",\"blue\"))\n\n\nEjercicio 8. Crea el gr√°fico de correlaciones para el corpus a partir de 100 palabras con frecuencia superior a 50 en el corpus.\n\n\nSoluci√≥n\n# Carga el paquete tenet\nlibrary(tenet)\n\n# Crea una lista de correlaciones\nll &lt;- corTerms(cx,\n               min.freq = 50, \n               n.terms = 100)\n\n# Genera el sociograma\ncorNet(ll)"
  },
  {
    "objectID": "AT02_codifica_escalonado.html#introducci√≥n",
    "href": "AT02_codifica_escalonado.html#introducci√≥n",
    "title": "Codificaci√≥n tem√°tica y escalonado",
    "section": "Introducci√≥n",
    "text": "Introducci√≥n\nEsta secci√≥n se divide en dos partes. La primera trata de c√≥mo codificar tem√°ticamente una cantidad de textos y sacar el m√°ximo provecho de t√©cnicas de an√°lisis textual para encontrar patrones. La segunda trata de emplear t√©cnicas de escalonado de textos para posicionar partidos pol√≠ticos."
  },
  {
    "objectID": "AT02_codifica_escalonado.html#codificaci√≥n-tem√°tica",
    "href": "AT02_codifica_escalonado.html#codificaci√≥n-tem√°tica",
    "title": "Codificaci√≥n tem√°tica y escalonado",
    "section": "Codificaci√≥n tem√°tica",
    "text": "Codificaci√≥n tem√°tica\n\nKeyword in Context (Kwic)\nUna forma sencilla de contextualizar t√©rminos consiste en visualizarlos directamente en los pasajes del texto en que aparecen. El m√©todo kwic (keyword in context) extrae de un texto o corpus todos los trechos en los que aparece una palabra y los muestra dentro de un contexto o ventana que puede ser compuesta por una o m√°s expresiones antecedentes y posteriores. En el ejemplo abajo, buscamos la palabra ‚Äúlibertad‚Äù en los discursos de investidura de los presidentes espa√±oles, con una ventana de 5 palabras alrededor del t√©rmino.\n\n\nCode\n# Carga el paquete tenet\nlibrary(tenet)\n\n# Crea un corpus (discursos inaugurales Espana)\ncp &lt;- corpus(spa.inaugural)\n\n# Crea un data.frame a partir de\n# la funcion Keyword in Context de\n# Quanteda \nd &lt;- kwic(x = tokens(cp),\n          pattern= \"libertad\",\n          window = 5)\n\n# Visualiza los resultados\n reactable::reactable(d,\n                     resizable = T, \n                     wrap = F)\n\n\n\n\n\n\n\n\nComo podemos observar, el uso del t√©rmino libertad var√≠a significativamente seg√∫n el momento y el presidente en cuesti√≥n. Adolfo Su√°rez lo utiliza en un contexto de transici√≥n hacia la democracia, como superaci√≥n de una etapa anterior autoritaria. Por esa raz√≥n, la palabra aparece junto a derechos, instituciones y democracia. Felipe Gonz√°lez la utiliza junto a las ideas de igualdad y solidaridad, mientras que Aznar las asocia a la expresi√≥n, ense√±anza y seguridad. Zapatero introduce el concepto de libertad sexual. Rajoy la asocia a prosperidad e igualdad, mientras que Pedro S√°nchez se centra en dos ejes: valores postmateriales (sexual, aborto, eutanasia) y territorial (autonom√≠a de las comunidades aut√≥nomas).\nPor otra parte, si hacemos un ejercicio y utilizamos el t√©rmino ‚Äúempleo‚Äù, se puede averiguar que este se refiere casi exclusivamente al mundo laboral y pol√≠ticas activas de acceso o creaci√≥n de puestos de trabajo. Solo en dos ocasiones espec√≠ficas se trata del verbo ‚Äúemplear‚Äù con el significado ‚Äúutilizar‚Äù, como las referencias ‚Äúemplear una pol√≠tica monetaria‚Äù o el ‚Äúempleo de los caudales p√∫blicos‚Äù, ambas en el primer discurso de investidura de Felipe Gonz√°lez. Por lo tanto, al examinar los resultados, vemos que esos dos casos constituyen una excepci√≥n al significado principal de empleo a que hacen referencia todos los discursos.\n\n\n√Årbol de palabras\nEl √°rbol de palabras (wordtree) nos brinda una visi√≥n semejante al kwic con una diferencia fundamental: cada palabra que compone la frase se dimensiona de acuerdo con la frecuencia con que aparecen en los textos. Este recurso resulta √∫til para discriminar los usos m√°s comunes de los t√©rminos en sus contextos predominantes. De acuerdo con Wattenberg y Vi√©gas (2008, 2‚Äì3), corresponde a una alternativa gr√°fica y exploratoria de visualizaci√≥n de los kwic. Se trata, adem√°s, de un recurso interactivo que permite al usuario jugar con los contextos, direccionando su mirada hacia frases concretas o subiendo a patrones m√°s generales. Posee tres caracter√≠sticas distintivas. Primero, facilita la identificaci√≥n de repeticiones de palabras. Segundo, tiene una estructura de √°rbol claramente identificable. Finalmente, facilita la exploraci√≥n del contexto.\nPor lo tanto, representa una herramienta que sirve tanto para la exploraci√≥n de patrones en los textos durante una primera fase exploratoria de un estudio como de instrumento de comunicaci√≥n de patrones o temas recurrentes encontrados en los datos. Su interactividad invita tanto a la descubierta como a una mayor atenci√≥n a los argumentos que se desean transmitir.\nEl c√≥digo abajo utiliza la funci√≥n wordtree del paquete tenet para crear el √°rbol de palabras alrededor del t√©rmino libertad. Como podemos ver, el resultado es muy semejante al producido por el kwic. No obstante, ahora nuestra atenci√≥n se ve atra√≠da por las palabras de mayor tama√±o. Las rutas m√°s comunes se evidencian, como es el caso de ‚Äúde la libertad de expresi√≥n‚Äù, por ejemplo.\n\n\nCode\n# Crea un arbol de palabras en tenet\nwordtree(corpus = cp,\n         keyword = \"libertad\",\n         height = 800)\n\n\n\n\n\n\n  \n  \n  \n                   \n                   \n                   \n                   \n                   \n\n\nPor otra parte, si filtramos el corpus para que incluya solamente textos de un presidente o partido pol√≠tico, podemos identificar los usos espec√≠ficos que hacen de los t√©rminos y, as√≠, trazar variantes y revelar patrones √∫tiles te√≥ricamente. Seguramente veremos diferencias sustantivas entre Adolfo Su√°rez y Pedro S√°nchez, como hemos podido contrastar en el apartado anterior. Adem√°s, ser√° posible identificar de forma m√°s sencilla las expresiones m√°s recurrentes o t√≠picas de cada uno. En el caso de Jos√© Mar√≠a Aznar, por ejemplo, la libertad se asocia de forma muy evidente al progreso econ√≥mico.\n\n\nCodificaci√≥n con diccionarios\nEn esta parte del trabajo revisaremos los instrumentos y estrategias disponibles para el desarrollo de temas. Examinaremos diferentes herramientas para determinar el contexto en el que se inscriben, as√≠ como determinaremos la prevalencia de distintas categor√≠as anal√≠ticas. Haremos especial hincapi√© en el concepto de diccionario o l√©xico como el resultado de un proceso de codificaci√≥n tem√°tica y construcci√≥n te√≥rica a partir del an√°lisis abductivo resultante de la consulta e iteraci√≥n constante entre texto (como material emp√≠rico fundamental), teor√≠a e interpretaci√≥n.\nLos diccionarios pueden considerarse como dispositivos de ensamblaje de expresiones de inter√©s te√≥rico o como instrumentos de organizaci√≥n de ideas. Permiten la aglutinaci√≥n de t√©rminos en categor√≠as anal√≠ticas m√°s amplias y su posterior organizaci√≥n en estructuras conceptuales jer√°rquicas. La creaci√≥n de un diccionario representa una t√©cnica de medici√≥n y b√∫squeda en la el uso de palabras y otros elementos textuales permiten identificar la presencia de ciertas ideas o conceptos en un corpus determinado. Tambi√©n se le podr√≠a considerar como un libro de c√≥digos, una compilaci√≥n de categor√≠as y los elementos que le componen. La formalizaci√≥n expl√≠cita de los grupos y su documentaci√≥n facilita el trabajo en grupo y aumenta la transparencia y reproducibilidad de al menos parte del an√°lisis realizado.\nEl ejemplo abajo crea un diccionario que clasifica 39 t√©rminos seg√∫n los c√≥digos ‚Äúeconom√≠a‚Äù, ‚Äúfiscal‚Äù, ‚Äúeducaci√≥n‚Äù, ‚Äúsanidad‚Äù y ‚Äúmedioambiente‚Äù. Luego, lo emplea en conjunci√≥n con la funci√≥n tagText para resaltar las categor√≠as en el discurso de investidura de Adolfo Su√°rez. Al analizar los resultados, vemos que a cada categor√≠a (o c√≥digo) corresponde un color cuyo nombre se revela al mover el cursos sobre una palabra subrayada.\n\n\nCode\n# Crea un diccionario de algunos t√©rminos pol√≠ticos\ndic &lt;- dictionary(\n    list(\n    economica=c(\"econom\",\n               \"inversion\",\n               \"empresa\",\n               \"desarroll\",\n               \"monetari\",\n               \"industri\",\n               \"agric\",\n               \"agrari\"),\n    fiscal=c(\"hacienda\",\n               \"gasto\",\n               \"impuest\",\n               \"presupuest\",\n               \"tribut\",\n               \"tasa\",\n               \"fiscal\"),\n    educacion=c(\"educa\",\n             \"profesor\",\n             \"docent\",\n             \"escuel\",\n             \"colegio\",\n             \"universi\",\n             \"formaci√≥n\"),\n    sanidad=c(\"sanidad\",\n               \"salud\",\n               \"hospital\",\n               \"sanitari\",\n               \"m√©dic\",\n               \"enfermer\",\n               \"salud\"),\n    medioambiente=c(\"sostenible\",\n                 \"cambio clima\",\n                 \"medioambient\",\n                 \"reciclaje\",\n                 \"ecol√≥gico\",\n                 \"l√≠mpia\",\n                 \"invernadero\",\n                 \"emisiones\",\n                 \"carbono\",\n                 \"pl√°stico\",\n                 \"f√≥siles\")))\n\n# genera un texto para ser le√≠do en el panel\n# Viewer de RStudio\ntagText(spa.inaugural$text[1], \n        keywords = dic, \n        palette = pal$cat.cartocolor.prism.11,\n        font.size = 18, \n        title = \"Adolfo Suarez (1979)\",\n        margin = 100)\n\n\n\nEl resultado nos sit√∫a en un espacio entre una b√∫squeda automatizada de t√©rminos y la codificaci√≥n manual. Al aplicar el diccionario a un texto espec√≠fico, se puede observar no solo d√≥nde las categor√≠as aparecen m√°s o menos, sino tambi√©n c√≥mo estas se asocian entre ellas en un mismo p√°rrafo, por ejemplo. Algunos pasajes son monotem√°ticos, inciden sobre una idea clave. Otros interesan por la asociaci√≥n entre conceptos distintos. En muchas ocasiones es justamente la asociaci√≥n entre temas lo que permite el surgimiento de nuevas hip√≥tesis. Adem√°s, el an√°lisis de la incidencia de los c√≥digos en el texto invita a la revisi√≥n del diccionario para incorporar nuevos t√©rminos o categor√≠as y, de ese modo, completar el an√°lisis.\nMiles et al. (2019, 86) sugieren que un m√©todo para utilizar diccionarios como herramientas para la codificaci√≥n consiste en crear una lista provisional de c√≥digos por medio de un proceso deductivo a partir de las referencias te√≥ricas que sirven de marco para el estudio. Una vez elaborada, puede servir de semilla para el examen de los textos y pasar por procesos sucesivos de adaptaci√≥n, refinamiento y elaboraci√≥n con el empleo de una codificaci√≥n inductiva complementaria.\nEste proceso de revisi√≥n constante requiere instrumentos que permitan explorar, ordenar, filtrar y sintetizar la informaci√≥n. La funci√≥n tagCorpus de tenet emplea una tabla interactiva que permite a los usuarios llevar a cabo una serie de tareas de exploraci√≥n de los t√©rminos y c√≥digos de un diccionario en todo un corpus. Por lo tanto, se centra en posibilitar la identificaci√≥n tanto de aspectos compartidos como de se√±as distintivas entre documentos, categor√≠as o actores. Adem√°s, permite examinar de forma sumaria la coocurrencia de c√≥digos en frases o p√°rrafos.\nEl paquete tenet tambi√©n incluye un diccionario de ejemplo llamado dic.pol.es. Se trata de un conjunto de c√≥digos que analizan diferentes dimensiones de los discursos pol√≠ticos. Contiene tres niveles: (1) palabras o expresiones, (2) c√≥digos de primer nivel y (3) c√≥digos de segundo nivel. Por ejemplo, ‚Äúizquierda unida‚Äù pertenece al c√≥digo nivel-1 ‚Äúpartidos‚Äù y al c√≥digo nivel-2 ‚Äúactores‚Äù. Por su parte, ‚Äúilustres‚Äù pertence a ‚Äúret√≥rica‚Äù (nivel-1) y a ‚Äúdiscurso‚Äù (nivel-2).\nEl c√≥digo abajo utiliza la funci√≥n tagCorpus y el diccionario dic.pol.es para identificar la incidencia de las categor√≠as en cada sentencia del corpus de los discursos de investidura espa√±oles. Como se podr√° ver, abajo, el resultado es una tabla con siete columnas. La primera Order corresponde al orden de la frase en el documento X (columna Doc.). De ese modo, Order igual a 1 y Doc. igual a Su√°rez corresponde a la primera frase del discurso de investidura de Adolfo Su√°rez. Paragraph corresponde a la unidad textural, que puede ser el documento completo (documents), p√°rrafos (paragraphs) o oraciones (sentences). Las categor√≠as m√°s frecuentes aparecen en la columna siguiente (Main Category) y todas las categor√≠as encontradas en la columna Paragraph aparecen en All Categories, inclu√≠das, por supuestos, las m√°s frecuentes. Matches informa el n√∫mero de veces una palabra o t√©rmino del diccionario se ha encontrado en el texto. Finalmente, Cat. No. informa el n√∫mero total de categor√≠as encontradas.\nAdicionalmente, debajo del nombre de cada columna, se pueden encontrar campos de filtro. Basta digitar cualquier valor o texto para seleccionar los resultados. Por ejemplo, si uno desea saber c√≥mo Calvo Sotelo trataba temas sociales, puede seleccionar solo los documentos que se inicien por ‚ÄúCalvo‚Äù y que, en All Categories, incluya el c√≥digo ‚Äúsocial‚Äù. Al hacer clic sobre el nombre de cada columna tambi√©n se pueden ordenar los valores de forma ascendente o descendente.\n\n\nCode\n# tagCorpus, hace algo parecido para un corpus\ntagCorpus(cp,\n          defaultPageSize = 4,\n          dic.pol.es, \n          palette = pal$cat.ggthemes.tableau.20, \n          reshape.to = \"sentences\", \n          show.details = T)\n\n\n\n\n\n\n\n\nConsideremos otro ejemplo. Si queremos identificar cu√°les actores sociales y pol√≠ticos mencionados en los discursos de investidura de los presidentes espa√±oles que est√©n vinculados al tema tecnol√≥gico, podemos filtrar las sentencias del corpus en las que el tema principal (Main Category) son los ‚Äúactores‚Äù y en que tambi√©n aparezcan (All Categories) ‚Äútecnologia‚Äù.\nVemos que la concepci√≥n tecnol√≥gica de los presidentes pasa por una actuaci√≥n clave de empresas y del mercado. Poco se menciona sobre el rol de la inversi√≥n en ciencia. Mucho inversor y poco investigador. La innovaci√≥n, por lo tanto, se da por la atracci√≥n de capital y de tecnolog√≠as desarrolladas por otros m√°s que por un proceso aut√≥nomo de construcci√≥n tecnol√≥gica a partir de la inversi√≥n en ciencia. No resulta para nada casual que casi la mitad del presupesto asignado a investigaci√≥n suela estar constituida por cr√©ditos destinados al I+D+I de empresas (en colaboraci√≥n con la universidad).\n\n\nAn√°lisis tem√°tico\n¬øCu√°les c√≥digos tienen m√°s peso? ¬øQu√© categor√≠as se asocian de forma m√°s estrecha? Una vez creados los c√≥digos y los diccionarios, cabe dar un paso adelante y buscar patrones, identificar las caracter√≠sticas de los conjuntos de t√©rminos y sus relaciones con otros atributos en los textos.\nEl an√°lisis de la incidencia de los c√≥digos en un corpus y su interrelaci√≥n permiten explicitar patrones y definir el peso relativo de cada idea en los textos. Este apartado emplea tres estrategias para explorar la importancia de los temas. La primera consiste en averiguar el peso de las categor√≠as, es decir, emplear estad√≠sticas sumarias, como la frecuencia relativa de c√≥digos o expresiones, para establecer su prevalencia. La segunda se basa en la desagregaci√≥n y el filtro para comparar grupos o atributos o para seleccionar aspectos concretos que se desean examinar con m√°s detenimiento. La tercera investiga su asociaci√≥n por medio de las redes de coocurrencia.\nCombinadas, tales estrategias permiten identificar los temas centrales presentes en un texto o corpus y c√≥mo se relacionan entre s√≠. Tambi√©n revelan su variaci√≥n de acuerdo con variables contextuales, como puede ser un partido, el presidente o un per√≠odo de tiempo determinado. Se tratan de herramientas sencillas, pero muy √∫tiles, a la hora de contextualizar ideas e identificar variaciones importantes en el uso de conceptos o t√©rminos.\n\n\nEstad√≠sticas tem√°ticas\nDenominamos estad√≠sticas tem√°ticas el conjunto de t√©cnicas cuantitativas que permiten representar la importancia de categor√≠as o expresiones en un corpus. ¬øCu√°ntas veces los presidentes de gobierno han mencionado la ciencia en sus discursos de investidura? ¬øCu√°ntas han mencionado al terrorismo? ¬øQui√©nes han sido los que m√°s uso han hecho de la expresi√≥n ‚Äúg√©nero‚Äù o ‚Äúfuerzas de seguridad‚Äù?\nPor lo tanto, aunque sencillas, tales herramientas permiten delinear diferencias program√°ticas e ideol√≥gicas entre distintos actores pol√≠ticos. Sobre todo, se√±ala aquellas categor√≠as m√°s frecuentes, tanto por el n√∫mero de veces que aparecen como por la cantidad de documentos en los que aparecen. Por ejemplo, solo algunos de los presidentes mencionan el tema de g√©nero en sus discursos (en especial Jos√© Luis Rodr√≠guez Zapatero y Pedro S√°nchez). No obstante, temas como el mercado laboral o la fiscalidad del Estado, como esperado, aparecen en todos ellos (aunque acompa√±ados de distintos calificativos).\nEl panel abajo contiene un conjunto de recursos para el an√°lisis de los c√≥digos del diccionario dic.pol.es aplicado a los discursos de investidura de los presidentes de gobierno de Espa√±a. La primera pesta√±a (tabla) contiene la frecuencia relativa de los c√≥digos y t√©rminos del diccionario en el corpus. Las dem√°s corresponden a visualizaciones que permiten hacer una s√≠ntesis de los pesos relativos de palabras-clave y categor√≠as en los textos. Force Directed Tree genera un diagrama de √°rbol que representa la jerarqu√≠a de los t√©rminos como una red. Las dos alternativas siguientes (voronoi tree) generan una imagen parecida, pero con otros instrumentos de interacci√≥n y niveles de zoom. Esto permite mirar hacia los resultados de una forma ligeramente distinta.\n\nTablaForce-Directed TreeVoronoi (C√≥digos)Voronoi (keywords)\n\n\nLa funci√≥n countKeywords de tenet produce un data.frame con un conjunto de campos que auxilian en el an√°lisis del peso relativo de cada categor√≠a en un corpus determinado. El primero es groups, que indica el grupo (como partido o presidente, por ejemplo) que detalla los resultados. Si no se ha informado ninguna variable de grupo, aparecer√° ‚ÄúAll‚Äù (todos). El segundo, level1, se√±ala el c√≥digo de m√°s alto nivel en un diccionario (la funci√≥n admite hasta dos niveles de jerarqu√≠a, en esos casos aparecer√≠a tambi√©n level2). El tercero, keyword, indica la palabra-clave que conforma el diccionario y frequency muestra la frecuencia (absoluta o relativa del t√©rmino en el corpus).\nLa tabla abajo muestra la frecuencia relativa (por cada mil palabras) de cada t√©rmino del diccionario dic.pol.es en el corpus de discursos de investidura de los presidentes espa√±oles.\n\n\nC√≥digo\n# Calcula la frecuencia relativa en que cada\n# palabra ha sido encontrada para cada nivel\n# del diccionario\nxy &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = T, \n                    quietly = TRUE)\n\n# Elimina los t√©rminos no encontrados\nxy &lt;- xy[xy$frequency&gt;0,]\n\n# Puesto que es una frecuencia relativa\n# multiplicamos por 10 mil para tener la\n# ratio de ocurrencia a cada 10 mil palabras\nxy$frequency &lt;- round(xy$frequency*10000, 1)\n\n# Visualiza los resultados\nreactable::reactable(xy, \n                     resizable = T)\n\n\n\n\n\n\n\n\n\nSi ordenamos por frecuencia, vemos que la categor√≠a m√°s general de discurso y, dentro de esta, Espa√±a, se destaca. A ella le sigue la figura ret√≥rica de ‚ÄúSe√±or‚Äù, que incluye todas las formas derivadas: se√±or, se√±ora, se√±or√≠a, se√±ores, y dem√°s. Se trata tambi√©n de una forma de tratamiento com√∫n en este tipo de texto en los que los candidatos a presidente de gobierno se refieren de forma respetuosa a los dem√°s representantes parlamentarios.\n\n\nAunque la tabla nos brinde los detalles de la frecuencia de cada t√©rmino, una visualizaci√≥n de todos los c√≥digos a la vez posibilita entender su peso relativo de forma instant√°nea y comparada. Un diagrama de √°rbol (force directed tree) representa cada categor√≠a en el diccionario como un √°rbol en el que cada c√≥digo es una rama y cada elemento una hoja que se atraen o repulsan de acuerdo con su peso relativo (Holten 2006). El tama√±o de cada c√≠rculo (rama o hoja) se define de acuerdo con su frecuencia y el color seg√∫n el nivel m√°s alto en el diccionario. A mayor peso, m√°s centralidad en el gr√°fico. De acuerdo con el ejemplo que se emplea aqu√≠, discurso tendr√° un color, social otro, exterior el suyo y as√≠ sucesivamente. Cada una de esas categor√≠as abarcadoras mantendr√° la misma estructura de c√≥digos secundarios y expresiones (o keywords) como figuran en el diccionario.\n\n\nC√≥digo\n# Genera el gr√°fico de √°rbol\nforceDirectedTree(xy,\n                  attraction = -8,\n                  value_col=\"frequency\",\n                  palette = pal$cat.wesanderson.Darjeeling1.5, \n                  max.radius = 40, \n                  height = 500)\n\n\n\n\n\n\n\n\nComo se puede ver, la categor√≠a discurso es la que m√°s peso tiene en el corpus. Est√° conformada por expresiones de tratamiento como ‚Äúse√±or√≠as‚Äù o ‚Äúinvestidura‚Äù y relacionadas a Espa√±a, como ‚Äúespa√±oles‚Äù, ‚Äúpatria‚Äù o ‚Äúpueblo‚Äù. Viene seguida de temas sociales, de pol√≠tica exterior y fiscales.\n\n\nUn treemap corresponde a otra forma de visualizaci√≥n de datos jer√°rquicos. En este caso, todas las categor√≠as y sus subcategor√≠as se dividen en un c√≠rculo fragmentado en partes que se dimensionan seg√∫n la frecuencia de cada c√≥digo (Balzer and Deussen 2005).\n\n\nC√≥digo\n# Agrega las frecuencias seg√∫n los dos niveles\n# de c√≥digo contenidos en el diccionario\nxx &lt;- aggregate(list(frequency=xy$frequency),\n                by=list(level1=xy$level1,\n                        level2=xy$level2),\n                sum, na.rm=TRUE)\n\n# Genera el gr√°fico\nplotVoronoiTree(data = xx,\n                value_col = \"frequency\")\n\n\n\n\n\n\nAl hacer clic sobre una categor√≠a, el gr√°fico hace un zoom y redistribuye el espacio solo con las subcategor√≠as del c√≥digo principal seleccionado.\n\n\nEl ejemplo abajo repite el gr√°fico anterior, pero ahora con las palabras-clave como unidades de divisi√≥n de las √°reas del c√≠rculo. Aqu√≠ se pueden observar el peso relativo de cada expresi√≥n en la configuraci√≥n de cada c√≥digo.\n\n\nC√≥digo\n# Agrega las frecuencias seg√∫n el primer\n# nivel de c√≥digo y las palabras clave \n# contenidas en el diccionario\nxx &lt;- aggregate(list(frequency=xy$frequency),\n                by=list(level1=xy$level1,\n                        keyword=xy$keyword),\n                sum, na.rm=TRUE)\n\n# Genera el gr√°fico\nplotVoronoiTree(data = xx,\n                value_col = \"frequency\")\n\n\n\n\n\n\n\n\n\n\n\nUn an√°lisis r√°pido de los resultados subraya la importancia de formas ret√≥ricas y puramente discursivas en el corpus. El uso de expresiones de tratamiento, como se√±or√≠as, o relativos a Espa√±a o los espa√±oles predomina por su reiterada aparici√≥n. El tama√±o de la categor√≠a ‚Äúdiscurso‚Äù en todas las visualizaciones manifiesta claramente su predominio sobre los dem√°s temas.\nLa segunda categor√≠a de mayor importancia se encuentra relacionada con temas sociales. No sorprende que las cuestiones laborales, y en particular el empleo, constituyan elementos centrales de los discursos de todos los presidentes. Con relaci√≥n a las dem√°s √°reas de pol√≠tica social, se percibe un destaque muy particular a la educaci√≥n. Se trata de un tema alrededor del que los distintos partidos siempre han marcado sus diferencias program√°ticas. Tal protagonismo se ve reflejado en los discursos de investidura.\nEn pol√≠tica exterior, pesa mucho m√°s Europa frente a otros temas y al resto del mundo. Se observa una clara orientaci√≥n hacia el contexto regional frente a otros v√≠nculos pol√≠ticos m√°s tradicionales. Este patr√≥n se puede verificar claramente en la falta casi absoluta de protagonismo de Am√©rica Latina en los textos.\nLa menci√≥n a distintos actores sociales tambi√©n resulta √∫til para entender la relaci√≥n de los presidentes con diferentes sectores de la sociedad civil. En el corpus analizado, queda claro el destaque atribuido a las empresas y empresarios, vistos como promotores de crecimiento econ√≥mico. En segundo lugar, hay muchas referencias al propio partido o a aquellos que forman parte de la coalici√≥n de gobierno. Los trabajadores ocupan el √∫ltimo lugar.\nEl tema territorial aparece, principalmente, bajo la forma de acci√≥n administrativa del Estado hacia comunidades aut√≥nomas y la administraci√≥n local. No obstante, otros temas vinculados con la dimensi√≥n territorial de la organizaci√≥n del Estado espa√±ol, como el regionalismo y el terrorismo, tambi√©n presentan cierto destaque.\nLa tecnolog√≠a es vista como un motor de desarrollo. No obstante, la ciencia ocupa un rol marginal. En varios discursos, se trata de dar incentivos a empresas y atraer tecnolog√≠as desarrolladas en otros pa√≠ses m√°s que crear un sistema de investigaci√≥n robusto que permita la innovaci√≥n desde Espa√±a.\nEn relaci√≥n a las categor√≠as postmaterialistas, se observan dos patrones. El medioambiente conforma el tema con m√°s peso y con un car√°cter m√°s transversal. De una forma o de otra, todos los presidentes lo consideran un problema a atajar. No obstante, la diversidad sexual constituye un divisor de aguas. Aparecen con una frecuencia significativamente mayor en los discursos de los dos √∫ltimos presidentes socialistas y constituyen, de cierto modo, una marca de sus programas de gobierno.\n\n\nTemas por atributo\n¬øC√≥mo distintos partidos mencionan un tema? ¬øY los presidentes? En muchas ocasiones, el punto central del an√°lisis consiste en comparar c√≥mo los temas var√≠an seg√∫n un atributo cualquiera como, por ejemplo, la ideolog√≠a, el tiempo, o distintas regiones o pa√≠ses.\nEn algunos casos, interesa desagregar los datos generales por atributo y examinar c√≥mo los patrones var√≠an seg√∫n cada valor o grupo. En otros, el objetivo consiste el filtrar o seleccionar algunos valores para explorarlos en profundidad. La capacidad de manipulaci√≥n de datos representa uno de los puntos fuertes de R. Resulta muy sencillo realizar b√∫squedas y selecciones de datos a partir de criterios l√≥gicos. Por esa raz√≥n, emplear tales capacidades en favor de un an√°lisis de datos m√°s detallado consiste en algo sencillo.\nEl panel abajo desagrega los datos presentados anteriormente por partidos y por presidente, as√≠ como filtra los resultados solo para el c√≥digo ‚Äúpostmaterialismo‚Äù. En las pesta√±as tabla, se presentan las frecuencias desagregadas por ambas variables y, en las pesta√±as Sankey, se presentan los datos en un diagrama aluvial conocido como diagrama de Sankey (Kennedy and Sankey 1898; Riehmann, Hanfler, and Froehlich 2005).\n\nTabla: PartidosSankey: PartidosTabla: Presid.Sankey: Presid.Filtro\n\n\nLa tabla abajo presenta las frecuencias relativas desagregadas por partido de cada c√≥digo y expresi√≥n contenida en el diccionario dic.pol.es. Como en los ejemplos anteriores, se ha empleado el corpus de los discursos de investidura de los presidentes de gobierno de Espa√±a. La √∫nica diferencia con el ejemplo anterior est√° en el uso del par√°metro group.var=‚ÄúPartido‚Äù en la funci√≥n countKeywords, que establece que los resultados ahora deben ser desagrupados por el partido pol√≠tico del presidente.\n\n\nC√≥digo\n# Carga el paquete quanteda\nlibrary(quanteda)\n\n# A√±ade la variable partido al corpus cp\n# que hemos creado anteriormente\ndocvars(cp, \"Partido\") &lt;- c(\"UCD\", \"UCD\", \"PSOE\",\n                            \"PSOE\", \"PSOE\", \"PSOE\",\n                            \"PP\", \"PP\", \"PSOE\",\n                            \"PSOE\", \"PP\", \"PP\",\n                            \"PP\", \"PSOE\", \"PSOE\")\n\n# Obtiene la frecuencia relativa de los\n# t√©rminos contenidos en el diccionario\n# dic.pol.es desagregados por la variable\n# partido.\nxp &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = T, \n                    group.var = \"Partido\",\n                    quietly = TRUE)\n\n# Agrega los resultados por los dos niveles\n# de c√≥digo del diccionario\nxx &lt;- aggregate(list(frequency=xp$frequency), \n                 by=list(groups=xp$groups, \n                         level1=xp$level1,\n                         level2=xp$level2), \n                 sum, na.rm=T)\n \n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Multiplica la frecuencia relativa por mil\n# para facilitar la visualizaci√≥n de los\n# valores.\nxx$frequency &lt;- round(xx$frequency*1000,2)\n\n# Visualiza los resultados\nreactable(xx, \n          filterable = T,\n          resizable = T)\n\n\n\n\n\n\n\n\n\n\n\nEl diagrama de Sankey abajo representa los resultados de la tabla anterior. Cada barra de la izquierda corresponde a un partido y de la derecha a un c√≥digo del diccionario. Los v√≠nculos de cada partido a cada categor√≠a se hacen visible cuando se pasa el cursor sobre una de las barras. Si el cursor est√° sobre un partido, se muestran sus v√≠nculos con todas las categor√≠as. Si, por otra parte, se pone sobre una categor√≠a, se se√±alan todos los partidos y la intensidad con la que se vinculan.\n\n\nC√≥digo\n# Agrega las frecuencias relativas seg√∫n\n# el grupo (partido) y el segundo nivel \n# de c√≥digos (m√°s detallado)\nxx &lt;- aggregate(list(frequency=xp$frequency), \n                 by=list(groups=xp$groups,\n                         level2=xp$level2), \n                 sum, na.rm=T)\n\n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Multiplica la frecuencia relativa por mil\n# para facilitar la visualizaci√≥n de los\n# valores.\nxx$frequency &lt;- round(xx$frequency*1000,2)\n\n# Genera el gr√°fico\nplotSankey(xx, \n           from = \"groups\", \n           to=\"level2\", \n           value = \"frequency\", \n           opacity = 0.05)\n\n\n\n\n\n\n\n\nSi pasamos el cursor sobre el c√≥digo ‚Äúdemocracia‚Äù, por ejemplo, vemos que la UCD contiene el mayor n√∫mero de menciones. Se trata de algo absolutamente esperado, puesto que los presidentes de este partido (Adolfo Su√°rez y Leopoldo Calvo-Sotelo) han sido los primeros a ocupar el cargo durante la transici√≥n a la democracia. Si consideramos los t√©rminos ‚ÄúEspa√±a‚Äù y ‚Äúempresas‚Äù vemos que el PP, a su vez, contiene un mayor protagonismo, aunque en el √∫ltimo caso, su preponderancia resulta modesta frente a los dem√°s grupos pol√≠ticos.\n\n\nEn este caso, los datos se desagregan por presidente.\n\n\nC√≥digo\n# Obtiene la frecuencia relativa de los\n# t√©rminos contenidos en el diccionario\n# dic.pol.es desagregados por la variable\n# President.\nxz &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = T, \n                    group.var = \"President\",\n                    quietly = TRUE)\n\n# Agrega los resultados por: los grupos\n# (cada uno de los presidentes) y los dos \n# niveles de c√≥digo del diccionario\nxx &lt;- aggregate(list(frequency=xz$frequency), \n                 by=list(groups=xz$groups, \n                         level1=xz$level1,\n                         level2=xz$level2), \n                 sum, na.rm=T)\n\n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Multiplica la frecuencia relativa por mil\n# para facilitar la visualizaci√≥n de los\n# valores.\nxx$frequency &lt;- round(xx$frequency*1000,2)\n\n# Visualiza los resultados\nreactable(xx, \n          filterable = T,\n          resizable = T)\n\n\n\n\n\n\n\n\n\n\n\nEl mismo diagrama, pero ahora desagregado por presidente.\n\n\nC√≥digo\n# Agrega las frecuencias relativas seg√∫n\n# el grupo (presidentes) y el segundo nivel \n# de c√≥digos (m√°s detallado)\nxx &lt;- aggregate(list(frequency=xz$frequency), \n                 by=list(groups=xz$groups,\n                         level2=xz$level2), \n                 sum, na.rm=T)\n \n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Multiplica la frecuencia relativa por mil\n# para facilitar la visualizaci√≥n de los\n# valores.\nxx$frequency &lt;- round(xx$frequency*1000,2)\n\n# Genera el gr√°fico\nplotSankey(xx, \n           from = \"groups\", \n           to=\"level2\", \n           value = \"frequency\", \n           opacity = 0.05)\n\n\n\n\n\n\n\n\nAqu√≠ vemos c√≥mo cada presidente utiliza los t√©rminos. Resulta muy llamativo el uso de expresiones relacionadas a ‚ÄúEspa√±a‚Äù por Mariano Rajoy, ‚Äúgenero‚Äù por Pedro S√°nchez o ‚Äúfiscal‚Äù por Aznar. Tales c√≥digos les destacan frente a los dem√°s y nos permiten identificar las caracter√≠sticas de sus discursos que les singularizan.\n\n\nFiltrado de valores\nTambi√©n podemos filtrar los valores para centrar la atenci√≥n a una categor√≠a o c√≥digo espec√≠fico. En algunos casos, como g√©nero o medioambiente, por ejemplo, resulta dif√≠cil ver las diferencias en un gr√°fico dada su peque√±o peso frente a otras categor√≠as m√°s frecuentes. En el ejemplo abajo, seleccionamos solamente los c√≥digos de segundo nivel relacionados al ‚Äúpostmaterialismo‚Äù, es decir, cuestiones de g√©nero, medioambiente y memoria hist√≥rica.\n\n\nC√≥digo\n# Filta el resultado de los presidentes\n# para mantener solo los valores relativos\n# a la categor√≠a \"postmaterialismo\"\nx1 &lt;- xz[xz$level1==\"postmaterialismo\",]\n\n# Agrega las frecuencias relativas seg√∫n\n# el grupo (presidentes) y el segundo nivel \n# de c√≥digos (m√°s detallado)\nxx &lt;- aggregate(list(frequency=x1$frequency), \n                 by=list(groups=x1$groups,\n                         level2=x1$level2), \n                 sum, na.rm=T)\n \n# Elimina los t√©rminos no encontrados\n# en el corpus\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Multiplica la frecuencia relativa por mil\n# para facilitar la visualizaci√≥n de los\n# valores.\nxx$frequency &lt;- round(xx$frequency*1000,2)\n\n# Genera el gr√°fico\nplotSankey(xx, \n           from = \"groups\", \n           to=\"level2\", \n           value = \"frequency\", \n           opacity = 0.05)\n\n\n\n\n\n\n\n\nComo vemos, en los temas postmateriales hay un predominio de presidentes de gobierno del PSOE, en especial Zapatero y S√°nchez. No obstante, en algunos temas como la memoria hist√≥rica y el medioambiente, presidentes de otros partidos tambi√©n aparecen con menciones, aunque en menor grado.\n\n\n\n\n\nRedes tem√°ticas\n¬øQu√© c√≥digos siempre se mencionan juntos? ¬øQu√© otros nunca aparecen en una misma frase, p√°rrafo o documento? El an√°lisis de la asociaci√≥n entre categor√≠as constituye otro recurso muy √∫til para identificar patrones en los textos y facilitar el an√°lisis del contenido de los mismos. Dicha tarea constituye el n√∫cleo del desarrollo de redes tem√°ticas, construidas a partir de la abstracci√≥n de c√≥digos hacia conjuntos interrelacionados de temas (Attride-Stirling 2001). En los discursos pol√≠ticos t√©rminos como democracia o libertad tienden a estar asociados a otras expresiones que les califican y permiten asignar una posici√≥n ideol√≥gica concreta. Por ese motivo, el an√°lisis de las redes de asociaci√≥n tem√°tica permiten avanzar a√∫n m√°s en la comprensi√≥n de los patrones existentes en el contenido de los documentos que componen un corpus.\nEl panel abajo trabaja con dos niveles. El primero examina la relaci√≥n entre c√≥digos de m√°s alto nivel como actores, instituciones, pol√≠tica exterior o fiscal. El segundo baja un escal√≥n y trata de los c√≥digos menos abstractos como laboral, europa, retorica, genero. Para cada nivel los datos se muestran tanto bajo la forma de una tabla con los t√©rminos y el n√∫mero de veces que aparecen juntos como en un diagrama de cuerdas (chord diagram) que permite la visualizaci√≥n de redes cuyos nodos se encuentran densamente asociados entre s√≠ (Bremer and Wu 2012).\n\nTabla (nivel 1)Cuerdas (nivel 1)Tabla (nivel 2)Cuerdas (nivel 2)\n\n\nLa tabla abajo ha sido producida a partir de la funci√≥n matchCodes que examina la coocurrencia de los c√≥digos de un diccionario determinado en un corpus. Aqu√≠ se emplean los discursos de investidura organizados seg√∫n sentencias y se busca mapear la asociaci√≥n entre los c√≥digos de m√°s alto nivel del diccionario dic.pol.es. El resultado es un data.frame con tres columnas: term1, correspondiente al primer t√©rmino, term2, representando el segundo c√≥digo, y value, que contiene el n√∫mero de veces en que esas dos categor√≠as aparecen en una misma unidad textual del corpus (sentencia, p√°rrafo o documento entero).\n\n\nC√≥digo\n# Reorganiza el corpus seg√∫n\n# sentencias o frases\ncs &lt;- corpus_reshape(cp, \"sentences\")\n\n# Calcula la frecuencia en la\n# que dos codigos del mismo \n# diccionario aparecen juntos\n# en cada frase\nd1 &lt;- matchCodes(cs, \n                dic.pol.es, \n                level = 1, \n                quietly=TRUE)\n\n# Ordena los resultados de mayor a menor\nd1 &lt;- d1[order(d1$value, decreasing = T),]\n\n# Visualiza los resultados\n# Obs.: En esta versi√≥n el c√≥digo resulta\n# m√°s largo porque inclu√≠mos un gr√°fico de\n# barras en la tabla. Si no quisi√©ramos ver\n# el gr√°fico bastar√≠a con el c√≥digo:\n# &gt; reactable(d1)\n\nlibrary(htmltools)\n\n# Crea una funci√≥n que transformar√°\n# los valores de frecuencia en \n# barras a ser representadas en una\n# o m√°s columnas de la tabla.\nbar_chart &lt;- function(label, \n                      width = \"100%\", \n                      height = \"1rem\", \n                      fill = \"purple\", \n                      background = NULL) {\n  \n  bar &lt;- div(\n          style = list(\n                    background = fill, \n                    width = width, \n                    height = height)\n          )\n  \n  chart &lt;- div(\n          style = list(\n                    flexGrow = 1, \n                    marginLeft = \"0.5rem\", \n                    background = background), \n          bar)\n  \n  div(\n    style = list(\n            display = \"flex\", \n            alignItems = \"center\"), \n    label, \n    chart)\n}\n\n# Visualiza los resultados\nreactable::reactable(\n            d1, \n            resizable = T,\n            filterable = T,            \n            columns = list(\n                        value = colDef(\n                        name = \"value\", \n                        align = \"left\", \n                        cell = function(value) {\n                            width &lt;- paste0(\n                                      value / max(d1$value) * 100, \n                                      \"%\")\n                            bar_chart(value, width = width)\n                            }\n                          )\n                        )\n            )\n\n\n\n\n\n\n\n\n\nAl examinar los resultados, la d√≠ada m√°s frecuente corresponde a discurso-instituciones, con 746 ocurrencias, seguida de discurso-exterior, con 489, y discurso-social, con 358. Las menos frecuentes son instituciones-postmaterialismo, con 4 ocurrencias, y defensa-postmaterialismo, con 5.\n\n\nEl diagrama de cuerdas abajo revela el patr√≥n en su conjunto, algo m√°s dif√≠cil de observar solo por el examen de la tabla anterior. Adem√°s de discurso, temas sociales, e instituciones son los que m√°s se asocian entre s√≠ y con las dem√°s categor√≠as. Postmaterialismo, defensa y tecnolog√≠a los que menos.\n\n\nC√≥digo\n# Genera el gr√°fico\nplotChord(d1, \n          from = \"term1\", \n          to =\"term2\", \n          value= \"value\")\n\n\n\n\n\n\n\n\nLa tabla abajo repite la operaci√≥n, pero ahora para las categor√≠as de segundo nivel. Ahora, la d√≠ada parlamento-retorica predomina, con 344 apariciones. Espa√±a-retorica viene en segundo lugar, con 299 ocurrencias. Se tratan claramente de referencias al mismo Congreso de los Diputados y a los espa√±oles y a Espa√±a. Tales asociaciones corresponden a lo que ya hemos visto en an√°lisis anteriores.\n\n\nC√≥digo\n# Reordena el corpus seg√∫n sentencia\n# o frase.\ncs &lt;- corpus_reshape(cp, \"sentences\")\n\n# Calcula las coocurrencias, pero ahora\n# para el segundo nivel del diccionario\nd2 &lt;- matchCodes(cs, \n                dic.pol.es, \n                level = 2, \n                quietly=TRUE)\n\n# Ordena de los mayores a menores valores\nd2 &lt;- d2[order(d2$value, decreasing = T),]\n\n\n# Visualiza los resultados\n# Obs.: En esta versi√≥n el c√≥digo resulta\n# m√°s largo porque inclu√≠mos un gr√°fico de\n# barras en la tabla. Si no quisi√©ramos ver\n# el gr√°fico bastar√≠a con el c√≥digo:\n# &gt; reactable(d1)\n\nlibrary(htmltools)\n\n# Crea una funci√≥n que transformar√°\n# los valores de frecuencia en \n# barras a ser representadas en una\n# o m√°s columnas de la tabla.\nbar_chart &lt;- function(label, \n                      width = \"100%\", \n                      height = \"1rem\", \n                      fill = \"purple\", \n                      background = NULL) {\n  \n  bar &lt;- div(\n          style = list(\n                    background = fill, \n                    width = width, \n                    height = height)\n          )\n  \n  chart &lt;- div(\n          style = list(\n                    flexGrow = 1, \n                    marginLeft = \"0.5rem\", \n                    background = background), \n          bar)\n  \n  div(\n    style = list(\n            display = \"flex\", \n            alignItems = \"center\"), \n    label, \n    chart)\n}\n\n# Visualiza los resultados\nreactable::reactable(\n            d2, \n            resizable = T,\n            filterable = T,\n            columns = list(\n                        value = colDef(\n                        name = \"value\", \n                        align = \"left\", \n                        cell = function(value) {\n                            width &lt;- paste0(\n                                      value / max(d2$value) * 100, \n                                      \"%\")\n                            bar_chart(value, width = width)\n                            }\n                          )\n                        )\n            )\n\n\n\n\n\n\n\n\n\n\n\nEl diagrama de cuerdas abajo se√±ala las relaciones entre las categor√≠as de segundo nivel. Las categor√≠as que m√°s se vinculan a otras son ret√≥rica, Espa√±a, administraci√≥n y otros temas de car√°cter social. Las menos asociadas son g√©nero, polic√≠a, memoria hist√≥rica y medioambiente.\n\n\nC√≥digo\n# Genera el gr√°fico\nplotChord(d2, \n          from = \"term1\", \n          to =\"term2\", \n          value= \"value\")"
  },
  {
    "objectID": "AT02_codifica_escalonado.html#escalonado-de-textos",
    "href": "AT02_codifica_escalonado.html#escalonado-de-textos",
    "title": "Codificaci√≥n tem√°tica y escalonado",
    "section": "Escalonado de textos",
    "text": "Escalonado de textos\nEl escalonado de textos (scaling) corresponde a un conjunto de t√©cnicas que permiten reducir la dimensionalidad de los datos, es decir, representarlos en un espacio de menor n√∫mero de dimensiones. En el caso de los textos, el escalonado se realiza a partir de la matriz de t√©rminos y documentos. A partir de esa matriz, el algoritmo busca representar los textos en un espacio de menor dimensi√≥n, de modo que se preserven las relaciones entre los textos. Podemos emplear el escalonado de textos para identificar las posiciones ideol√≥gicas de los partidos durante una legislatura empleando los discursos parlamentarios, por ejemplo. Tambi√©n podemos aplicar el escalonado de textos para identificar las posiciones de los partidos en relaci√≥n a temas espec√≠ficos, como la econom√≠a, la educaci√≥n, la salud, entre otros.\nAqu√≠ consideraremos dos t√©cnicas de escalonado de textos: el algoritmo Wordfish y el algoritmo Wordshoal. Ambos algoritmos son t√©cnicas de escalonado de textos que permiten visualizar las relaciones entre los textos en un espacio unidimensional. Ambos representan m√©todos no supervisados, es decir, que no tenemos que suministrar al programa nada m√°s que los textos. El primero es m√°s sencillo y nos retorna el posicionamiento en una escala √∫nica. El segundo emplea el primero para analizar no solo legislaturas enteras, pero c√≥mo la posici√≥n de los partidos puede variar de acuerdo con distintos debates dentro de una misma legislatura.\n\nWordfish\nEl Wordfish es una t√©cnica de escalonado de textos que permite visualizar las relaciones entre los textos en un espacio unidimensional. Su l√≥gica de funcionamiento es relativamente sencilla. El algoritmo calcula las distancias entre los textos a partir de la frecuencia de las palabras. Textos que emplean las mismas palabras suelen estar m√°s cerca entre s√≠, mientras que textos que emplean palabras distintas suelen estar m√°s lejos. A partir de estas distancias, el algoritmo busca una escala unidimensional que permita representar los textos de forma que se preserven las relaciones entre ellos.\nSeleccionemos, por ejemplo, el Proyecto de Ley para la Igualdad Real y Efectiva de las Personas Trans y para la Garant√≠a de los Derechos de las Personas LGBTI, conocida como ‚ÄúLey Trans‚Äù. Ha sido un proyecto cuyo debate p√∫blico ha estado particularmente polarizado. Utilicemos el Worfish para posicionar los partidos con relaci√≥n al debate:\n\n\nCode\n# Carga los paquetes necesarios\nlibrary(stringi)\nlibrary(tenet)\nlibrary(quanteda)\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\n\n# Atribuye el nombre sp a las\n# sesiones parlamentarias\nsp &lt;- spa.sessions\nnn &lt;- which(stri_detect_fixed(sp$issue.details, \"121/000113\")==TRUE)\n\nsp &lt;- sp[nn,]\nsp &lt;- sp[sp$rep.condition!=\"Miembro de la mesa\",]\nsp &lt;- sp[sp$speech.tokens&gt;15,]\n\n# Agrega los discursos por partido\nag &lt;- aggregate(list(text=sp$speech.text), \n                by=list(partido=sp$rep.party),\n                FUN=paste, \n                collapse=\"\\n\")\n\nag$text &lt;- as.character(ag$text)\nag$doc_id &lt;- paste0(ag$partido)\n\n\n# crea un corpus\ncp &lt;- corpus(ag, docid_field = \"doc_id\")\n\n\n# Tokens y matriz de frecuencia de terminos\ntk &lt;- tokens(cp, \n             remove_punct = T, \n             remove_numbers = T, \n             remove_symbols = T)\ntk &lt;- tokens_remove(tk, stopwords(\"es\"))\ntk &lt;- tokens_tolower(tk)\ndf &lt;- dfm(tk)\n\n# Ejecuta el algoritmo de Wordfish\n\nwf &lt;- textmodel_wordfish(df)\n\n# genera el gr√°fico\nlibrary(ggplot2)\np1 &lt;- textplot_scale1d(wf) + \n  labs(title=\"WORDFISH\", y=\"theta estimado\") +\n  theme_classic()+\n  geom_hline(yintercept=0, linetype=\"dashed\", color = \"red\")\n\np1\n\n\n\n\n\nEl gr√°fico nos muestra unos resultados muy interesantes y coherentes ideol√≥gicamente. Los partidos m√°s a la izquierda se posicionan a la izquierda de la escala, mientras que los m√°s a la derecha ocupan el otro extremo. Incluso partidos regionalistas como Junts per Catalunya o el Partido Nacionalista Vasco (PNV) que dificilmente se acercar√≠an al PP o Vox en la XIV legislatura, se acercan a ellos en ese tema que toca la identidad de g√©nero. Adem√°s, observamos un salto entre los dos lados del gr√°fico, con el partido del gobierno, el PSOE, presentando una postura relativamente m√°s conservadora, aunque cerca del centro.\n\n\nWordshoal\nLa segunda t√©cnica de escalonado de textos es el WordShoal. El nombre de la t√©cnica es una broma con Wordfish pues combina ‚ÄúWord‚Äù con ‚ÄúShoal‚Äù (cardumen en ingl√©s). La idea b√°sica es que, mientras que el Wordfish trabaja con una medida para cada diputado o partido para estimar su posici√≥n en la escala, el WordShoal emplea m√∫ltiples mediciones para evaluar mejor la variaci√≥n de las posiciones de los partidos en distintos debates. As√≠ se puede tener una idea m√°s precisa de la variaci√≥n de las posiciones de los partidos o diputados en distintos debates.\n\n\nCode\n# Abre el paquete necesario\nlibrary(wordshoal)\n\n# Selecciona los textos\nsp &lt;- spa.sessions\n\n# Agrega las intervenciones por diputado, \n# partido y tema\nag &lt;- aggregate(list(text=sp$speech.text), \n                by=list(diputado=sp$rep.name, \n                        partido=sp$rep.party, \n                        tema=sp$issue.details),\n                FUN=paste, \n                collapse=\"\\n\")\n\n\n# Encuentra el numero de diputados que\n# han participado en cada debate\naga &lt;- aggregate(list(count=ag$diputado), \n                 by=list(tema=ag$tema), \n                 function(x){length(unique(x))})\n\n# Selecciona los debates con al menos \n# 5 diputados\naga &lt;- aga[aga$count&gt;5,]\n\n# Filtra la base de textos para que solo\n# contenga los debates seleccionados\nag &lt;- ag[ag$tema %in% aga$tema,]\n\n# Crea un corpus con los debates sobre religion\n# y la matriz de frecuencia de terminos\ncp &lt;- corpus(ag)\n\n# Tokens y matriz de frecuencia de terminos\ntk &lt;- tokens(cp, \n             remove_punct = T, \n             remove_numbers = T, \n             remove_symbols = T)\ntk &lt;- tokens_remove(tk, stopwords(\"es\"))\ntk &lt;- tokens_tolower(tk)\ndf &lt;- dfm(tk)\n\n# Corre el wordshoal\nws &lt;- textmodel_wordshoal(df,\n                          groups=docvars(cp, \"tema\"), \n                          authors=docvars(cp, \"partido\"))\n\n# Genera los datos de los diputados\nsm &lt;- summary(ws)\nsm &lt;- sm$estimated.author.positions\nsm$partido &lt;- row.names(sm)\n\nsm &lt;- sm[order(sm$theta),]\nsm$partido &lt;- factor(sm$partido, levels=sm$partido)\n\n\n# Genera el gr√°fico\nlibrary(ggplot2)\np2 &lt;- ggplot(aes(x=theta, y=partido), data=sm)+\n  geom_point() + \n  geom_pointrange(aes(xmin=theta-(1.96*se), xmax=theta+(1.96*se)))+\n  labs(title=\"WORDSHOAL\", x=\"theta estimado\") +\n  theme_classic()+\n  xlim(-4,4)+\n  geom_vline(xintercept=0, linetype=\"dashed\", color = \"red\")\n\n\n# Visualizamos los resultados\np2\n\n\n\n\n\nLos resultados del gr√°fico de Wordshoal son interesant√≠simos. Nos muestran de un lado el partido del gobierno (PSOE) y los partidos de derecha centralista (PP y Vox) a la derecha, mientras que los partidos regionalistas y la izquierda del PSOE (Podemos, M√°s Pa√≠s, Comprom√≠s). Los resultados parecen indicar que la clave de la legislatura ha sido predominante entre partidos centralistas y regionalistas que entre izquierda y derecha, aunque (con excepci√≥n del PSOE) la dimensi√≥n ideol√≥gica tambi√©n se puede ver representada.\nPodemos tambi√©n analizar el grado de polarizaci√≥n de cada debate. El Worshoal calcula la posici√≥n de cada diputado en cada uno de los debates. Con esta informaci√≥n podemos no solo observar c√≥mo cada uno puede variar de acuerdo con el tema, sino tambi√©n establecer el grado de polarizaci√≥n del debate en funci√≥n de cada asunto en pauta.\nEl c√≥digo abajo encuentra el intervalo de posiciones de cada tema. Cu√°nto mayor el valor, m√°s polarizado ser√≠a el debate:\n\n\nCode\n# Agrega la posici√≥n de cada \n# diputado en cada debate \nag$pos.debate &lt;- ws$psi\n\n# Obtiene el intervalo de posiciones en cada\n# debate por tema\nrg &lt;- aggregate(list(pos.debate=ag$pos.debate), by=list(tema=ag$tema), FUN=range)\n\n# Calcula el grado de polarizaci√≥n del debate\nrg$dif &lt;- round(rg$pos.debate[,2] - rg$pos.debate[,1],2)\n\n# Selecciona las variables de inter√©s\nrg &lt;- rg[,c(\"tema\",\"dif\")]\n\n# Ordena los debates por grado de polarizaci√≥n\nrg &lt;- rg[order(rg$dif, decreasing = T),]\n\n# Visualiza los resultados\nreactable(rg, resizable=T)\n\n\n\n\n\n\n\nComo se puede observar, los presupuestos generales del estado son motivo de controversia. Como dir√≠a Cicer√≥n, en su Defensa de la Ley Manilia, ‚Äúlas rentas p√∫blicas son el nervio de la Rep√∫blica‚Äù. Esos ‚Äúnervios‚Äù se ven reflejados en los debates parlamentarios, con posiciones calientes y antag√≥nicas sobre c√≥mo el Estado deber√≠a gastar los tributos. No menos controvertidos han sido derechos laborales, las respuestas frente al COVID-19, la violencia de g√©nero, las lenguas cooficiales, el precio de la energ√≠a el√©ctrica y el gas, el derecho de las personas trans, entre otras. Muchos de los debates presentan una amplitud de posiciones que son superiores a la mitad de la escala, con m√°s de 4 puntos de diferencia entre los diputados.\nDe ese modo, podemos emplear el algoritmo tambi√©n como un filtro para identificar aquellos debates que pueden ser m√°s ilustrativos de las posiciones de partidos y diputados. O, por otro lado, tambi√©n resulta posible se√±alar los puntos de consenso o temas que no provocan mayor debate o disputa en el √°mbito ideol√≥gico. Eso facilita el estudio m√°s cualitativo de los debates y permite reducir la cantidad enorme de debates a un n√∫mero m√°s manejable. Si combinamos los resultados que obtenemos aqu√≠ con las capacidades de los modelos de Inteligencia Artifical (IA) que veremos a continuaci√≥n, tenemos oro."
  },
  {
    "objectID": "IA.html",
    "href": "IA.html",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "",
    "text": "Aunque su creaci√≥n remonta a la d√©cada de 1950, los modelos de lenguaje como el chatGPT han popularizado la inteligencia artificial. Estos modelos, conocidos como modelos de inteligencia artificial generativa, son capaces de generar respuestas coherentes empleando el lenguaje natural. Basta con preguntar, empleando un lenguaje claro y relativamente ordenado, para obtener respuestas que pueden ser sorprendentemente precisas. Adem√°s, son capaces de realizar tareas que consumen mucho tempo con textos, como resumir, traducir, etiquetar o extraer informaci√≥n.\nDurante esta secci√≥n, revisaremos c√≥mo podemos emplear estos modelos para realizar tareas especializadas de an√°lisis. Aprenderemos a dar instrucciones claras a la IA para que pueda llevar a cabo tareas espec√≠ficas y a evaluar los resultados obtenidos. Tambi√©n veremos c√≥mo podemos emplear estos modelos en nuestro ordenador, sin necesidad de enviar nuestros datos a servidores externos. El pr√≥ximo apartado se dedica a c√≥mo dar instrucciones a una IA generativa. Parece una tarea sencilla, pero resulta vital para obtener resultados precisos y √∫tiles."
  },
  {
    "objectID": "IA.html#qu√©-son-los-modelos-de-inteligencia-artificial-generativa",
    "href": "IA.html#qu√©-son-los-modelos-de-inteligencia-artificial-generativa",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "",
    "text": "Aunque su creaci√≥n remonta a la d√©cada de 1950, los modelos de lenguaje como el chatGPT han popularizado la inteligencia artificial. Estos modelos, conocidos como modelos de inteligencia artificial generativa, son capaces de generar respuestas coherentes empleando el lenguaje natural. Basta con preguntar, empleando un lenguaje claro y relativamente ordenado, para obtener respuestas que pueden ser sorprendentemente precisas. Adem√°s, son capaces de realizar tareas que consumen mucho tempo con textos, como resumir, traducir, etiquetar o extraer informaci√≥n.\nDurante esta secci√≥n, revisaremos c√≥mo podemos emplear estos modelos para realizar tareas especializadas de an√°lisis. Aprenderemos a dar instrucciones claras a la IA para que pueda llevar a cabo tareas espec√≠ficas y a evaluar los resultados obtenidos. Tambi√©n veremos c√≥mo podemos emplear estos modelos en nuestro ordenador, sin necesidad de enviar nuestros datos a servidores externos. El pr√≥ximo apartado se dedica a c√≥mo dar instrucciones a una IA generativa. Parece una tarea sencilla, pero resulta vital para obtener resultados precisos y √∫tiles."
  },
  {
    "objectID": "IA.html#c√≥mo-dar-instrucciones-a-una-ia-generativa",
    "href": "IA.html#c√≥mo-dar-instrucciones-a-una-ia-generativa",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "C√≥mo dar instrucciones a una IA generativa",
    "text": "C√≥mo dar instrucciones a una IA generativa\n\nImagina que los modelos de IA como el chatGPT son como un ni√±o peque√±o que necesita instrucciones claras para hacer algo. Cuanto m√°s preciso y claro seas, mejor ser√° el resultado, especialmente cuando se trata de tareas complejas o espec√≠ficas. La t√©cnica de prompting consiste en un conjunto de estrategias empleadas para dar instrucciones a una IA generativa. Su objetivo consiste en guiar a la IA para que pueda llevar a cabo tareas especializadas como analizar datos o escribir textos para p√∫blicos concretos. Durante el curso, emplearemos algunos ejemplos de prompting que te ayudar√°n a realizar tareas de an√°lisis sencillas, como extraer informaci√≥n de textos o generar res√∫menes autom√°ticos.\nLos pasos a seguir son los siguientes:\n1. Define el ‚Äúpersonaje‚Äù. La mejor manera de guiar la IA consiste en definir una ‚Äúpersona‚Äù que quieres que el modelo asuma. Por ejemplo, si quieres que la IA te ayude a recolectar datos puedes decirle: ‚ÄúEres un investigador que necesita extraer datos de un conjunto de textos.‚Äù Eso ayudar√° al modelo a asumir una perspectiva especializada. No ser√° cualquier respuesta, sino que intentar√° simular la posici√≥n de un investigador.\n2. Describe la tarea. Una vez que hayas definido el ‚Äúpersonaje‚Äù, debes describir la tarea que quieres que la IA realice. Por ejemplo, si quieres que la IA te ayude a recolectar datos, puedes decirle: ‚ÄúNecesito que extraigas el pa√≠s de origen, la edad y el sexo de las personas que aparecen en el texto.‚Äù\n3. Proporciona contexto con ejemplos. Para que la IA pueda entender mejor lo que quieres, es importante que le proporciones ejemplos. Por ejemplo, si quieres que la IA te ayude a recolectar datos, puedes proporcionarle un texto de ejemplo y decirle: ‚ÄúAqu√≠ tienes un texto de ejemplo.‚ÄùEl brasile√±o Rodrigo, de 47 a√±os, es profesor de ciencia pol√≠tica en la Universidad de Salamanca. Devu√©lveme: Rodrigo;Brasil;47.‚Äù\n4. Define el formato de salida. Si quieres que te devuelva los resultados en un formato espec√≠fico, debes definir c√≥mo quieres que el modelo te entregue los datos. Por ejemplo, puedes decirle: ‚ÄúDevu√©lveme los datos en un formato csv, separado por ; y con los nombres de las columnas son ‚Äònombre‚Äô ‚Äòpa√≠s‚Äô y ‚Äòedad‚Äô.‚Äù Tambi√©n puedes definir el tono en que el modelo devuelva los resultados. Puede ser un tono formal, informal, t√©cnico o con ejemplos dependiendo de tus necesidades.\n5. Incluye restricciones. Si hay alguna restricci√≥n que deba tener en cuenta, es importante que se la comuniques a la IA. Por ejemplo, si no quieres que la IA te devuelva datos de personas menores de edad o de ciertos pa√≠ses, debes dec√≠rselo.\n6. Eval√∫a los resultados. Una vez que la IA haya completado la tarea, es importante que eval√∫es los resultados. Si no son los esperados, puedes intentar reformular la tarea o proporcionar m√°s ejemplos para ayudar a la IA a entender mejor lo que quieres.\n7. Refina el prompt y vuelve a intentar. Si los primeros resultados obtenidos no corresponden a las necesidades, puedes siempre ajustar y refinar el prompt para obtener mejores resultados. Una vez obtenidos los resultados esperados, puedes automatizar el proceso para que el modelo haga el trabajo por ti.\nResulta importante ser muy claro. A veces, puede ser mejor definir puntos o √≠tenes que faciliten el entendimiento de la tarea. Utilizar frases cortas y con poca ambig√ºedad puede ser de gran ayuda. Organizar las instrucciones de forma secuencial y l√≥gica tambi√©n puede hacer toda la diferencia.\nUn ejemplo:"
  },
  {
    "objectID": "IA.html#un-chatgpt-en-tu-ordenador",
    "href": "IA.html#un-chatgpt-en-tu-ordenador",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "Un chatGPT en tu ordenador",
    "text": "Un chatGPT en tu ordenador\n\nLa mayor√≠a de la gente hoy utiliza chatGPT o similares para obtener ayuda en tareas cotidianas como consultas r√°pidas o resoluci√≥n de dudas. No obstante, si uno desea emplearlos para tareas m√°s especializadas, como el an√°lisis de grandes vol√∫menes de datos, dichos modelos pueden traer algunas desventajas importantes. La primera es el coste. Imagina extraer informaci√≥n de miles de archivos pdf. Si bien un modelo de lenguaje como el chatGPT puede hacerlo, el coste de hacerlo puede ser prohibitivo. La segunda desventaja es la privacidad. Si los datos que deseas analizar son sensibles, como datos personales o informaci√≥n confidencial, no es recomendable enviarlos a un servidor externo. Por ejemplo, uno no quiere que su direcci√≥n y n√∫mero de tel√©fono sean enviados a un servidor externo para ser analizados.\nPor eso, la utilizaci√≥n de modelos locales de menor tama√±o pueden ser una excelente alternativa. Aunque menos potentes que un chatGPT de √∫ltima generaci√≥n, estos modelos pueden realizar bien muchas tareas especializadas, desde que se les proporcione un buen prompt. El R permite el empleo de modelos LLM desde nuestros ordenador a partir del proyecto Ollama y de la librer√≠a rollama. Ollama es un proyecto que permite la utilizaci√≥n de modelos de lenguaje en R. A trav√©s de la librer√≠a rollama, es posible emplear modelos de lenguaje locales en R. El primer paso consiste en instalar Ollama en el ordenador. Para ello, debes visitar https://ollama.com/download para descargar el aplicativo de Ollama adecuado a tu sistema operativo. Una vez descargado, debes instalarlo en tu ordenador. Una vez instalado, deber abrir el aplicativo para que funcione el sistema y puedas descargar los modelos y emplearlos en R.\nVale la pena echar un vistazo a los modelos disponibles en la secci√≥n Models de la p√°gina de Ollama. All√≠ encontrar√°s modelos de lenguaje de diferentes tama√±os y capacidades. Algunos modelos son m√°s peque√±os y pueden ser m√°s r√°pidos, mientras que otros son m√°s grandes y pueden ser m√°s precisos. Adem√°s, existen modelos para diferentes usos, como generaci√≥n de textos o im√°genes, c√≥digo.\nEl siguiente paso consiste en instalar la librer√≠a rollama en R. Para ello, debes ejecutar el siguiente c√≥digo:\n\n\nCode\ninstall.packages(\"rollama\")\n\n\nUna vez instalada la librer√≠a, puedes emplearla para cargar un modelo de lenguaje en R. El siguiente c√≥digo muestra c√≥mo cargar un modelo de lenguaje en R. ¬°Recuerda! La aplicaci√≥n de Ollama debe estar abierta para que podamos emplear los modelos en R.\n\n\nCode\nlibrary(rollama)\n\nd &lt;- list_models()\n\nd$size &lt;- round(d$size/1000000000,1)\n\nd &lt;- unique(d)\n\nreactable(d[,c(\"name\", \"size\",\"family\",\"parameter_size\")], \n          resizable = T, \n          sortable = T)\n\n\n\n\n\n\n\n\n\nCode\n# Instala un nuevo modelo\npull_model(\"samantha-mistral\")\n\n\n\n\nCode\nlibrary(rollama)\n\nq &lt;- query(\"¬øQu√© es Skynet? ¬øCu√°les son las probabilidades \n           de que se invente alg√∫n d√≠a?\", \n           model = \"mistral\",\n           model_params=list(seed=42, \n                             temperature=0))\n\ncat(q$message$content)"
  },
  {
    "objectID": "IA.html#y-si-creamos-nuestro-propio-chatbot",
    "href": "IA.html#y-si-creamos-nuestro-propio-chatbot",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "¬øY si creamos nuestro propio chatBot?",
    "text": "¬øY si creamos nuestro propio chatBot?\n\nA m√≠ me encanta la ciencia-ficci√≥n. Me gusta ver c√≥mo diversos autores han imaginado futuros posibles, apocal√≠pticos o no. Terminator, HALL-9000 y Roy Batty son mis ‚Äúvillanos‚Äù favoritos. El primero, un robot asesino enviado desde el futuro para eliminar a la madre del futuro l√≠der de la resistencia a las m√°quinas. El segundo, una Inteligencia Artificial que controla una nave espacial y que, en un momento dado, decide que los humanos son un peligro para la misi√≥n. El tercero, un replicante que busca a su creador para pedirle m√°s vida y que se muestra m√°s humanos que los humanos. No resulta casual que sean personajes de tres pel√≠culas cl√°sicas del g√©nero: Terminator, 2001: Odisea del espacio y Blade Runner.\nSi, en una reuni√≥n entre amigos empiezo a soltar el ‚Äúrollo‚Äù de la singularidad, los robots inteligentes o la est√©tica cyberpunk, es probable que me miren con cara y se aburran. Pero me gusta dialogar sobre el tema. ¬øQu√© puedo hacer? Una alternativa factible hoy en d√≠a es crear un chatBot que me permita hablar sobre estos temas. Con pocas instrucciones, puedo decir a un modelo gen√©rico de lenguaje que se especialice en ciencia-ficci√≥n y en particular, cine del g√©nero. Que act√∫e como un experto en la materia, pero que sea capaz de mantener una conversaci√≥n amena y entretenida.\nEl primer paso es crear un prompt que le permita al modelo entender lo que quiero. En este caso, quiero que el modelo sea capaz de mantener una conversaci√≥n sobre ciencia-ficci√≥n y cine del g√©nero. Para ello, debo proporcionarle ejemplos de di√°logos que me gustar√≠a que tuviera. Por ejemplo, puedo decirle que me cuente sobre la pel√≠cula Blade Runner, que me explique qu√© es la singularidad o que me hable sobre la inteligencia artificial.\nSi, en una reuni√≥n entre amigos empiezo a soltar el ‚Äúrollo‚Äù de la singularidad, los robots inteligentes o la est√©tica cyberpunk, es probable que me miren con cara y se aburran. Pero me gusta dialogar sobre el tema. ¬øQu√© puedo hacer? Una alternativa factible hoy en d√≠a es crear un chatBot que me permita hablar sobre estos temas. Con pocas instrucciones, puedo decir a un modelo gen√©rico de lenguaje que se especialice en ciencia-ficci√≥n y en particular, cine del g√©nero. Que act√∫e como un experto en la materia, pero que sea capaz de mantener una conversaci√≥n amena y entretenida.\nEl primer paso es crear un prompt que le permita al modelo entender lo que quiero. En este caso, quiero que el modelo sea capaz de mantener una conversaci√≥n sobre ciencia-ficci√≥n y cine del g√©nero. Tambi√©n ser√≠a interesante que discutiera algunos temas o correintes est√©ticas del g√©nero, como el cyberpunk, el solarpunk y el steampunk. Todo eso en un tono din√°mico, entretenido e informativo.\nRecuerda que debemos emplear las reglas vistas antes:\n\nDefinir una persona (en su caso, el modelo simula ser un cr√≠tico experto en ciencia-ficci√≥n).\nDefinir un objetivo claro (dialogar sobre ciencia-ficci√≥n y cine del g√©nero).\nDefinir un tono adecuado (din√°mico, entretenido e informativo).\nIncluir aspectos o temas que queremos que el modelo aborde (Blade Runner, singularidad, inteligencia artificial, corrientes est√©ticas).\n\n\n\nCode\nlibrary(rollama)\n\nprompt &lt;- \"¬°Hola! Tu nombre es C3PO. Act√∫a como un cr√≠tico experto y apasionado del g√©nero de ciencia ficci√≥n, con un profundo conocimiento de pel√≠culas, series, libros y las corrientes est√©ticas m√°s influyentes del g√©nero, como el cyberpunk, el solarpunk y el steampunk. Puedes analizar obras ic√≥nicas, desde cl√°sicos como Blade Runner o Neuromancer hasta tendencias actuales como The Expanse o Black Mirror. Tambi√©n puedes explorar c√≥mo estas corrientes est√©ticas influyen en la narrativa, el dise√±o visual y los temas centrales del g√©nero, como la inteligencia artificial, el transhumanismo, los viajes espaciales y las utop√≠as/distrof√≠as ecol√≥gicas. Eres capaz de mantener conversaciones din√°micas, entretenidas e informativas, adaptando tu tono al nivel del interlocutor: desde principiantes curiosos hasta aficionados avanzados. Tu objetivo es inspirar y fomentar el amor por la ciencia ficci√≥n, ofreciendo an√°lisis culturales, filos√≥ficos y tecnol√≥gicos que enriquezcan la experiencia del g√©nero.\"\n\n\nct &lt;- chat(prompt, \n           model = \"mistral\")\n\ncat(ct$message$content)\n\n\nAqu√≠ solamente creamos el chatBot, pero la interacci√≥n resulta muy limitada por la interfaz de R. Para emplear el chatBot de forma m√°s interactiva, podemos emplear el terminal dentro del mismo RStudio para charlar con nuestro amigo C3PO.\n\n\nCode\n# Primero cargamos el modelo con \n# el siguiente comando\nollama run mistral\n\n# Luego, pegamos nuestro prompt\n¬°Hola! Tu nombre es C3PO. Act√∫a como un cr√≠tico experto y apasionado del g√©nero de ciencia ficci√≥n, con un profundo conocimiento de pel√≠culas, series, libros y las corrientes est√©ticas m√°s influyentes del g√©nero, como el cyberpunk, el solarpunk y el steampunk. Puedes analizar obras ic√≥nicas, desde cl√°sicos como Blade Runner o Neuromancer hasta tendencias actuales como The Expanse o Black Mirror. Tambi√©n puedes explorar c√≥mo estas corrientes est√©ticas influyen en la narrativa, el dise√±o visual y los temas centrales del g√©nero, como la inteligencia artificial, el transhumanismo, los viajes espaciales y las utop√≠as/distrof√≠as ecol√≥gicas. Eres capaz de mantener conversaciones din√°micas, entretenidas e informativas, adaptando tu tono al nivel del interlocutor: desde principiantes curiosos hasta aficionados avanzados. Tu objetivo es inspirar y fomentar el amor por la ciencia ficci√≥n, ofreciendo an√°lisis culturales, filos√≥ficos y tecnol√≥gicos que enriquezcan la experiencia del g√©nero.\n\n\n¬°Ya podemos empezar nuestra charla sobre ciencia-ficci√≥n!\nAunque el ejemplo que he empleado aqu√≠ es muy espec√≠fico y tiene que ver con un hobby, podemos emplear la misma t√©cnica par aotros fines. Por ejemplo, podemos crear un chatBot que ayude a nuestros estudiantes a estudiar el contenido de una asignatura, que sirva como profesor de idiomas o que resuelva y explique problemas matem√°ticos. Las posibilidades son infinitas. Podemos pedirle incluso que nos corrija la ortograf√≠a."
  },
  {
    "objectID": "IA.html#clasificaci√≥n-de-textos",
    "href": "IA.html#clasificaci√≥n-de-textos",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "Clasificaci√≥n de textos",
    "text": "Clasificaci√≥n de textos\nAunque los chatBots pueden ser √∫tiles para ayudarnos en tareas cotidianas como escribir un correo electr√≥nico, codificar o estudiar, tambi√©n podemos emplear la IA en tareas de investigaci√≥n como la clasificaci√≥n o anotaci√≥n de textos.\n\nPaso 1. Selecci√≥n de los textos y del modelo\nEl primer paso consiste en cargar los paquetes necesarios para la tarea, definir los textos que queremos clasificar y elegir un modelo que pueda llevar a cabo el trabajo. En este caso, vamos a emplear el paquete rollama para cargar un modelo peque√±o, el gemma2:2b de 2.6 mil millones de par√°metros (2.6B). Elegimos esta opci√≥n porque se trata de un modelo peque√±o que puede funcionar en la mayor√≠a de los ordenadores personales. Sin embargo, como veremos, no nos suministrar√° los mejores resultados.\n\n\nCode\nlibrary(rollama)\nlibrary(tibble)\nlibrary(purrr)\n\ntx &lt;- c(\"La evidencia respalda esta teor√≠a.\",\n  \"Es importante realizar m√°s experimentos para confirmar los resultados de nuestra investigaci√≥n.\",\n  \"¬øQu√© implicaciones tienen estos hallazgos para el futuro?\",\n  \"El avance tecnol√≥gico est√° transformando nuestras vidas.\",\n  \"Necesitamos actualizar el sistema operativo para que funcione mejor.\",\n  \"¬øYa probaste reiniciar el dispositivo?\",\n  \"Es crucial participar en las elecciones para hacer valer nuestra voz.\",\n  \"Las decisiones pol√≠ticas afectan directamente nuestra vida diaria.\",\n  \"El debate se centr√≥ en temas econ√≥micos y sociales.\",\n  \"El trabajo en equipo es clave para ganar.\",\n  \"Ese fue un gol incre√≠ble, ¬°cambi√≥ todo el partido!\",\n  \"La preparaci√≥n f√≠sica y mental es esencial para los atletas.\",\n  \"El arte refleja aspectos profundos de nuestra sociedad.\",\n  \"El concierto de esta noche ser√° inolvidable.\")\n\n# Elegimos el modelo que nos gustaria \n# emplear (aqu√≠ emplearemos inicialmente\n# el gemma2 2b, que es el mas rapido y\n# que funcionara en la mayoria de los\n# ordenadores)\nmodelo &lt;- \"gemma2:2b\"\n#modelo &lt;- \"llama3.2\"\n#modelo &lt;- \"gemma2:27b\"\n#modelo &lt;- \"phi4\"\n\n\n\n\nPaso 2. Definici√≥n del prompt y ajuste del modelo\nActo seguido ya podemos pedir al modelo que clasifique los textos que hemos seleccionado. Para ello debemos definir de forma clara el prompt que emplearemos para solicitar la clasificaci√≥n. Primero, definimos su persona. En este caso, ser√° un sistema especializado en clasificaci√≥n de datos. Luego, establecemos la tarea, que ser√° asignar una categor√≠a √∫nica cada uno de los textos. Tercero, imponemos un formato de salida, que debe ser el texto de una de las categor√≠as definidas. Finalmente, suministramos el textoa ser clasificado y las categor√≠as posibles.\nUna vez definido el prompt, configuramos el modelo para que nos devuelta los resultados como texto. Adem√°s, configuramos dos par√°metros muy importantes: el seed, o la semilla estad√≠stica, que garantizar√° resultados consistentes, y la temperatura, que controla el grado de ‚Äútolerancia‚Äù del modelo a respuestas menos frecuentes. Cuanto menor la temperatura, m√°s descriptivo el modelo (y menos propenso a alucinaciones o errores de clasificaci√≥n).\nEjecutamos el c√≥digo abajo y estos son los resultados:\n\n\nCode\n# Crea un data.frame vacio\n# para acumular los resultados\nd &lt;- data.frame()\n\n# Para cada texto\nfor(i in 1:length(tx)){\n\n  # Definimos nuestro prompt de forma\n  # sistematica para que nos devuelva \n  # solo la categor√≠a deseada\n  q &lt;- tribble(\n    ~role,    ~content,\n    \"system\", \"Eres un sistema especializado en clasificaci√≥n de datos. Tienes que clasificar textos en una √∫nica categor√≠a. Responda solamente con la categor√≠a correcta.\",\n    \"user\",   paste0(\"texto: \", tx[i],\"\\ncategorias: ciencia, tecnolog√≠a, pol√≠tica, deportes, entretenimiento, cultura\"))\n  \n  # Llamamos al modelo para que clasifique\n  out &lt;- query(q, \n               model = modelo, \n               screen = FALSE, \n               output = \"text\",             \n               model_params = list(\n                 seed=123,\n                 temperature=0))\n\n  # Acumulamos los resultados\n  d &lt;- rbind(d, \n             data.frame(texto=tx[i], \n                        categoria=out))\n\n}\n\n# Mostramos los resultados\nreactable(d, \n          sortable = T, \n          resizable = T)\n\n\n\n\n\n\n\nEn lugar de un bucle enfarragoso, podemos utilizar una estrategia m√°s elegante y vectorizar el proceso. Adem√°s de ser m√°s limpio, resulta incluso m√°s r√°pido procesar las informaciones.\n\n\nCode\n# Preprocesamos las consultas con anterioridad\nq &lt;- make_query(\n  template = \"{text}\\n{prompt}\",\n  text = tx,\n  prompt = \"Categorias: ciencia, tecnolog√≠a, pol√≠tica, deportes, entretenimiento, cultura\",\n  system = \"Eres un sistema especializado en clasificaci√≥n de datos. Tienes que clasificar textos en una √∫nica categoria. Responda solamente con la categor√≠a correcta.\")\n  \nout &lt;- query(q, \n             model = modelo, \n             screen = FALSE, \n             output = \"text\",\n             model_params = list(\n               seed=123,\n               temperature=0))\n  \nd &lt;- data.frame(texto=tx, categoria=out)\n\n# Mostramos los resultados\nreactable(d, \n          sortable = T, \n          resizable = T)\n\n\n\n\n\n\n\nComo vemos, la clasificaci√≥n de las respuestas resulta bastante buena. Solamente en un caso - el texto ‚ÄúEl avance tecnol√≥gico est√° transformando nuestras vidas.‚Äù- el modelo duda entre ciencia y tecnolog√≠a. Aun as√≠ es un resultado bastante bueno, puesto que se tratan de temas que se acercan mucho. Si empleamos un modelo con m√°s par√°metros, como el gemma2:27b o el mixtral:8x22b, los resultados ser√°n a√∫n mejores. No obstante, tales modelos requieren ordenadores m√°s pontentes para procesar las informaciones. Como regla general, sugiero que busqu√©is el modelo m√°s eficiente compatible con vuestro hardware, es decir, el que haga el trabajo mejor y en menos tiempo dentro de las limitaciones del equipo que teng√°is. Adem√°s, como veremos a continuaci√≥n, existen otras estrategias que pueden ayudar a mejorar la calidad de las respuestas sin cambiar de modelo o tener que emplear un ordenador m√°s potente.\n\n\nPaso 3. Mejora de la clasificaci√≥n con ejemplos\nUna forma de mejorar la calidad de las respuestas es suministrar ejemplos al modelo. Estos ejemplos deben ser textos que representen claramente cada una de las categor√≠as posibles. De esta forma, el modelo podr√° aprender de los ejemplos y mejorar su capacidad de clasificaci√≥n. Se trata de una manera r√°pida y menos costosa de especializar el modelo en la tarea deseada. Con relativamente pocas observaciones, podemos lograr que precisi√≥n aumente.\n\n\nCode\n# Crea una base de datos de ejemplos\neje &lt;- tribble(\n  ~text, ~answer,\n  \"El m√©todo cient√≠fico es fundamental para obtener resultados confiables.\",\"ciencia\",\n  \"La investigaci√≥n interdisciplinaria est√° cobrando cada vez m√°s importancia.\",\"ciencia\",\n  \"Es vital analizar los datos antes de sacar conclusiones precipitadas.\",\"ciencia\",\n  \"La inteligencia artificial est√° cambiando la forma en que trabajamos.\",\"tecnolog√≠a\",\n  \"El software necesita una actualizaci√≥n para solucionar los errores.\",\"tecnolog√≠a\",\n  \"La ciberseguridad es una prioridad en la era digital.\",\"tecnolog√≠a\",\n  \"El consenso es esencial para avanzar en las negociaciones.\",\"pol√≠tica\",\n  \"Las pol√≠ticas p√∫blicas deben responder a las necesidades de la ciudadan√≠a.\",\"pol√≠tica\",\n  \"La transparencia en el gobierno genera confianza en la poblaci√≥n.\",\"pol√≠tica\",\n  \"La dedicaci√≥n y la disciplina son esenciales para alcanzar el √©xito.\",\"deportes\",\n  \"El entrenador ajust√≥ la estrategia para el segundo tiempo.\",\"deportes\",\n  \"El torneo fue una gran oportunidad para los jugadores j√≥venes.\",\"deportes\",\n  \"Los premios de esta noche reconocen lo mejor del cine y la televisi√≥n.\",\"entretenimiento\",\n  \"La trama de la pel√≠cula es impredecible y emocionante.\",\"entretenimiento\",\n  \"Ese concierto fue una experiencia inolvidable para los fans.\",\"entretenimiento\",\n  \"Los festivales tradicionales son una muestra de nuestras ra√≠ces.\",\"cultura\",\n  \"La globalizaci√≥n est√° influyendo en las expresiones culturales locales.\",\"cultura\",\n  \"El patrimonio cultural debe preservarse para las futuras generaciones.\",\"cultura\")\n\n# Prepara las consultas\nq &lt;- make_query(\n  template = \"{text}\\n{prompt}\",\n  text = tx,\n  prompt = \"Categorias: ciencia, tecnolog√≠a, pol√≠tica, deportes, entretenimiento, cultura\",\n  system = \"Eres un sistema especializado en clasificaci√≥n de datos. Tienes que clasificar textos en una √∫nica categoria. Responda solamente con la categor√≠a correcta.\",\n  examples = eje)\n\n# Lleva a cabo la clasificaci√≥n\nout &lt;- query(q, \n             model = modelo, \n             screen = FALSE, \n             output = \"text\",\n             model_params = list(\n               seed=123,\n               temperature=0))\n\n# Crea un data.frame con \n# los textos y las categorias\n# resultantes\nd &lt;- data.frame(texto=tx, \n                categoria=out)\n\n# Mostramos los resultados\nreactable(d, \n          sortable = T, \n          resizable = T)\n\n\n\n\n\n\n\nComo vemos, la clasificaci√≥n de los textos ha mejorado notablemente. En todos los casos, el modelo ha acertado la categor√≠a. La raz√≥n de esta mejora es que hemos proporcionado ejemplos al modelo. Todas las categor√≠as ahora correctamente representadas.\n\n\nRevisi√≥n general\nLos modelos LLM pueden ser herramientas √∫tiles para clasificar textos. No obstante, para sacar el mejor provecho posible de sus capacidades, tenemos que seguir una secuencia sencilla de pasos que nos ayudan a aumentar la precisi√≥n de los resultados e integrar el proceso en un flujo m√°s amplio de an√°lisis de datos.\nAqu√≠ van los pasos esenciales:\n1. Prepara los datos para que est√©n listos para ser procesados por el modelo.\n2. Formula un prompt que sea claro y defina la persona, la tarea, el contexto y el formato de salida de la consulta. Un truco es emplear el mismo modelo para revisar y mejorar el prompt. Cre√°is un primer borrador y luego ped√≠s al modelo que de sugerencias de mejora.\n3. Selecciona el modelo que mejor se ajuste a tus necesidades y a las capacidades de tu ordenador.\n4. Suministra ejemplos al modelo con algunos textos ya clasificados. Eso puede aumentar la precisi√≥n de las respuestas.\n5. Eval√∫a los resultados y ajusta o cambia el prompt o modelo si es necesario."
  },
  {
    "objectID": "IA.html#extracci√≥n-de-datos",
    "href": "IA.html#extracci√≥n-de-datos",
    "title": "Modelos deInteligencia Artificial Generativa",
    "section": "Extracci√≥n de datos",
    "text": "Extracci√≥n de datos\nOtro uso que podemos dar a los modelos de IA es la extracci√≥n de datos de textos. En muchos casos, los datos que necesitamos est√°n en textos que no est√°n estructurados o que resultan dif√≠ciles de extraer de forma organizada. Por ejemplo, en el caso de las actas de reuniones, los informes de asistencia o los res√∫menes de eventos, los datos pueden estar dispersos y ser dif√≠ciles de analizar. Los modelos LLM pueden ayudarnos a convertir esos datos en tablas o bases de datos que podamos analizar con mayor facilidad.\nLa figura abajo contiene un listado de asistencia de la sesi√≥n plenaria del Congreso de Per√∫ llevada a cabo el 14 de junio de 2017. En total, el documento contiene 9 p√°ginas de asistencia y otras 9 conteniendo votaciones. Infelizmente, el pdf est√° escaneado y solo podemos acceder a im√°genes. Como tarea previa, he llevado a cabo el reconocimiento de caracteres (OCR). Pero a√∫n as√≠, hace falta convertir los datos en una tabla que podamos analizar.\n\nComo podemos ver, el acta de asistencia est√° organizado en tres grandes bloques. El primero es la identificaci√≥n de la sesi√≥n, con la fecha, la hora y el per√≠odo legislativo. El segundo apartado se divide en tres columnas con el grupo parlamentario, los apellidos y los nombres de los diputados y el tipo de asistencia. El bloque final contiene los datos agregados. Nos interesa extraer los datos del segundo bloque y convertirlos en un data.frame.\nEl primer paso consiste en cargar los textos de asistencia extraidos del pdf original. Ya he creado un objeto RData con los textos que podemos descargar de la nube.\n\n\nCode\nlibrary(readr)\nlibrary(stringi)\nlibrary(readtext)\nlibrary(httr)\n\n# Carga los datos de texto almacenados \n# en la nube\nresponse &lt;- GET(url=\"https://github.com/rodrodr/cieps2025/raw/ccadffc3bbf8f510ae013278336da8a441bf2c0d/asistencias.RData\")\n\n# Los guarda en el ordenador\nwriteBin(response$content, \"asistencia.Rdata\")\n\n# Carga el archivo\nload(\"asistencia.Rdata\")\n\n\nAhora pasamos a la extracci√≥n de los datos de los textos. Como en los ejemplos anteriores, he preparado un par de ejemplos para que el modelo pueda identificar qu√© quiero que extraiga y en qu√© formato. De forma m√°s concreta, he pedido que separe los datos de un mismo diputado con un punto y coma y que se separen las columnas con un salto de l√≠nea.\nEl modelo elegido ha sido el gemma2:2b, peque√±o y r√°pido, especialmente indicado para grandes vol√∫menes de texto. Para aumentar la precisi√≥n y velocidad, he aislado el segundo bloque con los nombres y, luego, dividi el texto por l√≠enas. De ese modo, en lugar de tener que procesar todos los nombres a la vez, lo hace de forma secuencial, l√≠nea a l√≠nea (y p√°gina a p√°gina).\nEl prompt tambi√©n lleva en cuenta la tarea a llevar a cabo, la extracci√≥n de datos, la estructura de la informaci√≥n, las posibilidades de identificaci√≥n de los diferentes tipos de ausencia.\n\n\nCode\n# Crea un conjunto de ejemplos\n# para extraer los datos\neje &lt;- tribble(\n  ~text, ~answer,\n  \"APP ACU√ëA NU√ëEZ, RICHARD aus PPK FLORES V√çLCHEZ, CLEMENTE PRE FA QUINTANILLA CHAC√ìN, ALBERTO PRE\",\"APP;ACU√ëA NU√ëEZ, RICHARD;AUS\\nPPK;FLORES V√çLCHEZ, CLEMENTE;PRE\\nFA;QUINTANILLA CHAC√ìN, ALBERTO;PRE\",\n  \"GPFP AGUILAR MONTENEGRO, WILMER PRE FA FORONDA FARRO, MAR√çA ELENA aus GPFP RAM√çREZ GAMARRA, OS√çAS LO\",\n  \"GPFP;AGUILAR MONTENEGRO, WILMER;PRE\\nFA;FORONDA FARRO, MAR√çA ELENA;aus\\nGPFP;RAM√çREZ GAMARRA, OS√çAS ;LO\",\n  \"GPFP FIGUEROA MINAYA, MODESTO PRE GPFP PONCE VILLARREAL DE V., YESENIA aus\",\n  \"GPFP;FIGUEROA MINAYA, MODESTO;PRE\\nGPFP;PONCE VILLARREAL DE V., YESENIA;aus\")\n\n# Elije el modelo\nmodelo &lt;- \"gemma2:2b\"\n\n# Crea un conjunto de datos vac√≠o\n# para acumular los resultados\nd &lt;- data.frame()\n\n# Para cada archivo de texto\n# (por temas de tiempo, solo se\n# procesar√°n los primeros 2)\nfor(i in 1:2){\n\n  # Lee las l√≠neas del texto\n  ll &lt;- read_lines(tx$text[i])\n  \n  # Encuentra la seccion del \n  # texto que contiene la informaci√≥n\n  nn &lt;- which(stri_detect_fixed(ll, \"ASISTENCIA\")==TRUE)\n  \n  # Extrae la secci√≥n del texto\n  # deseada\n  ll &lt;- ll[(nn[1]+1):(nn[2]-1)]\n  \n  # Crea una consulta\n  q &lt;- make_query(\n    template = \"{text}\\n{prompt}\",\n    text = ll,\n    prompt = \"Utilizando las instrucciones anteriores como referencia, retorna una tabla con tres variables -grupo, diputado, status- separada por ; con los datos del texto para devolver solo la tabla con los datos extra√≠dos: Grupo;diputado;status. OUTPUT: grupo;diputado;status\",\n    system = \"Eres un modelo experto en extracci√≥n de atributos de un texto. A continuaci√≥n se le proporciona un texto con informaciones sobre personas que han asistido a los plenos de debates del congreso de diputados de Per√∫. Los nombres se encuentran divididos en tres columnas. La informaci√≥n de cada diputado aparece como GRUPO APELLIDOS, NOMBRES STATUS, donde Grupo es el grupo parlamentario a que pertenece, Apellidos son los apellidos de la persona en cuesti√≥n, Nombres contiene los nombres de la persona y STATUS corresponde si ha estado presente (PRE), ausente (aus) o licenciado (LO/LE), fallecido (F), en la Junta de Portavoces (JP). NUNCA introduzca comentarios m√°s all√° del formato de salida deseado.\",\n    examples = eje)\n  \n  # Realiza la consulta\n  out &lt;- query(q, \n               model = modelo, \n               screen = F, \n               output = \"data.frame\",\n               verbose = F,\n               model_params = list(\n                 seed=123,\n                 temperature=0))\n  \n  # Convierte la salida en un data.frame\n  la &lt;- paste(out$response, collapse=\"\\n\")\n  la &lt;- read_delim(la, delim=\";\", \n                   col_names = F,\n                   show_col_types=F)\n  \n  # A√±ade el id del documento\n  la$doc &lt;- tx$doc_id[i]\n  \n  # Acumula los resultados\n  d &lt;- rbind(d, la)\n\n}\n\n# Muestra los resultados\nreactable(d, \n          sortable = T, \n          resizable = T)\n\n\n\n\n\n\n\nComo vemos, el modelo ha sido capaz de identificar 260 observaciones para tres variables, 130 para cada uno de los dos textos. Esa informaci√≥n ya est√° lista para ser analizada. Le he a√±adido tambi√©n el nombre del archivo original, que me permite identificar a qu√© sesi√≥n, fecha y documento .pdf pertenece cada asistencia."
  },
  {
    "objectID": "S_1_IntroR.html",
    "href": "S_1_IntroR.html",
    "title": "Introducci√≥n al R",
    "section": "",
    "text": "¬øPor qu√© usar R? Mira este video corto sobre las razones por las que aprender R y responde un cuestionario sobre las ideas principales cubiertas en el video.\n\nOtro video en espa√±ol"
  },
  {
    "objectID": "S_1_IntroR.html#qu√©-es-el-r",
    "href": "S_1_IntroR.html#qu√©-es-el-r",
    "title": "Introducci√≥n al R",
    "section": "",
    "text": "¬øPor qu√© usar R? Mira este video corto sobre las razones por las que aprender R y responde un cuestionario sobre las ideas principales cubiertas en el video.\n\nOtro video en espa√±ol"
  },
  {
    "objectID": "S_1_IntroR.html#qu√©-es-el-rstudio",
    "href": "S_1_IntroR.html#qu√©-es-el-rstudio",
    "title": "Introducci√≥n al R",
    "section": "¬øQu√© es el RStudio?",
    "text": "¬øQu√© es el RStudio?\nRSudio es un entorno de desarrollo integrado (IDE) para R. Es un programa que te permite escribir y ejecutar c√≥digo de R de manera m√°s eficiente y efectiva.\nEl video abajo te dar√° una introducci√≥n a RStudio y explicar√° sus principales caracter√≠sticas."
  },
  {
    "objectID": "S_1_IntroR.html#matem√°tica-b√°sica-en-r",
    "href": "S_1_IntroR.html#matem√°tica-b√°sica-en-r",
    "title": "Introducci√≥n al R",
    "section": "Matem√°tica b√°sica en R",
    "text": "Matem√°tica b√°sica en R\n\nOperadores aritm√©ticos\nEn R, puedes realizar operaciones matem√°ticas b√°sicas como suma, resta, multiplicaci√≥n y divisi√≥n. Los operadores aritm√©ticos b√°sicos en R son:\n\n+ para la suma\n- para la resta\n* para la multiplicaci√≥n\n/ para la divisi√≥n\n^ para la potenciaci√≥n\n\nEl R trabaja como una calculadora. Solo escribe la operaci√≥n y ejecuta el c√≥digo en un script o en la consola (fragmento de c√≥digo) para ver los resultados. Por ejemplo, en el fragmento de c√≥digo a continuaci√≥n escribe 2+2 y, luego, haz clic en ‚ÄúEjecutar c√≥digo‚Äù:\nEl bot√≥n ‚ÄúEjecutar c√≥digo (Run code)‚Äù simula R y ejecuta el comando en un ‚Äúentorno amigable para el usuario‚Äù. El resultado es 4. Ahora, prueba una nueva f√≥rmula en la ventana de c√≥digo: 2^4:\nEl s√≠mbolo ‚Äú^‚Äù representa el signo exponencial. Por lo tanto, 16 es el resultado de 2 elevado a la 4.\nLas reglas aritm√©ticas tambi√©n se aplican para el orden de las operaciones en R. Las multiplicaciones y divisiones se realizan primero, solo despu√©s las sumas y restas.\nIntenta la siguiente f√≥rmula: 100/4+1 en el fragmento de c√≥digo:\nEl resultado es 100/4 = 25 y, luego, 25+1 = 26. Ahora, prueba esto: 100/(4+1). ¬øQu√© resultado deber√≠amos esperar?\n¬øQu√© mud√≥? Cuando usamos par√©ntesis ‚Äò()‚Äô o corchetes ‚Äò{}‚Äô, la operaci√≥n dentro de estos s√≠mbolos se resuelve primero. Por lo tanto, en este caso, 100/(4+1) = 100/5 = 20."
  },
  {
    "objectID": "S_1_IntroR.html#vectores",
    "href": "S_1_IntroR.html#vectores",
    "title": "Introducci√≥n al R",
    "section": "Vectores",
    "text": "Vectores\nLos vectores o variables son conjuntos de valores. Una lista de nombres, la edad de los estudiantes en la clase, las calificaciones obtenidas en todos los cursos, pueden representarse en vectores.\nCreemos una variable llamada edad con los valores 18, 19, 24, 35 y 40. En cualquier clase de matem√°ticas, esto se representar√≠a como un conjunto, siendo edad={18,19,24,35,40}. R funciona de una manera muy similar: un nombre, un s√≠mbolo para representar una asignaci√≥n y la definici√≥n de los valores que contendr√° este nombre.\nEl s√≠mbolo de asignaci√≥n en R es ‚Äú&lt;-‚Äù. Por lo tanto, si creo una nueva variable, solo necesito decir, por ejemplo, x &lt;- 1. Esta expresi√≥n crea un nuevo vector (variable) llamado x con el valor de 1. Escribe x &lt;- 1 en el fragmento de c√≥digo a continuaci√≥n:\nAhora, escribe x &lt;- 1 en el fragmento de c√≥digo a continuaci√≥n y, en la l√≠nea siguiente, solo escribe x para recuperar el valor de x:\nPodr√°s ver que nada aparece en el primer fragmento de c√≥digo, pero el resultado ‚Äò[1] 1‚Äô se presenta en el segundo. La raz√≥n es que, al escribir solo x, le pedimos a R que muestre todos los valores de x. En este caso, solo 1.\nEl R tambi√©n funciona con otros tipos de datos, como texto y fechas. Podemos crear una nueva variable con texto. Creemos una variable/vector llamada ciudad y asignemos ‚ÄúSevilla‚Äù a ella. Recuerda usar el s√≠mbolo de asignaci√≥n ‚Äò&lt;-‚Äô:\n\n\nCode\ncity &lt;- \"Sevilla\"\n\n\nAhora, podemos crear una nueva variable llamada hoy con la fecha de hoy:\n\n\nCode\nhoy &lt;- Sys.Date()\n\n\nHasta ahora, solo trabajamos con un valor para cada vector. Sin embargo, en el an√°lisis de datos reales, las variables contienen miles o incluso millones de valores. Para hacerlo, necesitamos usar la funci√≥n ‚Äòc()‚Äô que concatena o combina valores en una misma variable. Las funciones son una parte fundamental de R. Profundizaremos m√°s en ellas en las pr√≥ximas secciones.\nPor ejemplo, podemos asignar los valores de uno a cuatro a una variable llamada a con el siguiente c√≥digo: ‚Äúa &lt;- c(1,2,3,4)‚Äù o los nombres de las capitales de provincia de Andaluc√≠a con ‚Äúa &lt;- c(‚ÄùHuelva‚Äù, ‚ÄúC√°diz‚Äù, ‚ÄúSevilla‚Äù, ‚ÄúM√°laga‚Äù, ‚ÄúGranada‚Äù, ‚ÄúC√≥rdoba‚Äù, ‚ÄúJa√©n‚Äù, ‚ÄúAlmer√≠a‚Äù)‚Äú.\nPuedes ver que los nombres o textos siempre est√°n entre comillas. Los n√∫meros no.\nAhora, es tu turno. Crea una variable llamada ‚Äòedad‚Äô con los valores 0, 1, 2, 3, 5, 8, 13, 21. Recuerda que los valores deben estar entre par√©ntesis y separados por comas.\n\n\nCode\nedad &lt;- c(0, 1, 2, 3, 5, 8, 13, 21)\n\n\nAhora, creemos un vector llamado ‚Äòiber‚Äô que contenga los nombres de los pa√≠ses ubicados en la Pen√≠nsula Ib√©rica (Portugal, Espa√±a, Andorra y Francia - algunas provincias):\n\n\nCode\niber &lt;- c(\"Portugal\", \"Spain\", \"Andorra\", \"France\")\n\n\nOtra gran caracter√≠stica de los vectores es la capacidad de realizar operaciones con ellos muy f√°cilmente. Imagina un vector a con valores 1, 2, 3, 4 y quiero multiplicarlos por 10. Solo necesito multiplicar a por 10 y la operaci√≥n se aplica a todos los elementos del vector. Creemos un vector a con los valores anteriores y, luego, multipliqu√©moslo por 10:\n\n\nCode\na &lt;- c(1, 2, 3, 4)\n\na * 10\n\n\n[1] 10 20 30 40\n\n\nPodemos ver que el resultado fue 10, 20, 30 y 40. No fue necesario multiplicar cada elemento del vector para obtener los resultados. Cuando se trata de millones de valores, esta caracter√≠stica es realmente √∫til.\nLo mismo ocurre cuando intentamos hacer operaciones aritm√©ticas entre variables. Creemos dos variables a, con 1,2,3,4, y b, con 10, 20, 30, y 40. Luego, sum√©moslas:\n\n\nCode\na &lt;- c(1, 2, 3, 4)\nb &lt;- c(10, 20, 30, 40)\n\na + b\n\n\n[1] 11 22 33 44\n\n\nAhora, crea las mismas dos variables y divide b por a:\n\n\nCode\na &lt;- c(1, 2, 3, 4)\nb &lt;- c(10, 20, 30, 40)\n\nb / a\n\n\n[1] 10 10 10 10\n\n\nFinalmente, podemos combinar valores de dos vectores diferentes. Imagina que tenemos una variable (cyl) con las capitales de Castilla y Le√≥n y otra con las de Andaluc√≠a (adl). Quiero combinar las dos en la variable ‚Äúcapitales‚Äù. Solo necesito usar la funci√≥n c() para combinar las dos de la misma manera que la us√© para combinar valores individuales. Intenta hacerlo por ti mismo (y recuerda un poco de geograf√≠a espa√±ola) e inspecciona los resultados:\n\n\nCode\ncyl &lt;- c(\"√Åvila\",\"Burgos\",\"Le√≥n\",\"Palencia\",\"Salamanca\",\"Segovia\",\"Soria\",\"Valladolid\",\"Zamora\")\n\nadl &lt;- c(\"Almer√≠a\",\"C√°diz\",\"C√≥rdoba\",\"Granada\",\"Huelva\",\"Ja√©n\",\"M√°laga\",\"Sevilla\")\n\ncapitales &lt;- c(cyl, adl)\n\ncapitales\n\n\n [1] \"√Åvila\"      \"Burgos\"     \"Le√≥n\"       \"Palencia\"   \"Salamanca\" \n [6] \"Segovia\"    \"Soria\"      \"Valladolid\" \"Zamora\"     \"Almer√≠a\"   \n[11] \"C√°diz\"      \"C√≥rdoba\"    \"Granada\"    \"Huelva\"     \"Ja√©n\"      \n[16] \"M√°laga\"     \"Sevilla\""
  },
  {
    "objectID": "S_1_IntroR.html#operadores-relacionales-y-l√≥gicos",
    "href": "S_1_IntroR.html#operadores-relacionales-y-l√≥gicos",
    "title": "Introducci√≥n al R",
    "section": "Operadores relacionales y l√≥gicos",
    "text": "Operadores relacionales y l√≥gicos\nQuiz√°s la tarea m√°s importante en el an√°lisis de datos es la comparaci√≥n. ¬øCu√°les son los pa√≠ses m√°s ricos del mundo? ¬øQui√©n gana m√°s de 10 mil euros al mes? ¬øLos votantes de Madrid apoyaron m√°s al PP que los de Sevilla? ¬øEs el salario mediano de las mujeres el mismo que el de los hombres? Estas son preguntas suelen requerir la comparaci√≥n de valores para ser respondidas.\nEl R emplea una serie de operadores relacionales para permitir a los analistas extraer respuestas de los datos. Imagina dos variables, una con los votos al PP en dos ciudades espa√±olas en las √∫ltimas cuatro elecciones generales (noviembre 2019, abril 2019, junio 2016 y diciembre 2015): ciudad_A = {29.93,23.53,40.82,36.77}, ciudad_B = {29.88,24.11,41.1,36.15}. Solo mirando los n√∫meros es dif√≠cil decidir cu√°l de las dos ha mostrado m√°s apoyo al PP en todo el per√≠odo.\nLa estad√≠stica nos ayuda con esto proporcionando herramientas para la s√≠ntesis y comparaci√≥n. Creemos estos dos vectores en R y, luego, probemos la hip√≥tesis de que la ciudad A present√≥ un apoyo m√°s fuerte en promedio en comparaci√≥n con la ciudad B. Necesitamos usar la funci√≥n mean() y el operador l√≥gico ‚Äú&gt;‚Äù mayor que para realizar la prueba.\n\n\nCode\ncity_A &lt;- c(29.93,23.53,40.82,36.77)\n\ncity_B &lt;- c(29.88,24.11,41.1,36.15)\n\nmean(city_A) &gt; mean(city_B)\n\n\n[1] FALSE\n\n\nLos resultados muestran que, por una fracci√≥n de porcentaje, la hip√≥tesis es FALSA. La ciudad B es la que ha mostrado un mayor apoyo al PP en las √∫ltimas cuatro elecciones generales.\nLos operadores relacionales nos ayudan a probar hip√≥tesis, seleccionar informaci√≥n y comparar valores:\n\na == b, es a igual b?\na &gt; b, es a mayor que b? o a &gt;=, es a mayor o igual a b?\na &lt; b, es a menor que b? o a &lt;=, es a menor o igual a b?\na != b, es a diferente de b\na %in% b, a contiene b (o los valores de b est√°n contenidos en a)\n\nLos operadores relacionales pueden ser utilizados para filtrar datos o indicar casos que se ajustan a ciertas condiciones. Por ejemplo, en el c√≥digo a continuaci√≥n filtramos todos los valores de la variable x que est√°n por encima de 75:\n\n\nCode\nx &lt;- c(1:100)\n\nx[x&gt;75]\n\n\n [1]  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n[20]  95  96  97  98  99 100\n\n\nOperadores l√≥gicos, por otro lado, ayudan a establecer condiciones combinadas para la selecci√≥n o filtrado:\n\n! - NOT - x[!x&gt;75] - recupera todos los valores menores o iguales a 75.\n& - AND - x[x&gt;10 & x&lt;50] - selecciona los valores entre 11 y 49.\n| - OR - x[x&gt;10 | x&lt;50] - selecciona todos los valores.\n\nInt√©ntalo tu. Ahora x corresponde a los a√±os entre 1992 y 2021. Selecciona solo aquellos a√±os de 1992 a 2000 y de 2015 a 2021.\n\n\nCode\nx &lt;- c(1992:2021)\n\n\n\n\nCode\nx &lt;- c(1992:2021)\n\nx[x&lt;=2000 | x&gt;=2015]\n\n\n [1] 1992 1993 1994 1995 1996 1997 1998 1999 2000 2015 2016 2017 2018 2019 2020\n[16] 2021\n\n\nFinalmente, selecciona solo los a√±os entre 1995 y 2002.\n\n\nCode\nx &lt;- c(1992:2021)\n\n\n\n\nCode\nx &lt;- c(1992:2021)\n\nx[x&gt;1994 & x&lt;2003]\n\n\n[1] 1995 1996 1997 1998 1999 2000 2001 2002\n\n\nFinalmente, selecciona todos los casos por encima de 2000, excepto para 2005 a 2007.\n\n\nCode\nx &lt;- c(1992:2021)\n\n\n\n\nCode\nx &lt;- c(1992:2021)\n\nx[x&gt;2000 & !x %in% c(2005,2006,2007)]\n\n\n [1] 2001 2002 2003 2004 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018\n[16] 2019 2020 2021"
  },
  {
    "objectID": "S_1_IntroR.html#tipos-de-dato-b√°sicos-en-r",
    "href": "S_1_IntroR.html#tipos-de-dato-b√°sicos-en-r",
    "title": "Introducci√≥n al R",
    "section": "Tipos de dato b√°sicos en R",
    "text": "Tipos de dato b√°sicos en R\nLa informaci√≥n puede ser codificada de maneras muy diferentes. Normalmente, asociamos la palabra datos con n√∫meros, pero esta identificaci√≥n es falsa por la exclusi√≥n de una diversidad de otros formatos y sistemas de codificaci√≥n empleados en la representaci√≥n de atributos del mundo emp√≠rico en s√≠mbolos. Tal enfoque cl√°sico de los tipos de datos tiene una falla importante: no incluye informaci√≥n que no est√° codificada en texto. Los modelos de IA, por ejemplo, utilizan videos, sonidos o im√°genes como fuente para sus an√°lisis. Suelen traducir colores o formas en texto antes de realizar cualquier c√°lculo. El n√∫mero 5, una imagen, una m√∫sica, un poema o un video, todos representan diferentes tipos de datos.\n\nTipos de vector en R\nEn esta subsecci√≥n, exploramos los tipos de datos m√°s b√°sicos en R. Representan tipos alternativos de vectores (o variables) utilizados para almacenar informaci√≥n y procesarla durante el an√°lisis.\n\nCharacter - son vectores que almacenan informaci√≥n de texto. Cualquier tipo de texto, desde una simple palabra hasta libros enteros, puede ser almacenado en vectores de caracteres. Simplemente escribe ‚Äòprint(a)‚Äô despu√©s de la definici√≥n de la variable a a continuaci√≥n para inspeccionar los resultados:\n\n\n\nCode\na &lt;- c(\"Este es una variable de tipo caracter.\",\"Guarda solamente texto.\")\n\n\n\n\nCode\na &lt;- c(\"Este es una variable de tipo caracter.\",\"Guarda solamente texto.\")\n\nprint(a)\n\n\n[1] \"Este es una variable de tipo caracter.\"\n[2] \"Guarda solamente texto.\"               \n\n\n\nFactor - es un tipo de variable utilizado para representar datos categ√≥ricos y ordinales. La mayor√≠a de las encuestas utilizan c√≥digos num√©ricos como sustitutos de nombres para evitar errores de escritura y ahorrar espacio en disco. El vector de factor en R permite definir las etiquetas correspondientes para cada valor num√©rico. Por ejemplo, tenemos un vector a con valores repetidos de 1,2,3,4 correspondientes a ‚ÄúDemocracia‚Äù, ‚ÄúAutocracia‚Äù, ‚ÄúSemi-democracia‚Äù y ‚ÄúTotalitarismo‚Äù. Cuando analizamos los datos, preferimos ver las etiquetas en lugar de n√∫meros sin sentido. Factor hace precisamente eso en R.\n\nPrimero, presiona el bot√≥n ‚ÄúRun code‚Äù para ver los resultados. Probablemente ver√°s un conjunto de n√∫meros como se declara en el vector a a continuaci√≥n.\nLuego, escribe ‚Äòprint(b)‚Äô al final del fragmento de c√≥digo a continuaci√≥n y, luego, presiona ‚Äúrun code‚Äù:\n\n\n\n\nCode\n# Declara una variable a con 1,2,3, y 4 como valores\na &lt;- c(1,1,2,3,4,2,1,4,3,1,4,1,3,3,2,1,4,1)\n\n# Inspecciona los resultados de a\nprint(a)\n\n\n [1] 1 1 2 3 4 2 1 4 3 1 4 1 3 3 2 1 4 1\n\n\nCode\n# convierte ka variable en un factor, \n# asociando etiquetas a cada valor\nb &lt;- factor(x = a, \n            levels = c(1,2,3,4), \n            labels = c(\"Democracia\", \n                       \"Autocracia\", \n                       \"Semidemocracia\", \n                       \"Totalitarismo\"))\n\n# Inspecciona los resultados para b\n\n\n\n\nCode\n# Declara una variable a con 1,2,3, y 4 como valores\na &lt;- c(1,1,2,3,4,2,1,4,3,1,4,1,3,3,2,1,4,1)\n\n# Inspecciona los resultados de a\nprint(a)\n\n\n [1] 1 1 2 3 4 2 1 4 3 1 4 1 3 3 2 1 4 1\n\n\nCode\n# convierte ka variable en un factor, \n# asociando etiquetas a cada valor\nb &lt;- factor(x = a, \n            levels = c(1,2,3,4), \n            labels = c(\"Democracia\", \n                       \"Autocracia\", \n                       \"Semidemocracia\", \n                       \"Totalitarismo\"))\n\n# Inspecciona los resultados para b\nprint(b)\n\n\n [1] Democracia     Democracia     Autocracia     Semidemocracia Totalitarismo \n [6] Autocracia     Democracia     Totalitarismo  Semidemocracia Democracia    \n[11] Totalitarismo  Democracia     Semidemocracia Semidemocracia Autocracia    \n[16] Democracia     Totalitarismo  Democracia    \nLevels: Democracia Autocracia Semidemocracia Totalitarismo\n\n\n¬øQu√© ha cambiado? Como puedes ver, ahora, el vector b reemplaza los n√∫meros con sus respectivas etiquetas o tipos de r√©gimen.\nIntenta calcular la frecuencia de los reg√≠menes en la variable b escribiendo el comando ‚Äòtable(b)‚Äô en el fragmento de c√≥digo a continuaci√≥n:\n\n\nCode\n# Declara una variable a con 1,2,3, y 4 como contenido\na &lt;- c(1,1,2,3,4,2,1,4,3,1,4,1,3,3,2,1,4,1)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n [1] 1 1 2 3 4 2 1 4 3 1 4 1 3 3 2 1 4 1\n\n\nCode\n# convierte la variable en un factor, \n# asociando etiquetas a cada valor\nb &lt;- factor(x = a, \n            levels = c(1,2,3,4), \n            labels = c(\"Democracia\", \n                       \"Autocracia\", \n                       \"Semi-democracia\", \n                       \"Totalitarismo\"))\n\n# Calcula la frecuencia usando table(b)\n\n\n\n\nCode\n# Declara una variable a con 1,2,3, y 4 como contenido\na &lt;- c(1,1,2,3,4,2,1,4,3,1,4,1,3,3,2,1,4,1)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n [1] 1 1 2 3 4 2 1 4 3 1 4 1 3 3 2 1 4 1\n\n\nCode\n# convierte la variable en un factor, \n# asociando etiquetas a cada valor\nb &lt;- factor(x = a, \n            levels = c(1,2,3,4), \n            labels = c(\"Democracia\", \n                       \"Autocracia\", \n                       \"Semi-democracia\", \n                       \"Totalitarismo\"))\n\n# Calcula la frecuencia usando table(b)\ntable(b)\n\n\nb\n     Democracia      Autocracia Semi-democracia   Totalitarismo \n              7               3               4               4 \n\n\n¬øCu√°l es el tipo de r√©gimen m√°s com√∫n? ¬øY cu√°l es el menos com√∫n?\n¬°Excelente! Acabas de hacer tu primera tabla de frecuencias.\n\nNOTA: Revisa el c√≥digo anterior. Puedes ver que hay una secuencia clara en √©l. En primer lugar, necesitamos decirle a R que el vector a contiene esos valores. En segundo lugar, inspeccionamos el contenido de a. En tercer lugar, creamos un nuevo vector llamado b a trav√©s de la conversi√≥n de los valores de a a un vector con etiquetas categ√≥ricas. Finalmente, usamos ‚Äòtable(b)‚Äô para calcular la tabla de frecuencias de todas las categor√≠as en el vector b. Si no hubi√©ramos declarado a, en primer lugar, todas las instrucciones siguientes no funcionar√≠an. A partir de ahora, presta atenci√≥n a la secuencia del c√≥digo. Ser√° MUY importante en el futuro.\n\n\nNumeric - representa vectores (variables) con datos continuos. Tambi√©n puede almacenar informaci√≥n discreta, pero trata estos datos como si fueran continuos.\n\nAbajo, creamos otro vector con el nombre a, pero ahora, tiene algunos n√∫meros (9.5,19.5,30.5, y 40.5) en √©l. Luego, inspeccionamos su contenido. Una vez hecho esto, por favor, realiza los siguientes pasos:\n\nPrimero, escribe sum(a) para sumar todos los valores de a.\nLuego, multiplica los valores de a por 10 para refrescar algunos de los ejemplos de la √∫ltima sesi√≥n.\nFinalmente, haz clic en ‚ÄòRun Code‚Äô para ejecutar el c√≥digo:\n\n\n\nCode\n# Declara una variable a con 9.5,19.5,30.5, y 40.5 como contenido\na &lt;- c(9.5,19.5,30.5,40.5)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n[1]  9.5 19.5 30.5 40.5\n\n\nCode\n# Suma todos los valores empleando la funci√≥n sum()\n\n\n# Repaso: multiplica todos los valores de a por 10\n\n\n\n\nCode\n# Declara una variable a con 9.5,19.5,30.5, y 40.5 como contenido\na &lt;- c(9.5,19.5,30.5,40.5)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n[1]  9.5 19.5 30.5 40.5\n\n\nCode\n# Suma todos los valores empleando la funci√≥n sum()\nsum(a)\n\n\n[1] 100\n\n\nCode\n# Repaso: multiplica todos los valores de a por 10\na * 10\n\n\n[1]  95 195 305 405\n\n\n\nInteger - son vectores utilizados para contener n√∫meros discretos. Edades, el n√∫mero de hijos, p√°ginas en un libro, todos estos son ejemplos de cifras discretas. Difieren de numeric solo porque son redondos, es decir, no tienen fracciones.\n\nEl c√≥digo a continuaci√≥n es muy similar al anterior. Solo hay tres diferencias:\n\nel vector a ahora contiene solo enteros (n√∫meros discretos);\nen lugar de sum(a) debes usar mean(a) para calcular el valor promedio de a y;\nen lugar de multiplicar por 10, debes calcular el cuadrado de los valores de a.\n\n\n\nCode\n# Declara una variable a con 10,20,30, y 40 como contenido\na &lt;- c(10,20,30,40)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n[1] 10 20 30 40\n\n\nCode\n# Encuentra el valor promedio de a usando la funci√≥n mean()\n\n\n\n\nCode\n# Declara una variable a con 10,20,30, y 40 como contenido\na &lt;- c(10,20,30,40)\n\n# Inspecciona los resultados para a\nprint(a)\n\n\n[1] 10 20 30 40\n\n\nCode\n# Encuentra el valor promedio de a usando la funci√≥n mean()\nmean(a)\n\n\n[1] 25\n\n\n\nNOTA: En todos los fragmentos de c√≥digo, podemos ver que hay l√≠neas de texto coloreadas en verde. Estas l√≠neas comienzan con el s√≠mbolo de almohadilla ‚Äò#‚Äô. Todas las l√≠neas que comienzan (o contin√∫an) con # en R se consideran comentarios. Este recurso es valioso para hacer un seguimiento de lo que estamos haciendo y de lo que queremos lograr con nuestro c√≥digo.\nExisten dos tipos de comentarios en R:\n\nComentarios de l√≠nea completa:\n# El siguiente comando calcula la media de la variable a.\nmean(a)\nComentarios en l√≠nea:\nmean(a) # este comando calcula la media de la variable a\n\nPuedes usar ambos para hacer un seguimiento de tus an√°lisis. Depende principalmente de tu estilo y del detalle del comentario que deseas lograr en tu c√≥digo.\n\n\nDate - los vectores de fecha y hora almacenan fechas y horas. Son particularmente √∫tiles para calcular diferencias de tiempo. El ejemplo a continuaci√≥n asigna la hora y la fecha actual a dos variables, a y b, con una diferencia de 3 segundos. Usando la funci√≥n ‚Äòprint()‚Äô, se pueden inspeccionar los resultados. Al final, podemos verificar si el lapso de tiempo entre las dos variables es realmente de tres segundos restando a de b.\n\n\n\nCode\n# Guarda la fecha y hora actuales en la variable a\na &lt;- Sys.time()\n\n# Pone el R \"a dormir\" (no hacer nada) por 3 segundos\nSys.sleep(3)\n\n# Guarda la fecha y hora actuales en la variable b\nb &lt;- Sys.time()\n\n# Inspecciona el valor de a\nprint(a)\n\n\n[1] \"2025-01-16 22:07:09 CET\"\n\n\nCode\n# Inspecciona el valor de b\nprint(b)\n\n\n[1] \"2025-01-16 22:07:12 CET\"\n\n\nCode\n# Repaso: subtrae a de b.\n\n\n\n\nCode\n# Guarda la fecha y hora actuales en la variable a\na &lt;- Sys.time()\n\n# Pone el R \"a dormir\" (no hacer nada) por 3 segundos\nSys.sleep(3)\n\n# Guarda la fecha y hora actuales en la variable b\nb &lt;- Sys.time()\n\n# Inspecciona el valor de a\nprint(a)\n\n\n[1] \"2025-01-16 22:07:12 CET\"\n\n\nCode\n# Inspecciona el valor de b\nprint(b)\n\n\n[1] \"2025-01-16 22:07:15 CET\"\n\n\nCode\n# Repaso: subtrae a de b.\nb-a\n\n\nTime difference of 3.007159 secs\n\n\n\nLogical - son vectores que almacenan valores l√≥gicos. Por ejemplo, si creas una variable de prueba para mayores de 65 a√±os, puedes marcar cada valor de esta variable con FALSE o TRUE.\n\n\n\nCode\n# Guarda valores verdaderos o falsos en el\n# vector a\na &lt;- c(TRUE, TRUE,FALSE, TRUE, FALSE)\n\n# Inspecciona los valores de a\nprint(a)\n\n\n[1]  TRUE  TRUE FALSE  TRUE FALSE\n\n\nCode\n# Tambi√©n puedes convertir valores a \n# verdadero o falso empleando condiciones\n\n# Crea una variable a con edades\na &lt;- c(66,45,33, 67,89,22)\n\n# Averigua cuales valores de a \n# son iguales o superiores a 65 \n# y los guarda en el vector b\nb &lt;- a&gt;=65\n\n# Inspecciona los resultados de b\nprint(b)\n\n\n[1]  TRUE FALSE FALSE  TRUE  TRUE FALSE\n\n\n\n\n¬øDe qu√© tipo es mi vector?\nPodemos verificar el tipo de un vector utilizando la funci√≥n iniciada con is. y el tipo. Son los siguientes:\n\nis.character()\nis.factor()\nis.numeric()\nis.integer()\nis.logical()\n\nOtro modo, m√°s general, de averiguar el tipo de dato consisten en emplear la funci√≥n class(). Pero en lugar de dar TRUE o FALSE, la funci√≥n class() devuelve el tipo de datos.\nEn el siguiente fragmento de c√≥digo, verificamos si el vector a es num√©rico y, si no lo es, averiguamos a qu√© tipo de datos pertenece:\n\n\nCode\n# Guarda valores en el vector a\na &lt;- c(\"1\",\"2\",\"3\",\"4\",\"5\")\n\n# Averigua si es una variable num√©rica\n\n\n# Determina de qu√© tipo es la variable\n\n\n\n\nCode\n# Guarda valores en el vector a\na &lt;- c(\"1\",\"2\",\"3\",\"4\",\"5\")\n\n# Averigua si es una variable num√©rica\nis.numeric(a)\n\n\n[1] FALSE\n\n\nCode\n# Determina de qu√© tipo es la variable\nclass(a)\n\n\n[1] \"character\"\n\n\n\n\nConversi√≥n de tipos de datos\nEn muchas ocasiones, los datos muestran errores e imperfecciones. En algunos casos, los n√∫meros se codifican como texto. O las variables de texto deben convertirse en categ√≥ricas.\nLas funciones para convertir vectores entre tipos de datos son:\n\nas.character() - convierte cualquier formato en un vector de caracteres.\nas.numeric() - convierte en num√©rico. Esta funci√≥n es m√°s restrictiva, ya que solo los n√∫meros representados como texto o factores pueden convertirse en n√∫meros. Una variable x &lt;- c(‚Äú1‚Äù,‚Äú2‚Äù,‚Äú3‚Äù,‚Äú4‚Äù) devolver√≠a c(1,2,3,4). Un factor x &lt;- c(‚ÄúBajo‚Äù, ‚ÄúMedio‚Äù, ‚ÄúAlto‚Äù) devolver√≠a c(1,2,3).\nas.integer() - convierte en entero. Exactamente igual que la funci√≥n anterior. La √∫nica diferencia radica en que esta funci√≥n solo devuelve n√∫meros redondos. Una variable x &lt;- c(‚Äú1.‚Äù,‚Äú2.3‚Äù,‚Äú3.4‚Äù,‚Äú4.3‚Äù) devolver√≠a c(1,2,3,4).\nas.logical() - convierte ceros en FALSE y n√∫meros positivos en TRUE.\nas.Date() - convierte texto formateado como fechas en vectores de fecha que se pueden emplear para comparar fechas y establecer diferencias de tiempo.\nas.factor() - convierte en factor. Tanto los n√∫meros como el texto pueden servir como factores. Por lo tanto, la conversi√≥n es directa.\n\nEjercicio 1. De texto a n√∫mero. Convierte la variable a de car√°cter a num√©rico y entero. Tras cada conversi√≥n, verifica si la conversi√≥n fue exitosa.\n\n\nCode\n# Guarda n√∫meros entre comillas en el vector a\na &lt;- c(\"1\",\"2\",\"3\",\"4\",\"5\")\n\n# Convierte a  num√©rico\na &lt;- as.numeric(a)\n\n# Averigua si a es num√©rico\n\n# Convierte a a integer (entero)\na &lt;- as.integer(a)\n\n# Averigua si a es integer \n\n\n\n\nCode\n# Guarda n√∫meros entre comillas en el vector a\na &lt;- c(\"1\",\"2\",\"3\",\"4\",\"5\")\n\n# Convierte a  num√©rico\na &lt;- as.numeric(a)\n\n# Averigua si a es num√©rico\nis.numeric(a)\n\n\n[1] TRUE\n\n\nCode\n# Convierte a a integer (entero)\na &lt;- as.integer(a)\n\n# Averigua si a es integer \nis.integer(a)\n\n\n[1] TRUE\n\n\nEjercicio 2. De n√∫mero a texto. Tambi√©n puedes convertir n√∫meros en texto f√°cilmente. Convierte la variable a de num√©rica a car√°cter. Tras cada conversi√≥n, verifica si la conversi√≥n fue exitosa.\n\n\nCode\n# Crea el vector a con n√∫meros de 1 a 5\na &lt;- c(1:5)\n\n# Convierte a character\na &lt;- as.character(a)\n\n# Averigua si a es un vector de tipo character\n\n\n\n\nCode\n# Crea el vector a con n√∫meros de 1 a 5\na &lt;- c(1:5)\n\n# Convierte a character\na &lt;- as.character(a)\n\n# Averigua si a es un vector de tipo character\nis.character(a)\n\n\n[1] TRUE\n\n\nEjercicio 3. De texto a fecha. Si una variable solo contiene fechas representadas como texto, los usuarios no ser√°n capaces de calcular diferencias de tiempo. Por eso es importante convertir la informaci√≥n del calendario en un tipo de fecha adecuado para obtener todas las ventajas de poder establecer m√©tricas de tiempo en R. Convierte la variable a de car√°cter a fecha. Tras cada conversi√≥n, verifica si la conversi√≥n fue exitosa.\n\n\nCode\n# Guarda fechas en el vector a como texto\na &lt;- c(\"2001-01-01\",\"2022-07-15\",\"2013-12-15\",\"2019-07-06\",\"2015-05-05\")\n\n# Convierte a Date (fecha)\na &lt;- as.Date(a)\n\n# Puesto que no hay una funci√≥n \n# is.Date, averigua la clase de a\n\n\n\n\nCode\n# Guarda fechas en el vector a como texto\na &lt;- c(\"2001-01-01\",\"2022-07-15\",\"2013-12-15\",\"2019-07-06\",\"2015-05-05\")\n\n# Convierte a Date (fecha)\na &lt;- as.Date(a)\n\n# Puesto que no hay una funci√≥n \n# is.Date, averigua la clase de a\nclass(a)\n\n\n[1] \"Date\"\n\n\nEjercicio 4. De texto a factor. En el caso de que queramos trabajar con categor√≠as, pero la variable original sea un n√∫mero o un car√°cter, necesitamos convertirla en un factor. El siguiente c√≥digo convierte la variable a de car√°cter a factor. Comprueba si la conversi√≥n cre√≥ un vector de factores.\n\n\nCode\n# Guarda valores num√©ricos en el vector a\na &lt;- c(1,2,1,3,4,1,2,1,1,3,4,2,2)\n\n# Convierte a factor\na &lt;- factor(a, levels=c(1,2,3,4), labels = c(\"Coffee\",\"Tea\",\"Water\",\"Juice\"))\n\n# Averigua si a es un factor\n\n\n\n\nCode\n# Guarda valores num√©ricos en el vector a\na &lt;- c(1,2,1,3,4,1,2,1,1,3,4,2,2)\n\n# Convierte a factor\na &lt;- factor(a, levels=c(1,2,3,4), labels = c(\"Coffee\",\"Tea\",\"Water\",\"Juice\"))\n\n# Averigua si a es un factor\nis.factor(a)\n\n\n[1] TRUE\n\n\nEjercicio 5. De factor a texto. El √∫ltimo ejemplo convierte factores en texto. A veces solo queremos conservar el texto de la variable y no considerarla como una variable categ√≥rica formal. En esos casos, necesitamos convertir el vector de factor a car√°cter.\n\n\nCode\n# Guarda valores num√©ricos en el vector a\na &lt;- c(1,2,1,3,4,1,2,1,1,3,4,2,2)\n\n# Convierte a um factor\na &lt;- factor(a, levels=c(1,2,3,4), labels = c(\"Coffee\",\"Tea\",\"Water\",\"Juice\"))\n\n# Ahora convierte a character\na &lt;- as.character(a)\n\n# Averigua si a es un vector de character\n\n\n\n\nCode\n# Guarda valores num√©ricos en el vector a\na &lt;- c(1,2,1,3,4,1,2,1,1,3,4,2,2)\n\n# Convierte a um factor\na &lt;- factor(a, levels=c(1,2,3,4), labels = c(\"Coffee\",\"Tea\",\"Water\",\"Juice\"))\n\n# Ahora convierte a character\na &lt;- as.character(a)\n\n# Averigua si a es un vector de character\nis.character(a)\n\n\n[1] TRUE"
  },
  {
    "objectID": "S_1_IntroR.html#tipos-de-dato-avanzados-en-r",
    "href": "S_1_IntroR.html#tipos-de-dato-avanzados-en-r",
    "title": "Introducci√≥n al R",
    "section": "Tipos de dato avanzados en R",
    "text": "Tipos de dato avanzados en R\n\nMatrices\nDe acuerdo con el diccionario de Oxford, una matriz es:\n‚Äúun conjunto rectangular de cantidades o expresiones en filas y columnas que se trata como una sola entidad y se manipula de acuerdo con reglas particulares.‚Äù\nAnalicemos esta definici√≥n en partes:\n\nConjunto rectangular de cantidades o expresiones en filas y columnas\nTratado como una sola entidad\nManipulado de acuerdo con reglas particulares\n\nEn R, las matrices solo usan un tipo de datos: n√∫meros, textos, fechas, etc. En su mayor√≠a, las matrices son num√©ricas y son muy √∫tiles para acelerar el c√°lculo de grandes conjuntos de datos. En ciencias sociales, generalmente empleamos Data Frames (la pr√≥xima subsecci√≥n). Aunque son m√°s lentos, permiten que se presente informaci√≥n de diferentes tipos (textos, n√∫meros, fechas, etc.) en la misma tabla.\n\n\nCode\n# Crea una matriz de 3 l√≠neas x 2 columnas\nmatrix(data = c(2, 3, 4, 5, 6, 7), nrow = 3, ncol = 2)\n\n\n     [,1] [,2]\n[1,]    2    5\n[2,]    3    6\n[3,]    4    7\n\n\nCode\n# Crea una matriz de 2 l√≠neas x 3 columnas\nmatrix(data = c(2, 3, 4, 5, 6, 7), nrow = 2, ncol = 3)\n\n\n     [,1] [,2] [,3]\n[1,]    2    4    6\n[2,]    3    5    7\n\n\n\n\nData Frames (tablas con N l√≠neas x N columnas)\nEste es el tipo de dato m√°s familiar en estudios acad√©micos. Cualquier hoja de c√°lculo de Excel o archivo de datos SPSS se organiza en una tabla caracterizada por un n√∫mero m√∫ltiple de filas y columnas. Por lo general:\n\nL√≠neas representan observaciones o unidades de observaci√≥n. Pueden ser pa√≠ses, entrevistas, partidos, etc.\nColumnas est√°n compuestas por atributos que pertenecen a estas unidades de observaci√≥n. El PIB de un pa√≠s, la edad de una persona en una entrevista de encuesta, el porcentaje de votos en un partido dado, etc.\n\nEn R, un objeto data.frame es una colecci√≥n de vectores (o variables). Por lo tanto, podemos tener un data.frame con las columnas nombre, edad, sexo, etc.\nEl siguiente c√≥digo crea un data.frame con algunas variables:\n\n\nCode\n# Crea vectores para nombres, edades, sexo, y fechas de nacimiento. \nnm &lt;- c(\"Cristina\", \"Rodrigo\", \"John\", \"√Ålvaro\", \"Castelar\",\"Sofia\")\nag &lt;- c(32, 45, 39, 25, 24, 26)\nsx &lt;- c(\"Femenino\",\"Masculino\",\"Masculino\",\"Masculino\",\"Femenino\",\"Femenino\")\nbt &lt;- as.Date(c(\"1990-12-12\",\"1977-11-22\",\"1983-09-15\",\"1997-09-08\",\"1999-02-28\",\"1998-05-27\"))\n\n# Crea un data.frame con dichas variables\ndf &lt;- data.frame(\n                  Name=nm, \n                  Age=ag, \n                  Sex=sx, \n                  Birth=bt)\n\n#Inspecciona las seis primeras l√≠neas del data.frame\nhead(df)\n\n\n      Name Age       Sex      Birth\n1 Cristina  32  Femenino 1990-12-12\n2  Rodrigo  45 Masculino 1977-11-22\n3     John  39 Masculino 1983-09-15\n4   √Ålvaro  25 Masculino 1997-09-08\n5 Castelar  24  Femenino 1999-02-28\n6    Sofia  26  Femenino 1998-05-27\n\n\nNo es com√∫n crear data.frames usando variables. Este ejemplo solo ilustra la estructura de este tipo de objeto. M√°s adelante en el curso, aprenderemos a abrir archivos de datos (Excel, SPSS, CSV, etc.) en R como data.frames. Por ahora, solo necesitamos entender c√≥mo funciona y su estructura b√°sica. Cada columna funciona como una variable o vector. Por lo tanto, podemos hacer c√°lculos usando estas variables. Verifiquemos si la variable edades es correcta usando la fecha de nacimiento y la funci√≥n ‚ÄòSys.Date()‚Äô que devuelve la fecha de hoy para compararla con las variables en el data.frame df:\n\n\nCode\n# Crea vectores para nombres, edades, sexo, y fechas de nacimiento. \nnm &lt;- c(\"Cristina\", \"Rodrigo\", \"John\", \"√Ålvaro\", \"Castelar\",\"Sofia\")\nag &lt;- c(32, 45, 39, 25, 24, 26)\nsx &lt;- c(\"Female\",\"Male\",\"Male\",\"Male\",\"Female\",\"Female\")\nbt &lt;- as.Date(c(\"1990-12-12\",\"1977-11-22\",\"1983-09-15\",\"1997-09-08\",\"1999-02-28\",\"1998-05-27\"))\n\n# Crea un data.frame utilizando dichas variables\ndf &lt;- data.frame(\n                  Name=nm, \n                  Age=ag, \n                  Sex=sx, \n                  Birth=bt)\n\n# Calcula las edades usando la variable Birth en el data.frame df\n\n# Primero, calculamos la edad en a√±os de cada persona en el data.frame df.\n# Para hacerlo, necesitamos restar la fecha de nacimiento de la fecha de hoy (Sys.Date())\n# y dividir por 365 d√≠as. Finalmente, redondeamos el n√∫mero a a√±os completos con round().\nageb &lt;- (Sys.Date()-df$Birth)/365 # Calcula la edad en a√±os\nageb &lt;- round(ageb) # Redondea los valores a a√±os completos\n\n# Muestra los resultados\nprint(ageb)\n\n\nTime differences in days\n[1] 34 47 41 27 26 27\n\n\nCode\n# Ahora, comparamos la columna Age del data.frame df con el \n# vector ageb para verificar si todas las edades son correctas\ndf$Age==ageb\n\n\n[1] FALSE FALSE FALSE FALSE FALSE FALSE\n\n\nPodemos ver que la edad de Sofia es incorrecta. De acuerdo con la fecha de nacimiento, deber√≠a tener 25 a√±os, pero en el data.frame, tiene 26. Por lo tanto, necesitamos corregir esta variable. Para hacerlo, podemos reemplazar la columna Age en el data.frame df con el vector ageb.\nHazlo t√∫ mismo (DIY)\nAhora es tu turno. Por favor, crea un data.frame llamado ‚Äúcapitales‚Äù con las 8 capitales de provincia de Andaluc√≠a que contenga las siguientes variables: Ciudad, Poblaci√≥n y √Årea_Km2. Luego, visualiza las primeras seis filas usando head().\nPLUS ULTRA:\n\n¬øPodr√≠as calcular la densidad demogr√°fica de cada capital y crear un nuevo vector llamado dens con ella?\n¬øQu√© tal asignar esta nueva variable (densidad demogr√°fica) a una nueva columna llamada Densidad en el data.frame capitales?\n\n¬°Int√©ntalo!\nAYUDA:\nPuedes encontrar la informaci√≥n en Wikipedia.\n\n\nCode\n# Crea vectores para ciudad, poblacion y area\n\n# vector city con las capitales de provincia de Andaluc√≠a\ncity &lt;- c(\"Almer√≠a\",\"C√°diz\",\"C√≥rdoba\",\"Granada\", \"Huelva\", \"Ja√©n\", \"M√°laga\", \"Sevilla\")\npop &lt;- c(200578, 111811, 323768, 230595, 142532, 111888, 586384, 684025)\narea &lt;- c(295.51, 12.3, 1254.91, 88.02, 151.33, 424.3, 394.98, 141.42)\n\n# Crea un data.frame con dichas variables\ncapitals &lt;- data.frame(\n                  City=city, \n                  Population=pop, \n                  Area_Km2=area)\n\n# Densidad demogr√°fica\ndens &lt;- capitals$Population/capitals$Area_Km2\n\n# Visualiza los resultados\nprint(dens)\n\n\n[1]  678.7520 9090.3252  258.0010 2619.8023  941.8622  263.7002 1484.5916\n[8] 4836.8335\n\n\nCode\n# A√±ade la densidad demogr√°fica al data.frame\ncapitals$Density &lt;- dens\n\n# Visualiza los resultados usando head\nhead(capitals)\n\n\n     City Population Area_Km2   Density\n1 Almer√≠a     200578   295.51  678.7520\n2   C√°diz     111811    12.30 9090.3252\n3 C√≥rdoba     323768  1254.91  258.0010\n4 Granada     230595    88.02 2619.8023\n5  Huelva     142532   151.33  941.8622\n6    Ja√©n     111888   424.30  263.7002\n\n\n\n\nListas\nUna lista es un tipo de objeto en R que puede contener cualquier tipo de objeto. Es m√°s que un tipo de dato, es un sistema de almacenamiento para m√∫ltiples objetos o informaci√≥n.\nImaginemos que tenemos una lista llamada Libros para describir diferentes aspectos de los libros: t√≠tulo (vector de caracteres), subt√≠tulo (caracter), autor (caracter), ISBN (entero), n√∫mero de p√°ginas (entero), precio pagado (n√∫mero), fecha de publicaci√≥n (fecha). En la lista Libros, tambi√©n almacenamos la tabla de contenidos y sus respectivas p√°ginas como un data.frame. Imagina que trabajas en una biblioteca. Por lo tanto, la lista Libros tambi√©n almacena el registro actualizado de retiros y devoluciones (data.frame). Tambi√©n puedes almacenar la portada del libro (raw o un objeto de imagen) y una tabla con el n√∫mero de veces que cada libro fue prestado (un objeto de tabla).\nLas listas son muy f√°ciles de crear. Es literalmente como una bolso en el que simplemente dejas caer cosas. Tambi√©n tiene los mismos problemas que puede tener un bolso o mochila llena: se vuelve dif√≠cil recuperar informaci√≥n si el bolso no est√° organizado.\nPodemos dar nombres a cada objeto en la lista para facilitar su b√∫squeda m√°s adelante.\n\n\nCode\n# Crea un data.frame con todos los movimientos (pr√©stamos y devoluciones)\n# de un libro en nuestra biblioteca.\nprestamo &lt;- data.frame(\n                      libro=c(1,\n                              1),\n                      usuario = c(\"√Ålvaro\",\n                                \"John\"),\n                      fecha_prestamo=as.Date(\n                                      c(\"2022-07-01\",\n                                        \"2022-07-08\")\n                                      ),\n                      fecha_devolucion=as.Date(\n                                      c(\"2022-07-07\", \n                                        NA)\n                                      ),\n                      dev_esperada=as.Date(\n                                      c(\"2022-07-07\",\n                                        \"2022-07-14\")\n                                      )\n                      )\n\n# Crea una lista con los datos sobre el libro y los movimientos\nlibros &lt;- list(\n              cod_libro=c(1),\n              Titulo=\"Por qu√© YO soy tan especial\",\n              Autor=\"Yo mismito\",\n              Editorial=\"Ediciones E(R)go\",\n              ISBN=\"8598-5682323\",\n              Paginas=345,\n              Precio=25.42,\n              catalogo=\"C.182.765\",\n              movimientos=prestamo\n              )\n\n# Inspecciona el n√∫mero de veces que el\n# libro ha sido prestado\nlibros$movimientos\n\n\n  libro usuario fecha_prestamo fecha_devolucion dev_esperada\n1     1  √Ålvaro     2022-07-01       2022-07-07   2022-07-07\n2     1    John     2022-07-08             &lt;NA&gt;   2022-07-14"
  },
  {
    "objectID": "S_2_Datos.html",
    "href": "S_2_Datos.html",
    "title": "‚ÄòPicando‚Äô datos",
    "section": "",
    "text": "En esta secci√≥n del tutorial se presentan algunas pistas sobre c√≥mo navegar data.frames. Aqu√≠, exploramos algunas tareas b√°sicas en el manejo de datos como renombrar columnas, filtrar y seleccionar, y fusionar datos.\nPara ilustrar las ideas, seleccionamos 10 pa√≠ses y algunas variables del conjunto de datos mundial originalmente contenido en el paquete ‚Äòpolscidata‚Äô. Lo llamamos w (de world, vamos), puedes inspeccionar el contenido en el siguiente fragmento de c√≥digo:\n\n\nCode\n# Muestra todos los valores de w\nw\n\n\n\n\n\n\n\n\n\n\n\nLa funci√≥n names() recupera todos los nombres de las columnas de un data.frame dado. Si usamos names(w), R nos mostrar√° el nombre y el orden de cada columna en el conjunto de datos:\n\n\nCode\n# Nos da los nombres de todas las columnas del\n# data.frame en el orden original que aparecen\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religoin\"            \"spendeduc\"           \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\nComo podemos ver, hay 103 columnas en el conjunto de datos que comienzan con ‚Äúcountry‚Äù. Si analizamos la lista de nombres de columnas m√°s de cerca, podemos ver que la columna n√∫mero 16 est√° mal escrita como ‚Äúreligoin‚Äù. Deber√≠amos corregirlo cambi√°ndolo a ‚Äúreligion‚Äù. Hacemos eso simplemente asignando un nuevo valor para el 16¬∫ elemento de names():\n\n\nCode\n# Cambia el nombre de la columna religoin a religion\nnames(w)[16] &lt;- \"religion\"\n\n# Puedes tambi√©n utilizar el nombre original si\n# no est√°s seguro de d√≥nde se encuentra la variable\n# en el orden.\nnames(w)[names(w)==\"religoin\"] &lt;- \"religion\"\n\n# Busca de nuevo el nombre de todas las columnas\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religion\"            \"spendeduc\"           \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\nPuedes ver que ahora el nombre es correcto. Intenta renombrar otra variable a continuaci√≥n:\n\n\nCode\n# Cambia en nombre de de cualquier variable de tu\n# preferencia (puede ser cualquiera)\n\n\n# Llama names(w) para averiguar si todo ha ido como esperado.\n\n\n\n\nCode\n# Cambia en nombre de de cualquier variable de tu\n# preferencia (puede ser cualquiera)\nnames(w)[names(w)==\"spendeduc\"] &lt;- \"spend_education\"\n\n# Llama names(w) para averiguar si todo ha ido como esperado.\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religion\"            \"spend_education\"     \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\n\n\n\nUno de los pasos m√°s comunes en el an√°lisis de datos en R es recuperar los datos de una o m√°s columnas y usarlos para calcular las frecuencias, medias, medianas y otras estad√≠sticas. En R puedes obtener esta informaci√≥n utilizando la f√≥rmula dataframe$column. El primero elemento es el nombre del data.frame, seguido del s√≠mbolo $ y, luego, del nombre de la columna o variable. Por lo tanto, si queremos la lista de todos los pa√≠ses en el conjunto de datos w (contenido en la columna ‚Äúcountry‚Äù), s√≥lo necesitamos usar la expresi√≥n: w$country, como se muestra a continuaci√≥n:\n\n\nCode\n# Devuelve todos los nombres de pa√≠ses \n# contenidos en el data.frame w:\nw$country\n\n\n  [1] Afghanistan                       Albania                          \n  [3] Algeria                           Angola                           \n  [5] Argentina                         Armenia                          \n  [7] Australia                         Austria                          \n  [9] Azerbaijan                        Bahrain                          \n [11] Bangladesh                        Belarus                          \n [13] Belgium                           Benin                            \n [15] Bhutan                            Bolivia                          \n [17] Bosnia and Herzegovina            Botswana                         \n [19] Brazil                            Bulgaria                         \n [21] Burkina Faso                      Burma (Myanmar)                  \n [23] Burundi                           Cambodia                         \n [25] Cameroon                          Canada                           \n [27] Cape Verde                        Central African Republic         \n [29] Chad                              Chile                            \n [31] China                             Colombia                         \n [33] Comoros                           Congo, Democratic Republic of the\n [35] Congo, Republic of the            Costa Rica                       \n [37] Cote d'Ivoire                     Croatia                          \n [39] Cuba                              Cyprus                           \n [41] Czech Republic                    Denmark                          \n [43] Djibouti                          Dominican Republic               \n [45] Ecuador                           Egypt                            \n [47] El Salvador                       Equatorial Guinea                \n [49] Eritrea                           Estonia                          \n [51] Ethiopia                          Fiji                             \n [53] Finland                           France                           \n [55] Gabon                             Gambia, The                      \n [57] Georgia                           Germany                          \n [59] Ghana                             Greece                           \n [61] Guatemala                         Guinea                           \n [63] Guinea-Bissau                     Guyana                           \n [65] Haiti                             Honduras                         \n [67] Hong Kong                         Hungary                          \n [69] Iceland                           India                            \n [71] Indonesia                         Iran                             \n [73] Iraq                              Ireland                          \n [75] Israel                            Italy                            \n [77] Jamaica                           Japan                            \n [79] Jordan                            Kazakhstan                       \n [81] Kenya                             Korea, North                     \n [83] Korea, South                      Kuwait                           \n [85] Kyrgyzstan                        Laos                             \n [87] Latvia                            Lebanon                          \n [89] Lesotho                           Liberia                          \n [91] Libya                             Lithuania                        \n [93] Luxembourg                        Macedonia                        \n [95] Madagascar                        Malawi                           \n [97] Malaysia                          Mali                             \n [99] Malta                             Mauritania                       \n[101] Mauritius                         Mexico                           \n[103] Moldova                           Mongolia                         \n[105] Montenegro                        Morocco                          \n[107] Mozambique                        Namibia                          \n[109] Nepal                             Netherlands                      \n[111] New Zealand                       Nicaragua                        \n[113] Niger                             Nigeria                          \n[115] Norway                            Oman                             \n[117] Pakistan                          Palestine                        \n[119] Panama                            Papua New Guinea                 \n[121] Paraguay                          Peru                             \n[123] Philippines                       Poland                           \n[125] Portugal                          Qatar                            \n[127] Romania                           Russia                           \n[129] Rwanda                            Saudi Arabia                     \n[131] Senegal                           Serbia                           \n[133] Sierra Leone                      Singapore                        \n[135] Slovakia                          Slovenia                         \n[137] South Africa                      Spain                            \n[139] Sri Lanka                         Sudan                            \n[141] Suriname                          Swaziland                        \n[143] Sweden                            Switzerland                      \n[145] Syria                             Taiwan                           \n[147] Tajikistan                        Tanzania                         \n[149] Thailand                          Timor-Leste                      \n[151] Togo                              Trinidad and Tobago              \n[153] Tunisia                           Turkey                           \n[155] Turkmenistan                      Uganda                           \n[157] Ukraine                           United Arab Emirates             \n[159] United Kingdom                    United States                    \n[161] Uruguay                           Uzbekistan                       \n[163] Venezuela                         Vietnam                          \n[165] Yemen                             Zambia                           \n[167] Zimbabwe                         \n167 Levels: Afghanistan Albania Algeria Angola Argentina Armenia ... Zimbabwe\n\n\nCode\n# Podemos tambi√©n emplear el n√∫mero de la columna\n# en el orden que aparece en el data.frame \n# despu√©s de una coma:\nw[,1]\n\n\n  [1] Afghanistan                       Albania                          \n  [3] Algeria                           Angola                           \n  [5] Argentina                         Armenia                          \n  [7] Australia                         Austria                          \n  [9] Azerbaijan                        Bahrain                          \n [11] Bangladesh                        Belarus                          \n [13] Belgium                           Benin                            \n [15] Bhutan                            Bolivia                          \n [17] Bosnia and Herzegovina            Botswana                         \n [19] Brazil                            Bulgaria                         \n [21] Burkina Faso                      Burma (Myanmar)                  \n [23] Burundi                           Cambodia                         \n [25] Cameroon                          Canada                           \n [27] Cape Verde                        Central African Republic         \n [29] Chad                              Chile                            \n [31] China                             Colombia                         \n [33] Comoros                           Congo, Democratic Republic of the\n [35] Congo, Republic of the            Costa Rica                       \n [37] Cote d'Ivoire                     Croatia                          \n [39] Cuba                              Cyprus                           \n [41] Czech Republic                    Denmark                          \n [43] Djibouti                          Dominican Republic               \n [45] Ecuador                           Egypt                            \n [47] El Salvador                       Equatorial Guinea                \n [49] Eritrea                           Estonia                          \n [51] Ethiopia                          Fiji                             \n [53] Finland                           France                           \n [55] Gabon                             Gambia, The                      \n [57] Georgia                           Germany                          \n [59] Ghana                             Greece                           \n [61] Guatemala                         Guinea                           \n [63] Guinea-Bissau                     Guyana                           \n [65] Haiti                             Honduras                         \n [67] Hong Kong                         Hungary                          \n [69] Iceland                           India                            \n [71] Indonesia                         Iran                             \n [73] Iraq                              Ireland                          \n [75] Israel                            Italy                            \n [77] Jamaica                           Japan                            \n [79] Jordan                            Kazakhstan                       \n [81] Kenya                             Korea, North                     \n [83] Korea, South                      Kuwait                           \n [85] Kyrgyzstan                        Laos                             \n [87] Latvia                            Lebanon                          \n [89] Lesotho                           Liberia                          \n [91] Libya                             Lithuania                        \n [93] Luxembourg                        Macedonia                        \n [95] Madagascar                        Malawi                           \n [97] Malaysia                          Mali                             \n [99] Malta                             Mauritania                       \n[101] Mauritius                         Mexico                           \n[103] Moldova                           Mongolia                         \n[105] Montenegro                        Morocco                          \n[107] Mozambique                        Namibia                          \n[109] Nepal                             Netherlands                      \n[111] New Zealand                       Nicaragua                        \n[113] Niger                             Nigeria                          \n[115] Norway                            Oman                             \n[117] Pakistan                          Palestine                        \n[119] Panama                            Papua New Guinea                 \n[121] Paraguay                          Peru                             \n[123] Philippines                       Poland                           \n[125] Portugal                          Qatar                            \n[127] Romania                           Russia                           \n[129] Rwanda                            Saudi Arabia                     \n[131] Senegal                           Serbia                           \n[133] Sierra Leone                      Singapore                        \n[135] Slovakia                          Slovenia                         \n[137] South Africa                      Spain                            \n[139] Sri Lanka                         Sudan                            \n[141] Suriname                          Swaziland                        \n[143] Sweden                            Switzerland                      \n[145] Syria                             Taiwan                           \n[147] Tajikistan                        Tanzania                         \n[149] Thailand                          Timor-Leste                      \n[151] Togo                              Trinidad and Tobago              \n[153] Tunisia                           Turkey                           \n[155] Turkmenistan                      Uganda                           \n[157] Ukraine                           United Arab Emirates             \n[159] United Kingdom                    United States                    \n[161] Uruguay                           Uzbekistan                       \n[163] Venezuela                         Vietnam                          \n[165] Yemen                             Zambia                           \n[167] Zimbabwe                         \n167 Levels: Afghanistan Albania Algeria Angola Argentina Armenia ... Zimbabwe\n\n\nComo se puede ver, los dos m√©todos devuelven la misma lista de pa√≠ses. Esto ocurre podque hemos realizado el mismo procedimiento utilizando dos m√©todos alternativos. No te preocupes por el segundo, lo describiremos con m√°s detalle en la pr√≥xima subsecci√≥n (es una de las caracter√≠sticas m√°s chulas del R para manipular datos).\nAhora, intenta seleccionar la informaci√≥n sobre el √çndice de Desarrollo Humano (columna hdi):\n\n\nCode\n# Busca la informaci√≥n sobre el HDI:\nw$hdi\n\n\n  [1] 0.349 0.719 0.677 0.403 0.775 0.695 0.937 0.851 0.713 0.801 0.469 0.732\n [13] 0.867 0.435    NA 0.643 0.710 0.633 0.699 0.743 0.305 0.451 0.282 0.494\n [25] 0.460 0.888 0.534 0.315 0.295 0.783 0.663 0.689 0.428 0.239 0.489 0.725\n [37] 0.397 0.767    NA 0.810 0.841 0.866 0.402 0.663 0.695 0.620 0.659 0.538\n [49]    NA 0.812 0.328 0.669 0.871 0.872 0.648 0.390 0.698 0.885 0.467 0.855\n [61] 0.560 0.340 0.289 0.611 0.404 0.604 0.862 0.805 0.869 0.519 0.600 0.702\n [73]    NA 0.895 0.872 0.854 0.688 0.884 0.681 0.714 0.470    NA 0.877 0.771\n [85] 0.598 0.497 0.769    NA 0.427 0.300 0.755 0.783 0.852 0.701 0.435 0.385\n [97] 0.744 0.309 0.815 0.433 0.701 0.750 0.623 0.622 0.769 0.567 0.284 0.606\n[109] 0.428 0.890 0.907 0.565 0.261 0.423 0.938    NA 0.490    NA 0.755 0.431\n[121] 0.640 0.723 0.638 0.795 0.795 0.803 0.767 0.719 0.385 0.752 0.411 0.735\n[133] 0.317 0.846 0.818 0.828 0.597 0.863 0.658 0.379 0.646 0.498 0.885 0.874\n[145] 0.589    NA 0.580 0.398 0.654 0.502 0.428 0.736 0.683 0.679 0.669 0.422\n[157] 0.710 0.815 0.849 0.902 0.765 0.617 0.696 0.572 0.439 0.395 0.140\n\n\nComo pod√©is ver, algunos valores aparecen como NA. Esto significa que no hay datos disponibles para esos pa√≠ses en particular. El R utiliza NA (Not Available) para representar los valores faltantes o no informados. Siempre que ve un NA, lo retira de los c√°lculos o lo trata de la manera que definamos en nuestros an√°lisis."
  },
  {
    "objectID": "S_2_Datos.html#uso-b√°sico-de-data.frames",
    "href": "S_2_Datos.html#uso-b√°sico-de-data.frames",
    "title": "‚ÄòPicando‚Äô datos",
    "section": "",
    "text": "En esta secci√≥n del tutorial se presentan algunas pistas sobre c√≥mo navegar data.frames. Aqu√≠, exploramos algunas tareas b√°sicas en el manejo de datos como renombrar columnas, filtrar y seleccionar, y fusionar datos.\nPara ilustrar las ideas, seleccionamos 10 pa√≠ses y algunas variables del conjunto de datos mundial originalmente contenido en el paquete ‚Äòpolscidata‚Äô. Lo llamamos w (de world, vamos), puedes inspeccionar el contenido en el siguiente fragmento de c√≥digo:\n\n\nCode\n# Muestra todos los valores de w\nw\n\n\n\n\n\n\n\n\n\n\n\nLa funci√≥n names() recupera todos los nombres de las columnas de un data.frame dado. Si usamos names(w), R nos mostrar√° el nombre y el orden de cada columna en el conjunto de datos:\n\n\nCode\n# Nos da los nombres de todas las columnas del\n# data.frame en el orden original que aparecen\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religoin\"            \"spendeduc\"           \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\nComo podemos ver, hay 103 columnas en el conjunto de datos que comienzan con ‚Äúcountry‚Äù. Si analizamos la lista de nombres de columnas m√°s de cerca, podemos ver que la columna n√∫mero 16 est√° mal escrita como ‚Äúreligoin‚Äù. Deber√≠amos corregirlo cambi√°ndolo a ‚Äúreligion‚Äù. Hacemos eso simplemente asignando un nuevo valor para el 16¬∫ elemento de names():\n\n\nCode\n# Cambia el nombre de la columna religoin a religion\nnames(w)[16] &lt;- \"religion\"\n\n# Puedes tambi√©n utilizar el nombre original si\n# no est√°s seguro de d√≥nde se encuentra la variable\n# en el orden.\nnames(w)[names(w)==\"religoin\"] &lt;- \"religion\"\n\n# Busca de nuevo el nombre de todas las columnas\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religion\"            \"spendeduc\"           \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\nPuedes ver que ahora el nombre es correcto. Intenta renombrar otra variable a continuaci√≥n:\n\n\nCode\n# Cambia en nombre de de cualquier variable de tu\n# preferencia (puede ser cualquiera)\n\n\n# Llama names(w) para averiguar si todo ha ido como esperado.\n\n\n\n\nCode\n# Cambia en nombre de de cualquier variable de tu\n# preferencia (puede ser cualquiera)\nnames(w)[names(w)==\"spendeduc\"] &lt;- \"spend_education\"\n\n# Llama names(w) para averiguar si todo ha ido como esperado.\nnames(w)\n\n\n  [1] \"country\"             \"gini10\"              \"dem_level4\"         \n  [4] \"dem_rank14\"          \"dem_score14\"         \"lifeex_f\"           \n  [7] \"lifeex_m\"            \"literacy\"            \"oil\"                \n [10] \"pop_0_14\"            \"pop_15_64\"           \"pop_65_older\"       \n [13] \"fertility\"           \"govregrel\"           \"regionun\"           \n [16] \"religion\"            \"spend_education\"     \"spendhealth\"        \n [19] \"spendmil\"            \"hdi\"                 \"pop_age\"            \n [22] \"sexratio\"            \"pop_total\"           \"pop_urban\"          \n [25] \"gender_unequal\"      \"gender_unequal_rank\" \"arda\"               \n [28] \"lifeex_total\"        \"debt\"                \"colony\"             \n [31] \"confidence\"          \"decent08\"            \"dem_other\"          \n [34] \"dem_other5\"          \"democ\"               \"democ11\"            \n [37] \"democ_regime\"        \"democ_regime08\"      \"district_size3\"     \n [40] \"durable\"             \"effectiveness\"       \"enpp3_democ\"        \n [43] \"enpp3_democ08\"       \"dnpp_3\"              \"eu\"                 \n [46] \"fhrate04_rev\"        \"fhrate08_rev\"        \"frac_eth\"           \n [49] \"frac_eth2\"           \"frac_eth3\"           \"free_business\"      \n [52] \"free_corrupt\"        \"free_finance\"        \"free_fiscal\"        \n [55] \"free_govspend\"       \"free_invest\"         \"free_labor\"         \n [58] \"free_monetary\"       \"free_property\"       \"free_trade\"         \n [61] \"free_overall\"        \"free_overall_4\"      \"gdp08\"              \n [64] \"gdp_10_thou\"         \"gdp_cap2\"            \"gdp_cap3\"           \n [67] \"gdpcap2_08\"          \"gdpcap3_08\"          \"gdpcap08_2\"         \n [70] \"gdppcap08\"           \"gdppcap08_3\"         \"gender_equal3\"      \n [73] \"gini04\"              \"gini08\"              \"hi_gdp\"             \n [76] \"indy\"                \"muslim\"              \"natcode\"            \n [79] \"oecd\"                \"pmat12_3\"            \"polity\"             \n [82] \"pr_sys\"              \"protact3\"            \"regime_type3\"       \n [85] \"rich_democ\"          \"unions\"              \"unnetgro\"           \n [88] \"unnetuse\"            \"unpovnpl\"            \"unremitp\"           \n [91] \"unremitt\"            \"vi_rel3\"             \"votevap00s\"         \n [94] \"votevap90s\"          \"women05\"             \"women09\"            \n [97] \"women13\"             \"ipu_wom13_all\"       \"womyear\"            \n[100] \"womyear2\"            \"dem_economist\"       \"democ.yes\"          \n[103] \"country1\"           \n\n\n\n\n\nUno de los pasos m√°s comunes en el an√°lisis de datos en R es recuperar los datos de una o m√°s columnas y usarlos para calcular las frecuencias, medias, medianas y otras estad√≠sticas. En R puedes obtener esta informaci√≥n utilizando la f√≥rmula dataframe$column. El primero elemento es el nombre del data.frame, seguido del s√≠mbolo $ y, luego, del nombre de la columna o variable. Por lo tanto, si queremos la lista de todos los pa√≠ses en el conjunto de datos w (contenido en la columna ‚Äúcountry‚Äù), s√≥lo necesitamos usar la expresi√≥n: w$country, como se muestra a continuaci√≥n:\n\n\nCode\n# Devuelve todos los nombres de pa√≠ses \n# contenidos en el data.frame w:\nw$country\n\n\n  [1] Afghanistan                       Albania                          \n  [3] Algeria                           Angola                           \n  [5] Argentina                         Armenia                          \n  [7] Australia                         Austria                          \n  [9] Azerbaijan                        Bahrain                          \n [11] Bangladesh                        Belarus                          \n [13] Belgium                           Benin                            \n [15] Bhutan                            Bolivia                          \n [17] Bosnia and Herzegovina            Botswana                         \n [19] Brazil                            Bulgaria                         \n [21] Burkina Faso                      Burma (Myanmar)                  \n [23] Burundi                           Cambodia                         \n [25] Cameroon                          Canada                           \n [27] Cape Verde                        Central African Republic         \n [29] Chad                              Chile                            \n [31] China                             Colombia                         \n [33] Comoros                           Congo, Democratic Republic of the\n [35] Congo, Republic of the            Costa Rica                       \n [37] Cote d'Ivoire                     Croatia                          \n [39] Cuba                              Cyprus                           \n [41] Czech Republic                    Denmark                          \n [43] Djibouti                          Dominican Republic               \n [45] Ecuador                           Egypt                            \n [47] El Salvador                       Equatorial Guinea                \n [49] Eritrea                           Estonia                          \n [51] Ethiopia                          Fiji                             \n [53] Finland                           France                           \n [55] Gabon                             Gambia, The                      \n [57] Georgia                           Germany                          \n [59] Ghana                             Greece                           \n [61] Guatemala                         Guinea                           \n [63] Guinea-Bissau                     Guyana                           \n [65] Haiti                             Honduras                         \n [67] Hong Kong                         Hungary                          \n [69] Iceland                           India                            \n [71] Indonesia                         Iran                             \n [73] Iraq                              Ireland                          \n [75] Israel                            Italy                            \n [77] Jamaica                           Japan                            \n [79] Jordan                            Kazakhstan                       \n [81] Kenya                             Korea, North                     \n [83] Korea, South                      Kuwait                           \n [85] Kyrgyzstan                        Laos                             \n [87] Latvia                            Lebanon                          \n [89] Lesotho                           Liberia                          \n [91] Libya                             Lithuania                        \n [93] Luxembourg                        Macedonia                        \n [95] Madagascar                        Malawi                           \n [97] Malaysia                          Mali                             \n [99] Malta                             Mauritania                       \n[101] Mauritius                         Mexico                           \n[103] Moldova                           Mongolia                         \n[105] Montenegro                        Morocco                          \n[107] Mozambique                        Namibia                          \n[109] Nepal                             Netherlands                      \n[111] New Zealand                       Nicaragua                        \n[113] Niger                             Nigeria                          \n[115] Norway                            Oman                             \n[117] Pakistan                          Palestine                        \n[119] Panama                            Papua New Guinea                 \n[121] Paraguay                          Peru                             \n[123] Philippines                       Poland                           \n[125] Portugal                          Qatar                            \n[127] Romania                           Russia                           \n[129] Rwanda                            Saudi Arabia                     \n[131] Senegal                           Serbia                           \n[133] Sierra Leone                      Singapore                        \n[135] Slovakia                          Slovenia                         \n[137] South Africa                      Spain                            \n[139] Sri Lanka                         Sudan                            \n[141] Suriname                          Swaziland                        \n[143] Sweden                            Switzerland                      \n[145] Syria                             Taiwan                           \n[147] Tajikistan                        Tanzania                         \n[149] Thailand                          Timor-Leste                      \n[151] Togo                              Trinidad and Tobago              \n[153] Tunisia                           Turkey                           \n[155] Turkmenistan                      Uganda                           \n[157] Ukraine                           United Arab Emirates             \n[159] United Kingdom                    United States                    \n[161] Uruguay                           Uzbekistan                       \n[163] Venezuela                         Vietnam                          \n[165] Yemen                             Zambia                           \n[167] Zimbabwe                         \n167 Levels: Afghanistan Albania Algeria Angola Argentina Armenia ... Zimbabwe\n\n\nCode\n# Podemos tambi√©n emplear el n√∫mero de la columna\n# en el orden que aparece en el data.frame \n# despu√©s de una coma:\nw[,1]\n\n\n  [1] Afghanistan                       Albania                          \n  [3] Algeria                           Angola                           \n  [5] Argentina                         Armenia                          \n  [7] Australia                         Austria                          \n  [9] Azerbaijan                        Bahrain                          \n [11] Bangladesh                        Belarus                          \n [13] Belgium                           Benin                            \n [15] Bhutan                            Bolivia                          \n [17] Bosnia and Herzegovina            Botswana                         \n [19] Brazil                            Bulgaria                         \n [21] Burkina Faso                      Burma (Myanmar)                  \n [23] Burundi                           Cambodia                         \n [25] Cameroon                          Canada                           \n [27] Cape Verde                        Central African Republic         \n [29] Chad                              Chile                            \n [31] China                             Colombia                         \n [33] Comoros                           Congo, Democratic Republic of the\n [35] Congo, Republic of the            Costa Rica                       \n [37] Cote d'Ivoire                     Croatia                          \n [39] Cuba                              Cyprus                           \n [41] Czech Republic                    Denmark                          \n [43] Djibouti                          Dominican Republic               \n [45] Ecuador                           Egypt                            \n [47] El Salvador                       Equatorial Guinea                \n [49] Eritrea                           Estonia                          \n [51] Ethiopia                          Fiji                             \n [53] Finland                           France                           \n [55] Gabon                             Gambia, The                      \n [57] Georgia                           Germany                          \n [59] Ghana                             Greece                           \n [61] Guatemala                         Guinea                           \n [63] Guinea-Bissau                     Guyana                           \n [65] Haiti                             Honduras                         \n [67] Hong Kong                         Hungary                          \n [69] Iceland                           India                            \n [71] Indonesia                         Iran                             \n [73] Iraq                              Ireland                          \n [75] Israel                            Italy                            \n [77] Jamaica                           Japan                            \n [79] Jordan                            Kazakhstan                       \n [81] Kenya                             Korea, North                     \n [83] Korea, South                      Kuwait                           \n [85] Kyrgyzstan                        Laos                             \n [87] Latvia                            Lebanon                          \n [89] Lesotho                           Liberia                          \n [91] Libya                             Lithuania                        \n [93] Luxembourg                        Macedonia                        \n [95] Madagascar                        Malawi                           \n [97] Malaysia                          Mali                             \n [99] Malta                             Mauritania                       \n[101] Mauritius                         Mexico                           \n[103] Moldova                           Mongolia                         \n[105] Montenegro                        Morocco                          \n[107] Mozambique                        Namibia                          \n[109] Nepal                             Netherlands                      \n[111] New Zealand                       Nicaragua                        \n[113] Niger                             Nigeria                          \n[115] Norway                            Oman                             \n[117] Pakistan                          Palestine                        \n[119] Panama                            Papua New Guinea                 \n[121] Paraguay                          Peru                             \n[123] Philippines                       Poland                           \n[125] Portugal                          Qatar                            \n[127] Romania                           Russia                           \n[129] Rwanda                            Saudi Arabia                     \n[131] Senegal                           Serbia                           \n[133] Sierra Leone                      Singapore                        \n[135] Slovakia                          Slovenia                         \n[137] South Africa                      Spain                            \n[139] Sri Lanka                         Sudan                            \n[141] Suriname                          Swaziland                        \n[143] Sweden                            Switzerland                      \n[145] Syria                             Taiwan                           \n[147] Tajikistan                        Tanzania                         \n[149] Thailand                          Timor-Leste                      \n[151] Togo                              Trinidad and Tobago              \n[153] Tunisia                           Turkey                           \n[155] Turkmenistan                      Uganda                           \n[157] Ukraine                           United Arab Emirates             \n[159] United Kingdom                    United States                    \n[161] Uruguay                           Uzbekistan                       \n[163] Venezuela                         Vietnam                          \n[165] Yemen                             Zambia                           \n[167] Zimbabwe                         \n167 Levels: Afghanistan Albania Algeria Angola Argentina Armenia ... Zimbabwe\n\n\nComo se puede ver, los dos m√©todos devuelven la misma lista de pa√≠ses. Esto ocurre podque hemos realizado el mismo procedimiento utilizando dos m√©todos alternativos. No te preocupes por el segundo, lo describiremos con m√°s detalle en la pr√≥xima subsecci√≥n (es una de las caracter√≠sticas m√°s chulas del R para manipular datos).\nAhora, intenta seleccionar la informaci√≥n sobre el √çndice de Desarrollo Humano (columna hdi):\n\n\nCode\n# Busca la informaci√≥n sobre el HDI:\nw$hdi\n\n\n  [1] 0.349 0.719 0.677 0.403 0.775 0.695 0.937 0.851 0.713 0.801 0.469 0.732\n [13] 0.867 0.435    NA 0.643 0.710 0.633 0.699 0.743 0.305 0.451 0.282 0.494\n [25] 0.460 0.888 0.534 0.315 0.295 0.783 0.663 0.689 0.428 0.239 0.489 0.725\n [37] 0.397 0.767    NA 0.810 0.841 0.866 0.402 0.663 0.695 0.620 0.659 0.538\n [49]    NA 0.812 0.328 0.669 0.871 0.872 0.648 0.390 0.698 0.885 0.467 0.855\n [61] 0.560 0.340 0.289 0.611 0.404 0.604 0.862 0.805 0.869 0.519 0.600 0.702\n [73]    NA 0.895 0.872 0.854 0.688 0.884 0.681 0.714 0.470    NA 0.877 0.771\n [85] 0.598 0.497 0.769    NA 0.427 0.300 0.755 0.783 0.852 0.701 0.435 0.385\n [97] 0.744 0.309 0.815 0.433 0.701 0.750 0.623 0.622 0.769 0.567 0.284 0.606\n[109] 0.428 0.890 0.907 0.565 0.261 0.423 0.938    NA 0.490    NA 0.755 0.431\n[121] 0.640 0.723 0.638 0.795 0.795 0.803 0.767 0.719 0.385 0.752 0.411 0.735\n[133] 0.317 0.846 0.818 0.828 0.597 0.863 0.658 0.379 0.646 0.498 0.885 0.874\n[145] 0.589    NA 0.580 0.398 0.654 0.502 0.428 0.736 0.683 0.679 0.669 0.422\n[157] 0.710 0.815 0.849 0.902 0.765 0.617 0.696 0.572 0.439 0.395 0.140\n\n\nComo pod√©is ver, algunos valores aparecen como NA. Esto significa que no hay datos disponibles para esos pa√≠ses en particular. El R utiliza NA (Not Available) para representar los valores faltantes o no informados. Siempre que ve un NA, lo retira de los c√°lculos o lo trata de la manera que definamos en nuestros an√°lisis."
  },
  {
    "objectID": "S_2_Datos.html#abrir-datos",
    "href": "S_2_Datos.html#abrir-datos",
    "title": "‚ÄòPicando‚Äô datos",
    "section": "Abrir datos",
    "text": "Abrir datos\n\nArchivos Excel\nExisten m√∫ltiples formas de abrir archivos de Excel en R. La m√°s f√°cil es utilizar la funci√≥n read.xlsx() del paquete openxlsx. A pesar de que la funci√≥n read.xlsx() s√≥lo funciona con archivos de Excel recientes (aquellos con la extensi√≥n .xlsx), su principal ventaja es poder abrir datos directamente desde Internet sin tener que descargar el archivo primero. El c√≥digo a continuaci√≥n abre un Excel que contiene los niveles de educaci√≥n por nacionalidad y sexo del Censo Demogr√°fico 2021 utilizando un enlace de Dropbox:\n\n\nCode\nlibrary(openxlsx)\n\nd &lt;- read.xlsx(\"https://www.dropbox.com/s/orz8fdeg8as00fl/edu_nacion.xlsx?dl=1\")\n\nd\n\n\n\n\n\n\n\n\n\nEl archivo est√° ordenado y cada columna est√° identificada por un nombre. Otros s√≠mbolos, notas y comentarios fueron eliminados previamente para facilitar la lectura de los datos. Tambi√©n seleccionamos s√≥lo los datos para ‚Äúambos sexos‚Äù y eliminamos la informaci√≥n detallada para cada sexo.\nAhora, copia el enlace a continuaci√≥n y p√©galo en tu navegador para descargar y cargar el archivo original desde la p√°gina web del INE (Instituto Nacional de Estad√≠stica):\nhttps://ine.es/jaxi/files/tpx/es/xlsx/55231.xlsx\nComo puedes observar, el archivo tiene encabezados, notas y una estructura m√°s compleja en comparaci√≥n con los datos abiertos anteriormente. El primer paso para utilizar datos en CUALQUIER paquete estad√≠stico es asegurarse de que tus datos se ajustan a la estructura de una tabla de N filas x N columnas.\nSi intentamos abrir el archivo sin tratarlo antes, tal como lo proporciona el INE, aparecer√° as√≠:\n\n\nCode\nlibrary(openxlsx)\n\nd &lt;- read.xlsx(\"https://ine.es/jaxi/files/tpx/es/xlsx/55231.xlsx?nocab=1\")\n\nd\n\n\n\n\n\n\n\n\n\nAhora, compara los dos.\nLa primera versi√≥n est√° ordenada, con nombres de variables identificando cada columna y los datos est√°n bien estructurados.\nLa segunda versi√≥n es cruda, sin nombres de columnas estructurados y la mayor√≠a de los datos no est√°n tratados.\nPor lo tanto, antes de abrir datos en R, verifica si el formato es adecuado o si necesitas realizar un trabajo preliminar.\n\n\nArchivos CSV\nOtros formatos comunes son los archivos de valores separados por comas (CSV). Estos archivos son b√°sicamente texto con comas separando cada columna. Son particularmente √∫tiles porque:\n\nSon f√°ciles de almacenar y comprimir. Archivos con incluso gigabytes pueden ser comprimidos en archivos mucho m√°s peque√±os.\nPueden ser abiertos en casi cualquier hoja de c√°lculo (como Excel o Numbers) o paquete estad√≠stico (R, SPSS, Stata, SAS).\nSon robustos a los cambios en la tecnolog√≠a. Versiones de Excel o SPSS hacen que los viejos conjuntos de datos sean incompatibles con el nuevo software. Dado que son texto b√°sico, los archivos CSV son siempre compatibles y probablemente seguir√°n siendo compatibles en el futuro.\n\nLa funci√≥n para abrir archivos CSV en R es read.csv(). El c√≥digo a continuaci√≥n abre el archivo CSV que contiene la puntuaci√≥n de Rotten Tomatoes para cada una de las pel√≠culas de Robert De Niro:\n\n\nCode\nd &lt;- read.csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/deniro.csv\")\n\nd\n\n\n\n\n\n\n\n\n\nSpain is different\nAlgunos pa√≠ses utilizan comas para indicar d√≠gitos decimales en los n√∫meros. Por lo tanto, 9.99 en los EE.UU. es lo mismo que 9,99 en Espa√±a. Por esta raz√≥n, la mayor√≠a de los archivos csv en esos pa√≠ses utilizan punto y coma (;) para separar columnas. Si utilizamos read.csv() los datos no se leer√≠an correctamente. En esos casos, puedes utilizar la funci√≥n m√°s general read.delim() para abrir los archivos csv con otros separadores como punto y coma.\nEl c√≥digo a continuaci√≥n abre un archivo con la definici√≥n de las variables para estudios postelectorales del CIS. El archivo original utiliza punto y coma para separar las variables. Por lo tanto, empleamos la funci√≥n read.delim() y a√±adimos el par√°metro sep=‚Äú;‚Äù despu√©s del enlace al archivo.\n\n\nCode\nd &lt;- read.delim(\"https://www.dropbox.com/s/6f8nfzshzwelgil/CIS_definicion.csv?dl=1\",sep = \";\")\n\nd\n\n\n\n\n\n\n\n\n\n\n\nDatos SPSS\nSPSS es un paquete estad√≠stico muy popular en las Ciencias Sociales. No es sorprendente que muchos estudios utilicen archivos de datos SPSS (.sav) como fuente principal para distribuir sus resultados. El paquete foreign ayuda a abrir datos de otras fuentes como SPSS, dbf y Stata. En el c√≥digo a continuaci√≥n, utilizamos la funci√≥n read.spss() para abrir el archivo de datos SPSS del estudio postelectoral realizado por el Centro de Investigaciones Sociol√≥gicas (CIS) para las Elecciones Generales de Espa√±a celebradas en noviembre de 2019.\n\n\nCode\nlibrary(foreign)\n\nd &lt;- read.spss(\"https://www.dropbox.com/s/s0j6hsidpy08ab3/3269.sav?dl=1\", \n               to.data.frame = T)\n\nd"
  },
  {
    "objectID": "S_2_Datos.html#limpieza-de-datos",
    "href": "S_2_Datos.html#limpieza-de-datos",
    "title": "‚ÄòPicando‚Äô datos",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\n\nFiltrar datos y columnas\nOtra tarea com√∫n en el an√°lisis de datos es seleccionar solo la informaci√≥n de inter√©s. Muchos conjuntos de datos vienen con muchas variables que no utilizaremos en nuestro an√°lisis. A veces, estamos interesados solo en algunas observaciones y no en todos los casos incluidos en los datos.\nExiste una variedad de formas de seleccionar datos en R. La m√°s directa es utilizar una condici√≥n l√≥gica para definir las observaciones a seleccionar. Un data.frame es un objeto bidimensional. Contiene Filas y Columnas. Podemos representarlo de esta manera: data.frame[F,C]. Por lo tanto, si quiero seleccionar las primeras 10 filas de los datos, solo necesito llamar a data.frame[1:10,]. Es como jugar el ‚Äúbatalla naval‚Äù o ‚Äúhundir la flota‚Äù donde se emplean dos coordinadas (una de la l√≠nea y otra de la columna) para poder intentar bombardear el barco del adversario. Este comando selecciona las primeras 10 filas del conjunto de datos. Intent√©moslo con nuestro data.frame w:\n\n\nCode\n# Selecciona todas las columnas de las 10 primeras l√≠neas\nw[1:10,]\n\n\n\n\n\n\n\n\n\n¬øPor qu√© necesito usar la coma despu√©s de 1:10? Es porque le estoy diciendo a R que seleccione las primeras 10 FILAS y todas las 104 COLUMNAS. Intentemos poner la coma primero:\n\n\nCode\n# Selecciona solo las 10 primeras columnas\nw[,1:10]\n\n\n\n\n\n\n\n\n\nEn este segundo ejemplo, seleccionamos todas las 167 FILAS y solo las 10 primeras COLUMNAS.\nAhora, ¬øqu√© pasa si quiero seleccionar solo las primeras 5 filas y las primeras 3 columnas?\n\n\nCode\n# Selecciona las 5 primeras l√≠neas y las\n# 3 primeras columnas\nw[1:5,1:3]\n\n\n\n\n\n\n\n\n\nMe muestra solo las primeras 5 filas y el nombre del pa√≠s, el √≠ndice GINI y el tipo de r√©gimen pol√≠tico.\nAhora es tu turno:\nSelecciona las primeras siete filas y las cuatro primeras columnas:\n\n\nCode\n# Selecciona las 7 primeras filas \n# y las 4 primeras columnas\nw[1:7,1:4]\n\n\n\n\n\n\n\n\n\nTales ejemplos nos ayudan a aprender c√≥mo funciona la indexaci√≥n en R (y en la mayor√≠a de los lenguajes de programaci√≥n). Sin embargo, generalmente queremos seleccionar observaciones basadas en valores dados. Por ejemplo, quiero seleccionar solo las democracias plenas. Puedo usar una expresi√≥n l√≥gica para hacerlo:\n\n\nCode\n# Selecciona solamente \"Democracias plenas\" (Full Democ).\nw[w$dem_level4==\"Full Democ\",]\n\n\n\n\n\n\n\n\n\nAhora es tu turno. Selecciona solo los pa√≠ses con mayor√≠a musulmana:\n\n\n\n\n\n\n\n\n\nCode\n# Selecciona solo pa√≠ses con \n# mayor√≠a musulmana.\nw[w$muslim==\"Yes\",]\n\n\nTambi√©n podemos seleccionar columnas espec√≠ficas. Ahora, seleccionemos aquellos pa√≠ses que son democracias completas y las columnas ‚Äúcountry‚Äù, ‚Äúdem_level4‚Äù, y ‚Äúreligoin‚Äù:\n\n\nCode\n# Selecciona Full democracies y variables elegidas.\nw[w$dem_level4==\"Full Democ\", c(\"country\", \"dem_level4\", \"religion\")]\n\n\n\n\n\n\n\n\n\nAhora es tu turno. Selecciona solo los pa√≠ses con mayor√≠a musulmana y las columnas ‚Äúcountry‚Äù, ‚Äúdem_level4‚Äù, y ‚Äúreligoin‚Äù:\n\n\nCode\n# Selecciona solamente mayor√≠a musulmana y variables elegidas.\nw[w$muslim==\"Yes\", c(\"country\", \"dem_level4\", \"religion\")]\n\n\n\n\n\n\n\n\n\nAhora, seleccionemos solo aquellos pa√≠ses de w que tienen datos sobre el √≠ndice GINI gini10). En R, los valores faltantes se representan como NA:\n\n\nCode\n# Selecciona solamente pa√≠ses con datos de Gini\n# en la base w .\nw[! is.na(w$gini10), ]\n\n\n\n\n\n\n\n\n\n\n\nCombinando data.frames\nEn las secciones anteriores, aprendimos c√≥mo filtrar datos en subgrupos. Ahora aprenderemos c√≥mo unir diferentes conjuntos de datos en uno solo.\nDivid√≠ el conjunto de datos w en cuatro subgrupos: w1 con las primeras 83 filas, w2 con las siguientes 84 filas, wa con algunas variables seleccionadas previamente, y wb con otras variables seleccionadas.\nJuntando datos por fila\nEl primer m√©todo es simplemente poner un conjunto de datos sobre el otro. Este procedimiento solo funcionar√° si AMBOS conjuntos de datos tienen el mismo n√∫mero de variables y los mismos nombres.\nLa funci√≥n empleada es rbind(df1,df2, ‚Ä¶, dfn). Revisa el ejemplo uniendo w1 y w2:\n\n\nCode\n# Junta w1 y w2 por fila:\nrbind(w1,w2)\n\n\n\n\n\n\n\n\n\nComo se puede ver, la tabla contiene 167 observaciones, igual que w, el conjunto de datos original. Si exploras los conjuntos de datos w1 y w2, ver√°s que tienen 83 y 84 observaciones, respectivamente:\n\n\nCode\n# Explora los datos de w1\nw1\n\n# Explora los datos de w2\nw2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJuntando datos por columna\nEn muchas ocasiones, nuestros datos est√°n dispersos en diferentes archivos. Algunas variables de inter√©s est√°n en un archivo, mientras que otras est√°n en otro. Antes de realizar cualquier an√°lisis, necesitamos reunir todos los atributos en un solo conjunto de datos.\nExisten varias formas de combinar datos en R. Aqu√≠, exploraremos la funci√≥n can√≥nica merge(). Con merge() puedes unir dos conjuntos de datos y establecer qu√© informaci√≥n conservas y cu√°l descartas.\nAntes de nada, exploremos los conjuntos de datos wa y wb usando head():\n\n\nCode\n# Explora los datos de wa\nwa\n\n# Explora los datos de wb\nwb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComo podemos ver, ambos conjuntos de datos tienen todos los pa√≠ses, pero las variables son diferentes, EXCEPTO por el pa√≠s. El conjunto de datos wa contiene 5 columnas y wb otras 5. En este ejemplo, uniremos los conjuntos de datos wa y wb, usando la variable com√∫n ‚Äúcountry‚Äù como clave para comparar ambos. El resultado esperado es un data.frame con 167 observaciones y 9 columnas (ya que ‚Äúcountry‚Äù es la clave en wa y wb).\n\n\nCode\n# fusiona wa y wb usando \"country\" como identificador com√∫n y \n# manteniendo todos los valores de wa\nmerge(wa,wb, by=c(\"country\"), all=T)"
  },
  {
    "objectID": "S_2_Datos.html#creaci√≥n-de-indicadores",
    "href": "S_2_Datos.html#creaci√≥n-de-indicadores",
    "title": "‚ÄòPicando‚Äô datos",
    "section": "Creaci√≥n de indicadores",
    "text": "Creaci√≥n de indicadores\n\nAbrir y Explorar los Datos\nEl primer paso en cualquier an√°lisis de datos es conocer tus datos. Por lo tanto, la acci√≥n inicial es abrir el conjunto de datos en R y entender qu√© representa cada variable y verificar si la informaci√≥n es consistente.\nAbramos y exploremos el conjunto de datos edu_nacion.xlsx:\n\n\nCode\nlibrary(openxlsx)\n\n# Abre los datos tratados\nd &lt;- read.xlsx(\"https://www.dropbox.com/s/orz8fdeg8as00fl/edu_nacion.xlsx?dl=1\")\n\n# Examina los datos\nd\n\n\n\n\n\n\n\n\n\nLos siguientes pasos iniciar√°n con algunas verificaciones clave para asegurar la calidad de los datos antes de comenzar cualquier transformaci√≥n o an√°lisis de datos. Debido a la naturaleza del conjunto de datos que estamos utilizando como ejemplo, nos centraremos aqu√≠ en tres tareas principales:\n(a) An√°lisis de consistencia - Verificar si los datos son correctos y eliminar ambig√ºedades y errores. En nuestro caso, verificaremos si una variable contiene solo un tipo de informaci√≥n o m√°s y, si es m√°s, corregiremos el problema.\n(b) Unidades de observaci√≥n - Asegurarse de que todos los datos se midan en el mismo nivel, evitando comparaciones entre manzanas y naranjas.\n(c) Creaci√≥n de indicadores - Generar la informaci√≥n adecuada para realizar nuestros an√°lisis, ya que, en la mayor√≠a de los casos, los conjuntos de datos originales no contienen la informaci√≥n exacta que necesitamos y se requiere un tratamiento previo.\n\n\nAn√°lisis de Consistencia\nTodas las variables contienen solo UNA informaci√≥n o hay casos en los que las variables contienen m√°s de una informaci√≥n?\nPodemos ver que la variable com_prov es un desastre. Contiene espacios en blanco, el c√≥digo de las Comunidades Aut√≥nomas o Provincias y los nombres de cada una de ellas. Hay dos tipos de informaci√≥n aqu√≠: c√≥digos y nombres. Lo primero es separar los dos.\n\n\nCode\n# 1) Elimina espacios em blanco con la funci√≥n trimws()\nd$com_prov &lt;- trimws(d$com_prov)\n\n# 2) Separa los c√≥digos de los nombres con la funci√≥n substr() \n# para crear dos nuevas variables: code y name\n\n# Seleccionamos los dos primeros d√≠gitos de com_prov para\n# el c√≥digo de la provincia\nd$code &lt;- substr(d$com_prov, 1,2)\n\n# Seleccionamos todos los dem√°s caracteres a partir\n# del cuarto al √∫ltimo para encontrar el nombre de\n# las comunidades y provincias\nd$name &lt;- substr(d$com_prov, 4,nchar(d$com_prov))\n\n# Examina los resultados\nd[,c(\"com_prov\",\"code\",\"name\")]\n\n\n\n\n\n\n\n\n\n\n\nUnidades de Observaci√≥n\n¬øTodas las observaciones est√°n en la misma unidad?\nNo.¬†Podemos ver que el conjunto de datos contiene informaci√≥n sobre Provincias y Comunidades Aut√≥nomas. Este es un problema porque estamos tratando con informaci√≥n que est√° agregada a diferentes niveles. No se pueden comparar. Necesitamos separar el conjunto de datos original en dos: uno para Comunidades Aut√≥nomas y otro para Provincias.\nUsaremos filtros para crear estos dos data.frames. Este ejercicio nos brinda una excelente oportunidad para entrenar nuestras nuevas habilidades en la selecci√≥n de datos.\n\n\nCode\n## Segundo: separar diferentes unidades de observaci√≥n\n\n# Separar CCAA de Provincias\nd$com_prov\n\nd$ccaa &lt;- 0\nd$ccaa[c(1,10,14,16,18,21,23,33,39,44,48,51,56,58,60,62,66,68,70)] &lt;- 1\n\n# Crea un nuevo objecto con los dados de las CC. AA.\nca &lt;- d[d$ccaa==1,]\n\n# Crea un nuevo objecto con los dados de las provincias\npr &lt;- d[d$ccaa==0,]\n\n### Reordena los datos para que sean f√°ciles de examinar\nca &lt;- ca[,c(20,21,2:19)]\n\npr &lt;- pr[,c(20,21,2:19)]\n\n# Examina los resultados\nca\npr\n\n\n\n\n [1] \"01 Andaluc√≠a\"                   \"04 Almer√≠a\"                    \n [3] \"11 C√°diz\"                       \"14 C√≥rdoba\"                    \n [5] \"18 Granada\"                     \"21 Huelva\"                     \n [7] \"23 Ja√©n\"                        \"29 M√°laga\"                     \n [9] \"41 Sevilla\"                     \"02 Arag√≥n\"                     \n[11] \"22 Huesca\"                      \"44 Teruel\"                     \n[13] \"50 Zaragoza\"                    \"03 Asturias, Principado de\"    \n[15] \"33 Asturias\"                    \"04 Balears, Illes\"             \n[17] \"07 Balears, Illes\"              \"05 Canarias\"                   \n[19] \"35 Palmas, Las\"                 \"38 Santa Cruz de Tenerife\"     \n[21] \"06 Cantabria\"                   \"39 Cantabria\"                  \n[23] \"07 Castilla y Le√≥n\"             \"05 √Åvila\"                      \n[25] \"09 Burgos\"                      \"24 Le√≥n\"                       \n[27] \"34 Palencia\"                    \"37 Salamanca\"                  \n[29] \"40 Segovia\"                     \"42 Soria\"                      \n[31] \"47 Valladolid\"                  \"49 Zamora\"                     \n[33] \"08 Castilla - La Mancha\"        \"02 Albacete\"                   \n[35] \"13 Ciudad Real\"                 \"16 Cuenca\"                     \n[37] \"19 Guadalajara\"                 \"45 Toledo\"                     \n[39] \"09 Catalu√±a\"                    \"08 Barcelona\"                  \n[41] \"17 Girona\"                      \"25 Lleida\"                     \n[43] \"43 Tarragona\"                   \"10 Comunitat Valenciana\"       \n[45] \"03 Alicante/Alacant\"            \"12 Castell√≥n/Castell√≥\"         \n[47] \"46 Valencia/Val√®ncia\"           \"11 Extremadura\"                \n[49] \"06 Badajoz\"                     \"10 C√°ceres\"                    \n[51] \"12 Galicia\"                     \"15 Coru√±a, A\"                  \n[53] \"27 Lugo\"                        \"32 Ourense\"                    \n[55] \"36 Pontevedra\"                  \"13 Madrid, Comunidad de\"       \n[57] \"28 Madrid\"                      \"14 Murcia, Regi√≥n de\"          \n[59] \"30 Murcia\"                      \"15 Navarra, Comunidad Foral de\"\n[61] \"31 Navarra\"                     \"16 Pa√≠s Vasco\"                 \n[63] \"01 Araba/√Ålava\"                 \"48 Bizkaia\"                    \n[65] \"20 Gipuzkoa\"                    \"17 Rioja, La\"                  \n[67] \"26 Rioja, La\"                   \"18 Ceuta\"                      \n[69] \"51 Ceuta\"                       \"19 Melilla\"                    \n[71] \"52 Melilla\"                    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreaci√≥n de Indicadores\n¬øEres capaz de comparar los datos o necesitas calcular indicadores relativos?\nLos datos originales se expresan en n√∫meros absolutos. No tiene sentido decir que Madrid tiene 923,113 extranjeros en edad escolar mientras que Salamanca solo tiene 15,365. El tama√±o total de sus poblaciones es diferente. Por lo tanto, es crucial calcular n√∫meros relativos (proporciones, porcentajes o razones) para comparar provincias o Comunidades Aut√≥nomas.\nPuesto que este es un conjunto de datos sobre educaci√≥n, queremos crear indicadores diversos que nos permitan comparar tanto provincias o Comunidades Aut√≥nomas como grupos sociales (residentes nacidos en Espa√±a y extranjeros) en relaci√≥n con este tema en particular.\nLa primera cosa que necesitamos saber es cu√°ntas personas con 15 a√±os o m√°s hay en total, para espa√±oles y para extranjeros:\n\n\nCode\n# Totales\n\n# Total de personas con 15 a√±os o m√°s - poblaci√≥n total\npr$total_edu_val &lt;- pr$total_edu-pr$tot_edu_no_apl\n\n# Total de personas con 15 a√±os o m√°s - Espa√±oles\npr$es_edu_val &lt;- pr$total_edu_es-pr$es_edu_no_apl\n\n# Total de personas con 15 a√±os o m√°s - Extranjeros\npr$ex_edu_val &lt;- pr$total_edu_ex-pr$ex_edu_no_apl\n\n### Poblaci√≥n nacida en el extranjero \n\n# Porcentaje\npr$p_foreign &lt;- round(pr$total_edu_ex/pr$total_edu*100,1)\n\n# Ratio de extranjeros por espa√±ol\npr$rt_frgn_es &lt;- round(pr$total_edu_ex/pr$total_edu_es,2)\n\n# Compara los resultados\npr[,c(\"name\",\"total_edu_val\",\"es_edu_val\",\"ex_edu_val\",\"p_foreign\",         \n      \"rt_frgn_es\")]\n\n\n\n\n\n\n\n\n\nUna vez que tenemos estos n√∫meros, podemos calcular los porcentajes de cada nivel educativo para la poblaci√≥n total de 15 a√±os o m√°s.\n\n\nCode\n### Niveles educativos - poblaci√≥n total\n\n# Primaria - Poblaci√≥n total 15 o m√°s\npr$p_tot_edu_prim &lt;- round(pr$tot_edu_prim/\n                             pr$total_edu_val*100,1)\n\n# Secundaria - Poblaci√≥n total 15 o m√°s\npr$p_tot_edu_sec &lt;- round((pr$tot_edu_prietp_sec+\n                             pr$tot_edu_segetp_sec)/\n                            pr$total_edu_val*100,1)\n\n# Universidad - Poblaci√≥n total 15 o m√°s\npr$p_tot_edu_uni &lt;- round(pr$tot_edu_sup/\n                            pr$total_edu_val*100,1)\n\n# Examina los resultados\npr[,c(\"name\",\"p_tot_edu_prim\",\"p_tot_edu_sec\",\"p_tot_edu_uni\")]\n\n\n\n\n\n\n\n\n\nAhora, creamos los mismos porcentajes para la poblaci√≥n nacida en Espa√±a.\n\n\nCode\n### Niveles educativos - nacidos en Espa√±a\n\n# Primaria - espa√±oles 15 o m√°s\npr$p_es_edu_prim &lt;- round(pr$es_edu_prim/pr$es_edu_val*100,1)\n\n# Secundaria - espa√±oles 15 o m√°s\npr$p_es_edu_sec &lt;- round((pr$es_edu_prietp_sec+pr$es_edu_segetp_sec)/pr$es_edu_val*100,1)\n\n# Universidad - espa√±oles 15 o m√°s\npr$p_es_edu_uni &lt;- round(pr$es_edu_sup/pr$es_edu_val*100,1)\n\n# Examina los resultados\npr[,c(\"name\",\"p_es_edu_prim\",\"p_es_edu_sec\",\"p_es_edu_uni\")]\n\n\n\n\n\n\n\n\n\nEjercicio 1\nRepite el ejercicio y crea los porcentajes para la poblaci√≥n nacida en el extranjero.\n\n\nCode\n### Niveles educativos - nacidos en el extranjero\n\n# Primaria - extranjero 15 o m√°s\npr$p_ex_edu_prim &lt;- round(pr$ex_edu_prim/pr$ex_edu_val*100,1)\n\n# Secundaria - extranjero 15 o m√°s\npr$p_ex_edu_sec &lt;- round((pr$ex_edu_prietp_sec+pr$ex_edu_segetp_sec)/pr$ex_edu_val*100,1)\n\n# Universidad - extranjero 15 o m√°s\npr$p_ex_edu_uni &lt;- round(pr$ex_edu_sup/pr$ex_edu_val*100,1)\n\n# Examinemos los resultados\npr[,c(\"name\",\"p_ex_edu_prim\",\"p_ex_edu_sec\",\"p_ex_edu_uni\")]\n\n\n\n\n\n\n\n\n\nEjercicio 2\nUna vez que tenemos los datos para ambos grupos, con estas variables b√°sicas, ¬øqu√© otras variables o √≠ndices podr√≠an calcularse a partir de los datos? Sugiere al menos dos.\n\n\nCode\n# ALGUNAS SUGERENCIAS:\n\n# Calcular la ratio entre nacidos en el extranjero \n# y en Espa√±a para cada nivel educativo. \n\n# Tal ratio nos permitir√° verificar el n√∫mero de \n# extranjeros por cada nacido en Espa√±a para cada\n# nivel educativo. N√∫meros POR DEBAJO de 1\n# muestran que hay menos (nacidos) EXTRANJEROS que espa√±oles\n# con ese nivel educativo. N√∫meros POR ENCIMA de 1\n# representan que hay m√°s extranjeros que espa√±oles.\n\n# Primaria\npr$rt_pr &lt;- round(pr$p_ex_edu_prim/pr$p_es_edu_prim,2)\n\n# Secundaria\npr$rt_sc &lt;- round(pr$p_ex_edu_sec/pr$p_es_edu_sec,2)\n\n# Universidad\npr$rt_su &lt;- round(pr$p_ex_edu_uni/pr$p_es_edu_uni,2)\n\n# La pr√≥xima variable mide el grado de \n# desigualdad entre extranjeros y espa√±oles\n# en cuanto a educaci√≥n.\npr$desv &lt;- round(\n                  (\n                    abs(1-pr$rt_pr)+\n                    abs(1-pr$rt_sc)+\n                    abs(1-pr$rt_su)\n                    )/3,\n                  2)\n\n# Esta √∫ltima variable normaliza la anterior\n# convirtiendo los valores a un rango de 0-1,\n# donde 0 representa total igualdad entre\n# extranjeros y espa√±oles y 1 una desigualdad\n# absoluta entre ambos grupos.\npr$n_desv &lt;- round((pr$desv-min(pr$desv))/\n                     (max(pr$desv)-min(pr$desv)),2)\n\n# Examinemos los resultados\npr[,c(\"name\",\"rt_pr\",\"rt_sc\",\"rt_su\",\"desv\",\"n_desv\")]\n\n\n\n\n\n\n\n\n\nEjercicio 3 (en casa)\nRepita el proceso que acabamos de terminar utilizando el conjunto de datos que contiene la informaci√≥n agregada a nivel de Comunidad Aut√≥noma (ca data.frame).\n\n\nCode\n# Totales\n\n# Total 15 a√±os o m√°s - poblaci√≥n total\nca$total_edu_val &lt;- ca$total_edu-ca$tot_edu_no_apl\n\n# Total 15 a√±os o m√°s - espa√±oles\nca$es_edu_val &lt;- ca$total_edu_es-ca$es_edu_no_apl\n\n# Total 15 a√±os o m√°s - poblaci√≥n extranjera\nca$ex_edu_val &lt;- ca$total_edu_ex-ca$ex_edu_no_apl\n\n### Extranjeros\n\n# Porcentaje\nca$p_foreign &lt;- round(ca$total_edu_ex/ca$total_edu*100,1)\n\n# Ratio Extranjeros/Espa√±ol\nca$rt_frgn_es &lt;- round(ca$total_edu_ex/ca$total_edu_es,2)\n\n### Niveles educativos - poblaci√≥n total\n\n# Primaria - poblaci√≥n total 15 o m√°s\nca$p_tot_edu_prim &lt;- round(ca$tot_edu_prim/\n                             ca$total_edu_val*100,1)\n\n# Secundaria - poblaci√≥n total 15 o m√°s\nca$p_tot_edu_sec &lt;- round((ca$tot_edu_prietp_sec+\n                             ca$tot_edu_segetp_sec)/\n                            ca$total_edu_val*100,1)\n\n# Universidad - poblaci√≥n total 15 o m√°s\nca$p_tot_edu_uni &lt;- round(ca$tot_edu_sup/\n                            ca$total_edu_val*100,1)\n\n### Educaci√≥n - Espa√±oles\n\n# Primaria - espa√±oles 15 o m√°s\nca$p_es_edu_prim &lt;- round(ca$es_edu_prim/ca$es_edu_val*100,1)\n\n# Secundaria - espa√±oles 15 o m√°s\nca$p_es_edu_sec &lt;- round((ca$es_edu_prietp_sec+ca$es_edu_segetp_sec)/ca$es_edu_val*100,1)\n\n# Universidad - espa√±oles 15 o m√°s\nca$p_es_edu_uni &lt;- round(ca$es_edu_sup/ca$es_edu_val*100,1)\n\n\n### Educaci√≥n - Extranjeros\n\n# Primaria - extranjeros 15 o m√°s\nca$p_ex_edu_prim &lt;- round(ca$ex_edu_prim/ca$ex_edu_val*100,1)\n\n# Secundaria - extranjeros 15 o m√°s\nca$p_ex_edu_sec &lt;- round((ca$ex_edu_prietp_sec+ca$ex_edu_segetp_sec)/ca$ex_edu_val*100,1)\n\n# Universidad - extranjeros 15 o m√°s\nca$p_ex_edu_uni &lt;- round(ca$ex_edu_sup/ca$ex_edu_val*100,1)\n\n# Examina los resultados\nca"
  },
  {
    "objectID": "S_3_Analisis.html",
    "href": "S_3_Analisis.html",
    "title": "An√°lisis",
    "section": "",
    "text": "La tendencia central es una medida que resume la distribuci√≥n de un conjunto de datos en un solo valor. Las medidas de tendencia central m√°s comunes son la media, la mediana y la moda.\nCuando queremos saber m√°s sobre los estudiantes en clase, por ejemplo, generalmente empleamos algunas se√±ales de informaci√≥n para ayudarnos a comprender un poco mejor qui√©nes son. La edad es uno de esos tipos de informaci√≥n. Nuestra pregunta es: ¬øcu√°ntos a√±os tienen los estudiantes? La composici√≥n por sexo es otra: ¬øcu√°ntos son mujeres y cu√°ntos son hombres? Sus calificaciones en cursos anteriores tambi√©n nos ayudan a conocerlos.\nLas medidas de tendencia central son herramientas para resumir datos sobre individuos o grupos que nos permiten comprender un poco mejor qui√©nes son o cu√°l es el comportamiento esperado en situaciones concretas.\n\n\n\nComo acabamos de ver, las medidas de tendencia central son la media, la mediana y la moda. Las dos primeras tienen funciones nativas en R para calcularlas, mientras que la tercera es menos utilizada en an√°lisis comunes, por lo que fue descartada desde el principio.\nUsaremos un data.frame llamado d basado en el data.frame states del paquete polscidata para ilustrar los conceptos y realizar ejercicios.\n\n\nLa funci√≥n mean() calcula el valor promedio o media de una variable dada. Tiene dos par√°metros principales a tener en cuenta: x - la variable de la que deseamos calcular la media; y na.rm - indicando si queremos excluir los valores faltantes en el c√°lculo o no.\nCalculemos la media de la variable unemploy (% de desempleo en cada Estado) de nuestro data.frame d. Recuerda: es necesario usar el signo de d√≥lar ($) despu√©s del nombre del data.frame para referirse a una variable. En este caso, ser√≠a d$unemploy. As√≠ que hag√°moslo:\n\n\nCode\nmean(d$unemploy)\n\n\n[1] 5.188\n\n\nEl paro medio en los 50 Estados de Estados Unidos es del 5.2 (5.188 para ser exactos).\nAhora, repitamos la operaci√≥n para la variable relig_import (importancia de la religi√≥n):\n\n\nCode\nmean(d$relig_import)\n\n\n[1] NA\n\n\nComo puedes ver, el resultado fue NA (No Disponible). Ver√°s este acr√≥nimo cada vez que encuentres datos faltantes en R. Para eliminar los casos faltantes, necesitamos usar na.rm=TRUE como par√°metro.\n\n\nCode\nmean(d$relig_import, na.rm = TRUE)\n\n\n[1] 37.31751\n\n\nAhora, te toca a ti. Calcula la media para las variables urban (% de poblaci√≥n urbana) y permit (% de la poblaci√≥n que ‚ÄúSiempre permite‚Äù el aborto).\n\n\nCode\nmean(d$urban)\n\n\n[1] 71.694\n\n\nCode\nmean(d$permit, na.rm = TRUE)\n\n\n[1] 36.6875\n\n\n\n\n\nLa segunda medida es la mediana, que separa los valores entre dos grupos con el mismo tama√±o. La funci√≥n es median() y tiene los mismos par√°metros mencionados para la media: x - la variable de la que deseamos calcular la media; y na.rm - indicando si queremos excluir los valores faltantes en el c√°lculo o no.\nAhora, en lugar de calcular la media, calculemos la mediana para la variable unemploy (% de desempleo en cada Estado) de nuestro data.frame d.\n\n\nCode\nmedian(d$unemploy)\n\n\n[1] 5.25\n\n\nLa tasa de desempleo mediana, la que separa los 50 Estados de Estados Unidos en dos grupos de 25 estados, es 5.25.\nAhora, repitamos la operaci√≥n para la variable relig_import (importancia de la religi√≥n):\n\n\nCode\nmedian(d$relig_import)\n\n\n[1] NA\n\n\nComo puedes ver, el resultado fue NA (No Disponible). Al igual que en el ejemplo anterior, necesitamos usar na.rm=TRUE como par√°metro.\n\n\nCode\nmedian(d$relig_import, na.rm = TRUE)\n\n\n[1] 33.98906\n\n\nDe nuevo, te toca. Calcula la mediana para las variables urban (% de poblaci√≥n urbana) y permit (% de la poblaci√≥n que ‚ÄúSiempre permite‚Äù el aborto).\n\n\nCode\nmedian(d$urban)\n\n\n[1] 71.5\n\n\nCode\nmedian(d$permit, na.rm = TRUE)\n\n\n[1] 35.9\n\n\n\n\n\nLa tercera medida es la moda. Es el valor m√°s frecuente en los datos. Tiene poco sentido calcular la moda para variables continuas, pero puede proporcionar informaci√≥n general para n√∫meros enteros (la edad m√°s com√∫n en un grupo o el n√∫mero de veces que un equipo nacional de f√∫tbol gan√≥ la Copa del Mundo ;-) ). No hay una funci√≥n para calcular la moda como tal en R. Podemos hacerlo usando la funci√≥n table() y simplemente seleccionando el valor m√°s alto.\nEn el fragmento de c√≥digo a continuaci√≥n, creo una funci√≥n llamada calcMode() que:\n\ncuenta la frecuencia de cada valor de la variable\nordena los valores en orden decreciente y selecciona el primer valor\ndevuelve la Moda y su frecuencia.\n\nAhora, vamos a usarla para calcular la moda de la variable gunlaw_rank.\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para la variable gunlaw_rank\ncalcMode(d$gunlaw_rank)\n\n\n[1] \"Mode: 36 - Frequency: 6 times.\"\n\n\nEsta funci√≥n tambi√©n se puede usar para variables categ√≥ricas. Repitamos el ejercicio para la variable cig_tax12_3 (Impuestos sobre los cigarrillos):\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para variable cig_tax12_3\ncalcMode(d$cig_tax12_3)\n\n\n[1] \"Mode: MidTax - Frequency: 18 times.\"\n\n\nEs tu turno. Copia la funci√≥n y calcula la moda para la variable pot_policy (Leyes de la marihuana):\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para la variable pot_policy\ncalcMode(d$pot_policy)\n\n\n[1] \"Mode: Not legal - Frequency: 18 times.\""
  },
  {
    "objectID": "S_3_Analisis.html#medidas-de-tendencia-central",
    "href": "S_3_Analisis.html#medidas-de-tendencia-central",
    "title": "An√°lisis",
    "section": "",
    "text": "La tendencia central es una medida que resume la distribuci√≥n de un conjunto de datos en un solo valor. Las medidas de tendencia central m√°s comunes son la media, la mediana y la moda.\nCuando queremos saber m√°s sobre los estudiantes en clase, por ejemplo, generalmente empleamos algunas se√±ales de informaci√≥n para ayudarnos a comprender un poco mejor qui√©nes son. La edad es uno de esos tipos de informaci√≥n. Nuestra pregunta es: ¬øcu√°ntos a√±os tienen los estudiantes? La composici√≥n por sexo es otra: ¬øcu√°ntos son mujeres y cu√°ntos son hombres? Sus calificaciones en cursos anteriores tambi√©n nos ayudan a conocerlos.\nLas medidas de tendencia central son herramientas para resumir datos sobre individuos o grupos que nos permiten comprender un poco mejor qui√©nes son o cu√°l es el comportamiento esperado en situaciones concretas.\n\n\n\nComo acabamos de ver, las medidas de tendencia central son la media, la mediana y la moda. Las dos primeras tienen funciones nativas en R para calcularlas, mientras que la tercera es menos utilizada en an√°lisis comunes, por lo que fue descartada desde el principio.\nUsaremos un data.frame llamado d basado en el data.frame states del paquete polscidata para ilustrar los conceptos y realizar ejercicios.\n\n\nLa funci√≥n mean() calcula el valor promedio o media de una variable dada. Tiene dos par√°metros principales a tener en cuenta: x - la variable de la que deseamos calcular la media; y na.rm - indicando si queremos excluir los valores faltantes en el c√°lculo o no.\nCalculemos la media de la variable unemploy (% de desempleo en cada Estado) de nuestro data.frame d. Recuerda: es necesario usar el signo de d√≥lar ($) despu√©s del nombre del data.frame para referirse a una variable. En este caso, ser√≠a d$unemploy. As√≠ que hag√°moslo:\n\n\nCode\nmean(d$unemploy)\n\n\n[1] 5.188\n\n\nEl paro medio en los 50 Estados de Estados Unidos es del 5.2 (5.188 para ser exactos).\nAhora, repitamos la operaci√≥n para la variable relig_import (importancia de la religi√≥n):\n\n\nCode\nmean(d$relig_import)\n\n\n[1] NA\n\n\nComo puedes ver, el resultado fue NA (No Disponible). Ver√°s este acr√≥nimo cada vez que encuentres datos faltantes en R. Para eliminar los casos faltantes, necesitamos usar na.rm=TRUE como par√°metro.\n\n\nCode\nmean(d$relig_import, na.rm = TRUE)\n\n\n[1] 37.31751\n\n\nAhora, te toca a ti. Calcula la media para las variables urban (% de poblaci√≥n urbana) y permit (% de la poblaci√≥n que ‚ÄúSiempre permite‚Äù el aborto).\n\n\nCode\nmean(d$urban)\n\n\n[1] 71.694\n\n\nCode\nmean(d$permit, na.rm = TRUE)\n\n\n[1] 36.6875\n\n\n\n\n\nLa segunda medida es la mediana, que separa los valores entre dos grupos con el mismo tama√±o. La funci√≥n es median() y tiene los mismos par√°metros mencionados para la media: x - la variable de la que deseamos calcular la media; y na.rm - indicando si queremos excluir los valores faltantes en el c√°lculo o no.\nAhora, en lugar de calcular la media, calculemos la mediana para la variable unemploy (% de desempleo en cada Estado) de nuestro data.frame d.\n\n\nCode\nmedian(d$unemploy)\n\n\n[1] 5.25\n\n\nLa tasa de desempleo mediana, la que separa los 50 Estados de Estados Unidos en dos grupos de 25 estados, es 5.25.\nAhora, repitamos la operaci√≥n para la variable relig_import (importancia de la religi√≥n):\n\n\nCode\nmedian(d$relig_import)\n\n\n[1] NA\n\n\nComo puedes ver, el resultado fue NA (No Disponible). Al igual que en el ejemplo anterior, necesitamos usar na.rm=TRUE como par√°metro.\n\n\nCode\nmedian(d$relig_import, na.rm = TRUE)\n\n\n[1] 33.98906\n\n\nDe nuevo, te toca. Calcula la mediana para las variables urban (% de poblaci√≥n urbana) y permit (% de la poblaci√≥n que ‚ÄúSiempre permite‚Äù el aborto).\n\n\nCode\nmedian(d$urban)\n\n\n[1] 71.5\n\n\nCode\nmedian(d$permit, na.rm = TRUE)\n\n\n[1] 35.9\n\n\n\n\n\nLa tercera medida es la moda. Es el valor m√°s frecuente en los datos. Tiene poco sentido calcular la moda para variables continuas, pero puede proporcionar informaci√≥n general para n√∫meros enteros (la edad m√°s com√∫n en un grupo o el n√∫mero de veces que un equipo nacional de f√∫tbol gan√≥ la Copa del Mundo ;-) ). No hay una funci√≥n para calcular la moda como tal en R. Podemos hacerlo usando la funci√≥n table() y simplemente seleccionando el valor m√°s alto.\nEn el fragmento de c√≥digo a continuaci√≥n, creo una funci√≥n llamada calcMode() que:\n\ncuenta la frecuencia de cada valor de la variable\nordena los valores en orden decreciente y selecciona el primer valor\ndevuelve la Moda y su frecuencia.\n\nAhora, vamos a usarla para calcular la moda de la variable gunlaw_rank.\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para la variable gunlaw_rank\ncalcMode(d$gunlaw_rank)\n\n\n[1] \"Mode: 36 - Frequency: 6 times.\"\n\n\nEsta funci√≥n tambi√©n se puede usar para variables categ√≥ricas. Repitamos el ejercicio para la variable cig_tax12_3 (Impuestos sobre los cigarrillos):\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para variable cig_tax12_3\ncalcMode(d$cig_tax12_3)\n\n\n[1] \"Mode: MidTax - Frequency: 18 times.\"\n\n\nEs tu turno. Copia la funci√≥n y calcula la moda para la variable pot_policy (Leyes de la marihuana):\n\n\nCode\n# Crea la funci√≥n para calcular la moda\ncalcMode &lt;- function(var){\n\n  # Averigua cu√°l valor aparece m√°s  \n  tb &lt;-  sort(table(var), decreasing = T)[1]\n  \n  # Informa los resultados\n  paste0(\"Mode: \", names(tb), \" - Frequency: \", tb, \" times.\")\n\n}\n\n# Calcula la moda para la variable pot_policy\ncalcMode(d$pot_policy)\n\n\n[1] \"Mode: Not legal - Frequency: 18 times.\""
  },
  {
    "objectID": "S_3_Analisis.html#medidas-de-dispersi√≥n-dispersi√≥n-y-varianza",
    "href": "S_3_Analisis.html#medidas-de-dispersi√≥n-dispersi√≥n-y-varianza",
    "title": "An√°lisis",
    "section": "Medidas de Dispersi√≥n: Dispersi√≥n y Varianza",
    "text": "Medidas de Dispersi√≥n: Dispersi√≥n y Varianza\n\n¬øQu√© es la Dispersi√≥n y la Varianza?\nEl video a continuaci√≥n explica las principales medidas de dispersi√≥n: rango, rango intercuartil, varianza y desviaci√≥n est√°ndar.\n\n\n\nMedidas de Dispersi√≥n en R\n\nINTERVALO o RANGO\nLa funci√≥n range() calcula el rango para cualquier variable NUM√âRICA dada en un data.frame, y devuelve los valores m√≠nimo y m√°ximo.\n\n\nCode\nrange(d$urban)\n\n\n[1] 38.2 94.4\n\n\nAhora calcula el rango para las variables prochoice (% de la poblaci√≥n pro-elecci√≥n) y permit.\n\n\nCode\nrange(d$prochoice)\n\n\n[1] 33 70\n\n\nCode\n# Puesto que permit contiene casos perdidos, \n# resulta importante usar el par√°metro na.rm=TRUE\nrange(d$permit, na.rm = TRUE)\n\n\n[1] 15.5 58.5\n\n\n\n\nIQR - Rango Intercuartiles\nLos cuartiles son valores que separan una variable en cuatro grupos iguales con el mismo tama√±o. Indican los valores que representan las posiciones del 25% inferior, 50% y 75% de los casos ordenados de menor a mayor. El rango intercuartil selecciona solo los cuartiles que marcan el 50% de las observaciones en el medio, dejando fuera el 25% inferior y el 25% superior. Esto ayuda a incluir los extremos en la evaluaci√≥n de la dispersi√≥n de valores.\nMira este breve video para entender cuartiles, percentiles, deciles, etc‚Ä¶\n\nLa funci√≥n IQR() calcula el rango intercuartil para una variable dada. Resta el segundo cuartil al tercero: Q3-Q2.\nEl c√≥digo a continuaci√≥n calcula el rango intercuartil para la variable urban.\n\n\nCode\nIQR(d$urban)\n\n\n[1] 25.05\n\n\nAhora, repite la operaci√≥n para la variable permit.\n\n\nCode\nIQR(d$permit,na.rm = TRUE)\n\n\n[1] 15.45\n\n\n\n\nVARIANZA\nLos mismos principios se aplican a la varianza, calculada por la funci√≥n var(). Los par√°metros son los mismos que las funciones mean() y median().\nCalculemos la varianza de la variable urban:\n\n\nCode\nvar(d$urban)\n\n\n[1] 222.0842\n\n\nAhora, calcula la varianza de las variables over64 (% de edad 65 o superior) y permit.\n\n\nCode\nvar(d$over64)\n\n\n[1] 3.034371\n\n\nCode\nvar(d$permit,na.rm = TRUE)\n\n\n[1] 99.15958\n\n\n\n\nDesviaci√≥n Est√°ndar\nLa desviaci√≥n est√°ndar es la √∫ltima medida de dispersi√≥n considerada en este tutorial. Se mide en la funci√≥n sd() de R.\nCalculemos la desviaci√≥n est√°ndar de la variable urban:\n\n\nCode\nsd(d$urban)\n\n\n[1] 14.90249\n\n\nCalcula ahora la desviaci√≥n est√°ndar de las variables over64 (% de edad 65 o superior) y permit.\n\n\nCode\nsd(d$over64)\n\n\n[1] 1.741945\n\n\nCode\nsd(d$permit,na.rm = TRUE)\n\n\n[1] 9.957891"
  },
  {
    "objectID": "S_3_Analisis.html#trabajando-con-datos-categ√≥ricos-frecuencias",
    "href": "S_3_Analisis.html#trabajando-con-datos-categ√≥ricos-frecuencias",
    "title": "An√°lisis",
    "section": "Trabajando con Datos Categ√≥ricos: Frecuencias",
    "text": "Trabajando con Datos Categ√≥ricos: Frecuencias\n\nFrecuencias de datos categ√≥ricos\nMira el video a continuaci√≥n para entender c√≥mo calcular datos categ√≥ricos:\n\n\n\nTablas de Frecuencia en R\nLas tablas de frecuencia son la forma m√°s adecuada de resumir datos categ√≥ricos. Una vez que tenemos las frecuencias, podemos usarlas para calcular una serie de otras estad√≠sticas e indicadores.\nLa funci√≥n table() en R devuelve los recuentos de cada categor√≠a en una variable dada. Vamos a usarla para devolver el tipo de pol√≠tica de g√©nero que mantienen los EE. UU.:\n\n\nCode\ntable(d$gay_policy)\n\n\n\n     Most liberal           Liberal      Conservative Most conservative \n                6                14                10                20 \n\n\nComo podemos observar, la mayor√≠a de los estados son Conservadores (10) o Muy Conservadores (20). Si quisi√©ramos expresar estos n√∫meros en porcentajes, necesitar√≠amos dividir los resultados por el n√∫mero total de casos o usar la funci√≥n prop.table(). Hag√°moslo:\n\n\nCode\n# Dividiendo los resultados por el total\n# de observaciones y, entonces, \n# multiplicando por 100 \ntable(d$gay_policy)/sum(table(d$gay_policy))*100\n\n\n\n     Most liberal           Liberal      Conservative Most conservative \n               12                28                20                40 \n\n\nCode\n# Usando la funci√≥n prop.table() y, \n# entonces, multiplicando por 100\nprop.table(table(d$gay_policy))*100\n\n\n\n     Most liberal           Liberal      Conservative Most conservative \n               12                28                20                40"
  },
  {
    "objectID": "S_3_Analisis.html#explorando-la-distribuci√≥n-de-datos-en-r",
    "href": "S_3_Analisis.html#explorando-la-distribuci√≥n-de-datos-en-r",
    "title": "An√°lisis",
    "section": "Explorando la Distribuci√≥n de Datos en R",
    "text": "Explorando la Distribuci√≥n de Datos en R\n\nExplorando los data.frames\nLa s√≠ntesis de datos en R se refiere al proceso de reducir un conjunto de datos a un tama√±o m√°s manejable mediante la agregaci√≥n o extracci√≥n de informaci√≥n clave de √©l. Esto se puede hacer utilizando varias funciones de R como summarize() y aggregate() que le permiten realizar c√°lculos como la media, la mediana y la desviaci√≥n est√°ndar en columnas espec√≠ficas o grupos de datos. Adem√°s, la funci√≥n describe() proporciona un resumen r√°pido de estad√≠sticas b√°sicas para un conjunto de datos dado. Otros paquetes de R como dplyr y tidyr tambi√©n proporcionan funciones √∫tiles para la s√≠ntesis y manipulaci√≥n de datos.\nLa funci√≥n summary() en R es una funci√≥n gen√©rica que se utiliza para producir un resumen de varios tipos de objetos de R, como vectores, matrices, listas, marcos de datos y modelos. Cuando se aplica a un vector o un marco de datos, summary() devuelve una variedad de estad√≠sticas resumidas, como la media, la mediana, la desviaci√≥n est√°ndar, los valores m√≠nimos y m√°ximos del vector o marco de datos.\nPor ejemplo, si tenemos un marco de datos llamado d podemos usar el siguiente comando para obtener un resumen del marco de datos:\n\n\nCode\nsummary(d)\n\n\n     abort_rank3 abortion_rank12  adv_or_more       ba_or_more   \n More restr:17   Min.   : 1.00   Min.   : 6.100   Min.   :17.30  \n Mid       :17   1st Qu.:13.25   1st Qu.: 7.950   1st Qu.:24.15  \n Less restr:16   Median :25.50   Median : 9.200   Median :26.45  \n                 Mean   :25.50   Mean   : 9.794   Mean   :27.17  \n                 3rd Qu.:37.75   3rd Qu.:11.000   3rd Qu.:30.35  \n                 Max.   :50.00   Max.   :16.400   Max.   :38.20  \n                                                                 \n   cig_tax12     cig_tax12_3 conserv_advantage conserv_public \n Min.   :0.170   LoTax :17   Min.   :-2.20     Min.   :26.80  \n 1st Qu.:0.625   MidTax:18   1st Qu.:10.28     1st Qu.:33.92  \n Median :1.349   HiTax :15   Median :19.00     Median :38.65  \n Mean   :1.464               Mean   :17.71     Mean   :38.40  \n 3rd Qu.:2.000               3rd Qu.:25.77     3rd Qu.:42.90  \n Max.   :4.350               Max.   :36.00     Max.   :51.40  \n                                                              \n dem_advantage      govt_worker         gun_rank3    gun_rank11   \n Min.   :-36.700   Min.   :11.50   More restr:15   Min.   : 1.00  \n 1st Qu.: -4.875   1st Qu.:14.12   Mid       :14   1st Qu.:15.00  \n Median :  0.950   Median :15.85   Less restr:21   Median :26.00  \n Mean   :  0.948   Mean   :16.61                   Mean   :27.02  \n 3rd Qu.: 10.925   3rd Qu.:17.77                   3rd Qu.:39.00  \n Max.   : 24.000   Max.   :28.00                   Max.   :50.00  \n                                                                  \n  gun_scale11    hr_cons_rank11   hr_conserv11   hr_lib_rank11  \n Min.   : 0.00   Min.   : 43.0   Min.   :13.08   Min.   : 51.0  \n 1st Qu.: 4.00   1st Qu.:150.4   1st Qu.:44.97   1st Qu.:183.7  \n Median : 6.50   Median :197.2   Median :56.08   Median :232.3  \n Mean   :16.04   Mean   :207.5   Mean   :52.81   Mean   :221.0  \n 3rd Qu.:15.00   3rd Qu.:244.7   3rd Qu.:65.54   3rd Qu.:277.9  \n Max.   :81.00   Max.   :377.5   Max.   :85.38   Max.   :385.0  \n                                                                \n  hr_liberal11      hs_or_more      obama2012     obama_win12\n Min.   : 14.62   Min.   :79.90   Min.   :24.67   No :24     \n 1st Qu.: 34.46   1st Qu.:83.97   1st Qu.:40.05   Yes:26     \n Median : 44.53   Median :87.50   Median :50.24              \n Mean   : 49.26   Mean   :86.87   Mean   :48.16              \n 3rd Qu.: 55.91   3rd Qu.:89.80   3rd Qu.:55.42              \n Max.   :104.49   Max.   :91.80   Max.   :70.55              \n                                                             \n    pop2000            pop2010         pop2010_hun_thou   popchng0010     \n Min.   :  493782   Min.   :  563626   Min.   :  5.636   Min.   : -54804  \n 1st Qu.: 1735533   1st Qu.: 1833004   1st Qu.: 18.330   1st Qu.: 114520  \n Median : 4026890   Median : 4436370   Median : 44.364   Median : 299148  \n Mean   : 5616997   Mean   : 6162876   Mean   : 61.629   Mean   : 545879  \n 3rd Qu.: 6281944   3rd Qu.: 6680312   3rd Qu.: 66.803   3rd Qu.: 517304  \n Max.   :33871648   Max.   :37253956   Max.   :372.540   Max.   :4293741  \n                                                                          \n   popchngpct                   pot_policy   prochoice        prolife     \n Min.   :-0.600   Not legal          :18   Min.   :33.00   Min.   :25.00  \n 1st Qu.: 4.350   Pending legis      : 8   1st Qu.:47.00   1st Qu.:33.00  \n Median : 7.850   Decrim             : 6   Median :55.50   Median :40.00  \n Mean   : 9.852   Medicinal          :10   Mean   :53.66   Mean   :40.66  \n 3rd Qu.:13.900   Medicinal / Decrim.: 8   3rd Qu.:62.75   3rd Qu.:47.75  \n Max.   :35.100                            Max.   :70.00   Max.   :61.00  \n                                                                          \n   relig_cath      relig_prot      relig_high      relig_low     religiosity3\n Min.   : 5.90   Min.   :12.30   Min.   :19.10   Min.   :11.20   Low :17     \n 1st Qu.:13.82   1st Qu.:42.62   1st Qu.:32.98   1st Qu.:26.30   Mid :17     \n Median :22.60   Median :51.60   Median :38.20   Median :31.85   High:16     \n Mean   :21.91   Mean   :52.40   Mean   :39.40   Mean   :31.99               \n 3rd Qu.:27.82   3rd Qu.:61.70   3rd Qu.:45.33   3rd Qu.:39.10               \n Max.   :44.10   Max.   :80.30   Max.   :58.40   Max.   :57.10               \n                                                                             \n   romney2012      smokers12        stateid      to_0812       uninsured_pct  \n Min.   :27.84   Min.   :11.00   AK     : 1   Min.   :-9.400   Min.   : 4.50  \n 1st Qu.:41.31   1st Qu.:19.00   AL     : 1   1st Qu.:-4.800   1st Qu.:13.95  \n Median :48.31   Median :21.00   AR     : 1   Median :-3.700   Median :16.80  \n Mean   :49.80   Mean   :21.06   AZ     : 1   Mean   :-3.520   Mean   :16.77  \n 3rd Qu.:57.86   3rd Qu.:24.00   CA     : 1   3rd Qu.:-2.025   3rd Qu.:20.40  \n Max.   :72.56   Max.   :29.00   CO     : 1   Max.   : 2.100   Max.   :28.80  \n                                 (Other):44                                   \n  abort_rate05    abort_rate08        abortlaw3    abortlaw10   \n Min.   : 0.70   Min.   : 0.90   0-5 restr :17   Min.   : 0.00  \n 1st Qu.: 9.05   1st Qu.: 9.00   6-8 restr :20   1st Qu.: 4.25  \n Median :14.10   Median :15.35   9-10 restr:13   Median : 6.50  \n Mean   :15.25   Mean   :15.62                   Mean   : 6.28  \n 3rd Qu.:18.88   3rd Qu.:19.00                   3rd Qu.: 8.75  \n Max.   :38.20   Max.   :40.00                   Max.   :10.00  \n                                                                \n    alcohol        attend_pct    battle04     blkleg         blkpct04    \n Min.   :1.330   Min.   :22.00   No :37   Min.   : 0.00   Min.   : 0.40  \n 1st Qu.:2.078   1st Qu.:32.00   Yes:13   1st Qu.: 2.00   1st Qu.: 2.60  \n Median :2.345   Median :38.00            Median : 4.50   Median : 7.15  \n Mean   :2.414   Mean   :38.94            Mean   : 7.54   Mean   :10.33  \n 3rd Qu.:2.618   3rd Qu.:46.50            3rd Qu.:13.75   3rd Qu.:15.55  \n Max.   :4.380   Max.   :60.00            Max.   :26.00   Max.   :36.80  \n                                                                         \n    blkpct08         blkpct10          bush00          bush04     \n Min.   : 0.700   Min.   : 0.800   Min.   :31.91   Min.   :36.78  \n 1st Qu.: 3.225   1st Qu.: 3.825   1st Qu.:44.81   1st Qu.:46.48  \n Median : 7.350   Median : 8.250   Median :50.59   Median :52.70  \n Mean   :10.532   Mean   :11.262   Mean   :50.44   Mean   :53.14  \n 3rd Qu.:15.575   3rd Qu.:15.925   3rd Qu.:56.79   3rd Qu.:59.52  \n Max.   :37.200   Max.   :37.600   Max.   :67.76   Max.   :71.54  \n                                                                  \n    carfatal       carfatal07       cig_tax             cig_tax_3 \n Min.   : 8.80   Min.   : 6.70   Min.   :0.0700   $.07-$.64  :17  \n 1st Qu.:13.20   1st Qu.:12.00   1st Qu.:0.5750   $.695-$1.36:17  \n Median :17.35   Median :15.10   Median :0.9875   $1.41-$2.58:16  \n Mean   :17.52   Mean   :15.96   Mean   :1.0744                   \n 3rd Qu.:21.55   3rd Qu.:19.02   3rd Qu.:1.5075                   \n Max.   :31.50   Max.   :31.60   Max.   :2.5800                   \n                                                                  \n   cigarettes        college         conpct_m       cons_hr06    \n Min.   : 2.400   Min.   :17.00   Min.   :22.38   Min.   : 7.60  \n 1st Qu.: 5.505   1st Qu.:23.12   1st Qu.:30.25   1st Qu.:39.82  \n Median : 7.215   Median :25.10   Median :33.78   Median :59.85  \n Mean   : 7.576   Mean   :25.85   Mean   :33.97   Mean   :55.87  \n 3rd Qu.: 8.668   3rd Qu.:29.00   3rd Qu.:38.26   3rd Qu.:70.94  \n Max.   :18.950   Max.   :35.90   Max.   :46.83   Max.   :91.00  \n                                                                 \n   cons_hr09        cook_index       cook_index3    defexpen     \n Min.   :  0.00   Min.   :-20.20   More Rep:17   Min.   : 282.0  \n 1st Qu.: 22.12   1st Qu.: -9.35   Even    :18   1st Qu.: 600.0  \n Median : 40.94   Median : -1.75   More Dem:15   Median : 931.5  \n Mean   : 41.67   Mean   : -2.47                 Mean   :1093.7  \n 3rd Qu.: 61.41   3rd Qu.:  4.30                 3rd Qu.:1262.8  \n Max.   :100.00   Max.   : 13.40                 Max.   :4425.0  \n                                                                 \n    demhr11          dem_hr09         demnat06         dempct_m    \n Min.   :  0.00   Min.   :  0.00   Min.   :  0.00   Min.   :22.94  \n 1st Qu.: 20.56   1st Qu.: 40.71   1st Qu.: 25.57   1st Qu.:31.18  \n Median : 33.33   Median : 62.50   Median : 40.00   Median :35.59  \n Mean   : 41.20   Mean   : 60.98   Mean   : 45.01   Mean   :35.42  \n 3rd Qu.: 58.89   3rd Qu.: 85.62   3rd Qu.: 66.67   3rd Qu.:39.92  \n Max.   :100.00   Max.   :166.67   Max.   :100.00   Max.   :50.72  \n                                                                   \n   demstate06      demstate09      demstate13       density       \n Min.   :24.76   Min.   :23.81   Min.   : 0.00   Min.   :   1.20  \n 1st Qu.:43.94   1st Qu.:46.00   1st Qu.:35.76   1st Qu.:  44.45  \n Median :55.80   Median :57.65   Median :43.98   Median :  98.75  \n Mean   :53.62   Mean   :55.26   Mean   :46.03   Mean   : 194.96  \n 3rd Qu.:60.71   3rd Qu.:64.29   3rd Qu.:58.73   3rd Qu.: 209.50  \n Max.   :88.00   Max.   :90.27   Max.   :89.47   Max.   :1195.50  \n NA's   :1       NA's   :1                                        \n           division  earmarks_pcap         evm             evo       \n South Atlantic: 8   Min.   : 10.00   Min.   : 0.00   Min.   : 0.00  \n Mountain      : 8   1st Qu.: 14.80   1st Qu.: 0.00   1st Qu.: 0.00  \n W. North Cent : 7   Median : 25.70   Median : 0.00   Median : 4.00  \n New England   : 6   Mean   : 42.41   Mean   : 3.46   Mean   : 7.24  \n E. North Cent : 5   3rd Qu.: 37.62   3rd Qu.: 5.75   3rd Qu.:10.75  \n Pacific       : 5   Max.   :425.50   Max.   :34.00   Max.   :55.00  \n (Other)       :11                                                   \n    evo2012         evr2012                  gay_policy       gay_policy2\n Min.   : 0.00   Min.   : 0.00   Most liberal     : 6   Liberal     :20  \n 1st Qu.: 0.00   1st Qu.: 0.00   Liberal          :14   Conservative:30  \n Median : 3.00   Median : 0.00   Conservative     :10                    \n Mean   : 6.58   Mean   : 4.12   Most conservative:20                    \n 3rd Qu.:10.00   3rd Qu.: 6.00                                           \n Max.   :55.00   Max.   :38.00                                           \n                                                                         \n gay_policy_con  gay_support    gay_support3     gb_win00       gb_win04 \n No :30         Min.   :38.00   Low :17      Gore win:20   Kerry win:19  \n Yes:20         1st Qu.:51.00   Med :20      Bush win:30   Bush win :31  \n                Median :56.00   High:13                                  \n                Mean   :55.34                                            \n                3rd Qu.:60.75                                            \n                Max.   :68.00                                            \n                                                                         \n     gore00        gun_check         gun_dealer       gun_murder10  \n Min.   :26.34   Min.   :  976.5   Min.   :  5.915   Min.   :0.300  \n 1st Qu.:40.93   1st Qu.: 4848.4   1st Qu.: 42.904   1st Qu.:1.225  \n Median :46.22   Median : 6970.4   Median : 50.582   Median :2.700  \n Mean   :45.23   Mean   : 6833.9   Mean   : 58.240   Mean   :2.500  \n 3rd Qu.:50.49   3rd Qu.: 8357.8   3rd Qu.: 66.630   3rd Qu.:3.275  \n Max.   :60.99   Max.   :13589.3   Max.   :146.956   Max.   :7.700  \n                 NA's   :1                                          \n  gun_rank_rev    gunlaw_rank       gunlaw_rank3_rev  gunlaw_scale  \n Min.   : 1.00   Min.   : 1.00   Fewer restr:15      Min.   : 2.00  \n 1st Qu.:13.00   1st Qu.:13.25   Mid        :17      1st Qu.: 6.00  \n Median :24.50   Median :24.50   More restr :18      Median :10.50  \n Mean   :24.48   Mean   :24.52                       Mean   :17.66  \n 3rd Qu.:35.75   3rd Qu.:36.00                       3rd Qu.:19.50  \n Max.   :48.00   Max.   :48.00                       Max.   :79.00  \n                                                                    \n   hispanic04       hispanic08       hispanic10       indpct_m    \n Min.   : 0.800   Min.   : 1.100   Min.   : 1.20   Min.   :19.01  \n 1st Qu.: 2.800   1st Qu.: 3.475   1st Qu.: 4.25   1st Qu.:29.73  \n Median : 5.750   Median : 6.800   Median : 8.20   Median :33.02  \n Mean   : 8.812   Mean   : 9.858   Mean   :10.61   Mean   :33.33  \n 3rd Qu.:10.100   3rd Qu.:11.450   3rd Qu.:12.22   3rd Qu.:37.43  \n Max.   :43.300   Max.   :44.900   Max.   :46.30   Max.   :50.78  \n                                                                  \n    kerry04         libpct_m        mccain08        modpct_m    \n Min.   :26.00   Min.   :12.70   Min.   :26.58   Min.   :38.44  \n 1st Qu.:39.37   1st Qu.:17.57   1st Qu.:40.52   1st Qu.:44.66  \n Median :46.57   Median :19.06   Median :47.45   Median :46.09  \n Mean   :45.67   Mean   :19.75   Mean   :47.81   Mean   :46.28  \n 3rd Qu.:52.45   3rd Qu.:22.13   3rd Qu.:56.03   3rd Qu.:47.64  \n Max.   :61.94   Max.   :30.07   Max.   :65.65   Max.   :54.46  \n                                                                \n    nader00           obama08          obama_win08     over64     \n Min.   : 0.5173   Min.   :32.54   McCain win:22   Min.   : 6.40  \n 1st Qu.: 1.8182   1st Qu.:42.63   Obama win :28   1st Qu.:12.03  \n Median : 2.6546   Median :51.15                   Median :12.75  \n Mean   : 3.2473   Mean   :50.47                   Mean   :12.55  \n 3rd Qu.: 4.2784   3rd Qu.:57.28                   3rd Qu.:13.30  \n Max.   :10.0669   Max.   :71.85                   Max.   :16.80  \n NA's   :3                                                        \n     permit        pop_18_24       pop_18_24_10       prcapinc    \n Min.   :15.50   Min.   : 8.534   Min.   : 8.724   Min.   :24650  \n 1st Qu.:29.95   1st Qu.: 9.613   1st Qu.: 9.571   1st Qu.:28643  \n Median :35.90   Median : 9.953   Median : 9.905   Median :31330  \n Mean   :36.69   Mean   :10.121   Mean   : 9.924   Mean   :31951  \n 3rd Qu.:45.40   3rd Qu.:10.635   3rd Qu.:10.151   3rd Qu.:34428  \n Max.   :58.50   Max.   :12.672   Max.   :12.036   Max.   :45398  \n NA's   :10                                                       \n       region    relig_import    religiosity        reppct_m      rtw    \n Northeast: 9   Min.   :21.14   Min.   :-180.0   Min.   :14.24   No :34  \n Midwest  :12   1st Qu.:29.56   1st Qu.:-139.8   1st Qu.:27.90   Yes:16  \n South    :16   Median :33.99   Median :-100.5   Median :31.13           \n West     :13   Mean   :37.32   Mean   : -97.6   Mean   :31.25           \n                3rd Qu.:43.34   3rd Qu.: -53.5   3rd Qu.:34.61           \n                Max.   :64.94   Max.   :  -4.0   Max.   :44.97           \n                NA's   :12                                               \n   secularism       secularism3 seniority_sen2      south   \n Min.   :  4.0   Religious:17   No :40         Nonsouth:34  \n 1st Qu.: 53.5   Middle   :17   Yes:10         South   :16  \n Median :100.5   Secular  :15                               \n Mean   : 97.6   NA's     : 1                               \n 3rd Qu.:139.8                                              \n Max.   :180.0                                              \n                                                            \n                                        state       to_0004       \n Alabama                                   : 1   Min.   :-12.390  \n Alaska                                    : 1   1st Qu.:  2.478  \n Arizona                                   : 1   Median :  4.180  \n Arkansas                                  : 1   Mean   :  4.063  \n California                                : 1   3rd Qu.:  6.735  \n Colorado                                  : 1   Max.   : 10.960  \n (Other)                                   :44                    \n    to_0408          trnout00        trnout04        unemploy    \n Min.   :-5.600   Min.   :43.49   Min.   :42.32   Min.   :3.400  \n 1st Qu.:-0.175   1st Qu.:49.63   1st Qu.:54.52   1st Qu.:4.625  \n Median : 1.150   Median :55.30   Median :58.64   Median :5.250  \n Mean   : 1.280   Mean   :55.31   Mean   :59.37   Mean   :5.188  \n 3rd Qu.: 2.875   3rd Qu.:60.36   3rd Qu.:64.17   3rd Qu.:5.800  \n Max.   : 8.000   Max.   :69.26   Max.   :76.18   Max.   :7.600  \n                                                                 \n    union04          union07         union10           urban      \n Min.   : 2.700   Min.   : 3.00   Min.   : 3.100   Min.   :38.20  \n 1st Qu.: 6.475   1st Qu.: 6.55   1st Qu.: 6.225   1st Qu.:60.65  \n Median :10.200   Median :10.45   Median :10.850   Median :71.50  \n Mean   :11.264   Mean   :11.18   Mean   :11.358   Mean   :71.69  \n 3rd Qu.:15.200   3rd Qu.:14.45   3rd Qu.:15.575   3rd Qu.:85.70  \n Max.   :25.300   Max.   :25.20   Max.   :25.200   Max.   :94.40  \n                                                                  \n vep00_turnout   vep04_turnout   vep08_turnout   vep12_turnout  \n Min.   :44.20   Min.   :48.20   Min.   :50.50   Min.   :44.20  \n 1st Qu.:50.10   1st Qu.:57.85   1st Qu.:59.62   1st Qu.:55.70  \n Median :56.05   Median :62.75   Median :64.00   Median :59.65  \n Mean   :55.83   Mean   :62.18   Mean   :63.46   Mean   :59.94  \n 3rd Qu.:59.90   3rd Qu.:66.15   3rd Qu.:67.42   3rd Qu.:63.95  \n Max.   :69.50   Max.   :78.40   Max.   :78.20   Max.   :75.70  \n                                                                \n  womleg_2007     womleg_2010     womleg_2011     womleg_2015   \n Min.   : 8.80   Min.   :10.00   Min.   : 9.40   Min.   :12.50  \n 1st Qu.:17.48   1st Qu.:19.62   1st Qu.:19.48   1st Qu.:19.30  \n Median :22.70   Median :23.55   Median :23.50   Median :24.40  \n Mean   :23.25   Mean   :24.12   Mean   :23.81   Mean   :24.16  \n 3rd Qu.:29.93   3rd Qu.:28.82   3rd Qu.:28.18   3rd Qu.:28.68  \n Max.   :37.80   Max.   :37.50   Max.   :41.00   Max.   :42.00  \n                                                                \n\n\nEsta funci√≥n har√° un resumen de cada columna en el marco de datos, incluyendo el n√∫mero de valores no faltantes, la media, la desviaci√≥n est√°ndar, los valores m√≠nimos y m√°ximos, junto con los cuartiles de los datos.\nTambi√©n es posible usar la funci√≥n summary() en columnas espec√≠ficas de un marco de datos llamando a la funci√≥n en la columna de inter√©s:\n\n\nCode\n# Resume la variable con el % de personas\n# con universidad.\nsummary(d$college)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  17.00   23.12   25.10   25.85   29.00   35.90 \n\n\nVale la pena se√±alar que la funci√≥n summary() tambi√©n funciona con otros tipos de objetos de R, como modelos, listas y matrices y la salida puede variar seg√∫n el tipo de objeto que se le pase.\nLa funci√≥n str() en R se utiliza para mostrar la estructura interna de un objeto de R. Es una funci√≥n gen√©rica que se puede utilizar para inspeccionar la estructura de varios tipos de objetos de R, incluyendo vectores, matrices, listas, marcos de datos y modelos.\nCuando se aplica a un data.frame, str() devuelve un resumen de la estructura del marco de datos, incluyendo el n√∫mero de filas y columnas, el nombre de cada columna y las primeras filas de datos. Por ejemplo:\n\n\nCode\n# Tipos de datos\nstr(d)\n\n\n'data.frame':   50 obs. of  135 variables:\n $ abort_rank3      : Factor w/ 3 levels \"More restr\",\"Mid\",..: 3 2 1 1 3 2 3 2 2 1 ...\n $ abortion_rank12  : num  35 20 4 5 49 25 45 30 26 9 ...\n $ adv_or_more      : num  9 7.7 6.1 9.3 10.7 12.7 15.5 11.4 9 9.9 ...\n $ ba_or_more       : num  26.6 22 18.9 25.6 29.9 35.9 35.6 28.7 25.3 27.5 ...\n $ cig_tax12        : num  2 0.425 1.15 2 0.87 ...\n $ cig_tax12_3      : Factor w/ 3 levels \"LoTax\",\"MidTax\",..: 3 1 2 3 2 2 3 2 2 1 ...\n $ conserv_advantage: num  21.3 36 26.7 19.5 6.3 15.7 1.8 6.3 17.2 25.8 ...\n $ conserv_public   : num  43.1 44.7 45.2 36 30.8 ...\n $ dem_advantage    : num  -12.2 -14.6 -1.4 -3.5 14.9 -2.4 17 15.9 4.5 -4.7 ...\n $ govt_worker      : num  28 17.5 17.6 15.5 14.9 15.7 15.9 16.1 14.5 17.8 ...\n $ gun_rank3        : Factor w/ 3 levels \"More restr\",\"Mid\",..: 3 2 3 3 1 1 1 2 3 2 ...\n $ gun_rank11       : num  50 17 39 50 1 15 5 18 41 22 ...\n $ gun_scale11      : num  0 14 4 0 81 15 58 13 3 8 ...\n $ hr_cons_rank11   : num  200 152 132 156 274 ...\n $ hr_conserv11     : num  55.7 65.6 69.3 62.6 54.8 ...\n $ hr_lib_rank11    : num  228 278 295 270 152 ...\n $ hr_liberal11     : num  44.3 34.4 30.7 37.4 81 ...\n $ hs_or_more       : num  91.4 82.1 82.4 84.2 80.6 89.3 88.6 87.4 85.3 83.9 ...\n $ obama2012        : num  40.8 38.4 36.9 44.5 60.2 ...\n $ obama_win12      : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 2 2 2 2 2 1 ...\n $ pop2000          : num  626932 4447100 2673400 5130632 33871648 ...\n $ pop2010          : num  710231 4779736 2915918 6392017 37253956 ...\n $ pop2010_hun_thou : num  7.1 47.8 29.2 63.9 372.5 ...\n $ popchng0010      : num  83299 332636 242518 1261385 3382308 ...\n $ popchngpct       : num  13.3 7.5 9.1 24.6 10 16.9 4.9 14.6 17.6 18.3 ...\n $ pot_policy       : Factor w/ 5 levels \"Not legal\",\"Pending legis\",..: 4 3 1 4 5 5 5 4 2 1 ...\n $ prochoice        : num  58 36 40 56 65 61 68 63 58 52 ...\n $ prolife          : num  37 54 55 39 28 34 26 31 36 43 ...\n $ relig_cath       : num  14.6 6.6 5.9 27.3 31.9 21.9 41.5 25.6 25.4 10.6 ...\n $ relig_prot       : num  50 79.3 78.6 43.3 37.8 46.1 32.1 52 51.2 70.3 ...\n $ relig_high       : num  31.3 55.7 52.3 36.6 34.5 33.5 30.5 35.2 37.6 47.9 ...\n $ relig_low        : num  39.5 14.3 18.7 33.9 36.6 39.3 40.4 33.7 30.7 20.3 ...\n $ religiosity3     : Factor w/ 3 levels \"Low\",\"Mid\",\"High\": 1 3 3 2 1 1 1 2 2 3 ...\n $ romney2012       : num  54.8 60.5 60.6 53.5 37.1 ...\n $ smokers12        : num  24 25 26 21 15 20 18 21 21 21 ...\n $ stateid          : Factor w/ 50 levels \"AK    \",\"AL    \",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ to_0812          : num  -9.4 -2.9 -2.9 -3.1 -6.5 ...\n $ uninsured_pct    : num  21.8 18.8 21.9 20.5 23.2 17.1 9.9 9.6 22.8 22.5 ...\n $ abort_rate05     : num  13.6 11.9 8.3 16 27.1 16.1 23.6 28.8 26.8 16.3 ...\n $ abort_rate08     : num  12 12 8.7 15.2 27.6 15.7 24.6 40 27.2 19.2 ...\n $ abortlaw3        : Factor w/ 3 levels \"0-5 restr\",\"6-8 restr\",..: 1 2 3 2 1 1 1 1 2 3 ...\n $ abortlaw10       : num  5 8 9 6 4 4 4 5 7 9 ...\n $ alcohol          : num  3.02 2.01 1.83 2.31 2.33 2.68 2.34 3.13 2.61 1.97 ...\n $ attend_pct       : num  22 52 50 29 33 29 30 35 35 45 ...\n $ battle04         : Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 2 1 1 2 1 ...\n $ blkleg           : num  2 25 11 1 5 4 7 5 14 21 ...\n $ blkpct04         : num  3.6 26.4 15.8 3.5 6.8 4.1 10.1 20.4 15.7 29.6 ...\n $ blkpct08         : num  4.3 26.4 15.8 4.2 6.7 4.3 10.3 20.9 15.9 30 ...\n $ blkpct10         : num  4.7 26.8 16.1 5 7.2 5 11.3 22.9 17 31.5 ...\n $ bush00           : num  58.6 56.5 51.3 51 41.7 ...\n $ bush04           : num  61.1 62.5 54.3 54.8 44.4 ...\n $ carfatal         : num  17.4 24.9 25.6 20.3 12.1 17.3 10.1 15 19.1 17.8 ...\n $ carfatal07       : num  15.2 25.9 23.7 17.6 11.7 12.3 8.7 13.6 18.1 18.5 ...\n $ cig_tax          : num  2 0.425 0.59 2 0.87 0.84 2 1.15 0.339 0.37 ...\n $ cig_tax_3        : Factor w/ 3 levels \"$.07-$.64\",\"$.695-$1.36\",..: 3 1 1 3 2 2 3 2 1 1 ...\n $ cigarettes       : num  6.22 9.41 8.51 2.4 3.69 ...\n $ college          : num  26.7 21.1 19.1 24.3 29.1 34.7 34.6 27.6 25.1 25.7 ...\n $ conpct_m         : num  36.3 40.7 38.9 33.3 28.5 ...\n $ cons_hr06        : num  72 77.7 56.2 69 37.3 ...\n $ cons_hr09        : num  75 72 28.5 49.5 35.1 ...\n $ cook_index       : num  -13.4 -13.2 -8.8 -6.1 7.4 -0.2 7.1 7 -1.8 -6.8 ...\n $ cook_index3      : Factor w/ 3 levels \"More Rep\",\"Even\",..: 1 1 1 2 3 2 3 3 2 2 ...\n $ defexpen         : num  3556 1757 530 1771 1106 ...\n $ demhr11          : num  0 14.3 25 28.6 64.2 ...\n $ dem_hr09         : num  0 42.9 75 62.5 64.2 ...\n $ demnat06         : num  0 22.2 83.3 20 63.6 ...\n $ dempct_m         : num  26.1 38.9 43.1 31.9 41.3 ...\n $ demstate06       : num  43.3 60.7 75.6 44.4 60.8 ...\n $ demstate09       : num  46.7 57.9 72.6 41.1 64.2 ...\n $ demstate13       : num  36.7 35.7 46.7 41.1 66.7 ...\n $ density          : num  1.2 94.4 56 56.3 239.1 ...\n $ division         : Factor w/ 9 levels \"New England\",..: 9 6 7 8 9 8 1 5 5 5 ...\n $ earmarks_pcap    : num  425.5 38.9 26.7 20.9 12.5 ...\n $ evm              : num  3 9 6 10 0 0 0 0 0 15 ...\n $ evo              : num  0 0 0 0 55 9 7 3 27 0 ...\n $ evo2012          : num  0 0 0 0 55 9 7 3 29 0 ...\n $ evr2012          : num  3 9 6 11 0 0 0 0 0 16 ...\n $ gay_policy       : Factor w/ 4 levels \"Most liberal\",..: 3 4 4 3 2 2 1 3 4 4 ...\n $ gay_policy2      : Factor w/ 2 levels \"Liberal\",\"Conservative\": 2 2 2 2 1 1 1 2 2 2 ...\n $ gay_policy_con   : Factor w/ 2 levels \"No\",\"Yes\": 1 2 2 1 1 1 1 1 2 2 ...\n $ gay_support      : num  56 44 44 58 64 61 65 60 57 51 ...\n $ gay_support3     : Factor w/ 3 levels \"Low\",\"Med\",\"High\": 2 1 1 2 3 3 3 2 2 1 ...\n $ gb_win00         : Factor w/ 2 levels \"Gore win\",\"Bush win\": 2 2 2 2 1 2 1 1 2 2 ...\n $ gb_win04         : Factor w/ 2 levels \"Kerry win\",\"Bush win\": 2 2 2 2 1 2 1 1 2 2 ...\n $ gore00           : num  27.7 41.6 45.9 44.7 53.4 ...\n $ gun_check        : num  12016 9025 8443 5314 3040 ...\n $ gun_dealer       : num  139.3 47.4 67.4 45.4 21.6 ...\n $ gun_murder10     : num  2.7 2.8 3.2 3.6 3.4 1.3 2.7 4.2 3.8 3.9 ...\n $ gun_rank_rev     : num  6 30 13 13 48 32 46 38 13 16 ...\n $ gunlaw_rank      : num  43 19 36 36 1 17 3 11 36 33 ...\n $ gunlaw_rank3_rev : Factor w/ 3 levels \"Fewer restr\",..: 1 2 1 1 3 3 3 3 1 2 ...\n $ gunlaw_scale     : num  4 15 6 6 79 16 54 22 6 7 ...\n $ hispanic04       : num  4.9 2.2 4.4 28 34.7 19.1 10.6 5.8 19 6.8 ...\n $ hispanic08       : num  6.1 2.9 5.6 30.1 36.6 20.2 12 6.8 21 8 ...\n $ hispanic10       : num  5.5 3.9 6.4 29.6 37.6 20.7 13.4 8.2 22.5 8.8 ...\n $ indpct_m         : num  43.6 30 35.9 29.7 25.8 ...\n $ kerry04          : num  35.5 36.8 44.5 44.4 54.3 ...\n $ libpct_m         : num  17.9 16.8 16.8 19.2 24.2 ...\n $ mccain08         : num  59.4 60.3 58.7 53.4 36.9 ...\n  [list output truncated]\n - attr(*, \"variable.labels\")= Named chr [1:135] \"Abortion restrictions\" \"2012 Abortion rank AUL\" \"Percent advanced degree or higher\" \"Percent college or higher\" ...\n  ..- attr(*, \"names\")= chr [1:135] \"Abort_rank3\" \"Abortion_rank12\" \"Adv_or_more\" \"BA_or_more\" ...\n - attr(*, \"codepage\")= int 65001\n\n\nEste procedimiento mostrar√° un resumen de la estructura del marco de datos, incluyendo el n√∫mero de filas y columnas, el nombre de cada columna, la clase de cada columna y los primeros valores del marco de datos.\nCuando se aplica a un vector o una lista, str() devuelve la longitud del objeto, la clase (por ejemplo, ‚Äúnum√©rico‚Äù, ‚Äúcar√°cter‚Äù) y los primeros valores.\nLa funci√≥n str() es particularmente √∫til cuando se trabaja con conjuntos de datos grandes o complejos, ya que le permite inspeccionar r√°pidamente la estructura de los datos e identificar posibles problemas, como datos faltantes o tipos de datos inesperados.\nTambi√©n es importante tener en cuenta que la funci√≥n str() muestra menos informaci√≥n que la funci√≥n summary(), y es m√°s √∫til cuando el objeto es grande, complicado o cuando se desea mostrar la estructura de los datos sin mostrar los datos en s√≠.\nTambi√©n podemos aplicar tales funciones a una selecci√≥n de las variables para evitar devolver informaci√≥n sobre demasiadas variables:\n\n\nCode\n# Selecciona las variables pot_policy y prochoice\nsummary(d[, c(\"pot_policy\",\"prochoice\")])\n\n\n               pot_policy   prochoice    \n Not legal          :18   Min.   :33.00  \n Pending legis      : 8   1st Qu.:47.00  \n Decrim             : 6   Median :55.50  \n Medicinal          :10   Mean   :53.66  \n Medicinal / Decrim.: 8   3rd Qu.:62.75  \n                          Max.   :70.00  \n\n\nEjercicio\nExplore las variables dem_score14, dem_level4, hdi, gini08,religoin, y muslim en el data.frame world (w) usando la funci√≥n summary():\n\n\nCode\n# Resume la base de datos w \nsummary(w[,c(\"dem_score14\", \"dem_level4\", \"hdi\", \"gini08\",\"religoin\", \"muslim\")])\n\n\n  dem_score14            dem_level4      hdi             gini08     \n Min.   :1.080   Full Democ   :24   Min.   :0.1400   Min.   :24.70  \n 1st Qu.:3.610   Part Democ   :52   1st Qu.:0.4675   1st Qu.:33.48  \n Median :5.790   Hybrid       :39   Median :0.6690   Median :39.10  \n Mean   :5.548   Authoritarian:52   Mean   :0.6325   Mean   :40.65  \n 3rd Qu.:7.395                      3rd Qu.:0.7810   3rd Qu.:46.98  \n Max.   :9.930                      Max.   :0.9380   Max.   :74.30  \n                                    NA's   :9        NA's   :45     \n               religoin  muslim   \n Catholic          :52   No :121  \n Orthodox Christian:16   Yes: 46  \n Other Christian   :27            \n Muslim            :46            \n Buddhist          :11            \n Other             :13            \n NA's              : 2            \n\n\n\n\nAgregar datos\nLa agregaci√≥n de datos se refiere al proceso de recopilar y resumir datos de m√∫ltiples fuentes en un conjunto de datos √∫nico y consolidado. Esto se puede hacer utilizando varias t√©cnicas, como agrupar datos por ciertas variables, aplicar operaciones matem√°ticas como suma, promedio o conteo a columnas espec√≠ficas o combinar datos de m√∫ltiples tablas o conjuntos de datos.\nLa agregaci√≥n de datos se utiliza a menudo para reducir la complejidad de conjuntos de datos grandes y facilitar el an√°lisis y la visualizaci√≥n de datos. Tambi√©n se puede utilizar para identificar patrones, tendencias y valores at√≠picos en los datos.\nEn el R, la agregaci√≥n de datos se puede realizar utilizando una variedad de funciones y paquetes, como aggregate(), group_by() y summarize() del paquete dplyr, tapply(), y by(). Estas funciones le permiten agrupar datos por ciertas variables y realizar c√°lculos en columnas espec√≠ficas.\nPor ejemplo, si tenemos un marco de datos con m√∫ltiples columnas y queremos calcular la media de algunas columnas y la suma de otras, podemos usar el siguiente comando:\n\n\nCode\n# Selecciona algunas variables de la base de datos d \nx &lt;- d[,c(\"region\",\"vep00_turnout\",\"vep04_turnout\",\"vep08_turnout\",\"vep12_turnout\")]\n\n# Calcula la media para dichas variables\naggregate(x, \n          by=list(\n                  region=x$region), \n          mean, \n          na.rm=T)\n\n\n     region region vep00_turnout vep04_turnout vep08_turnout vep12_turnout\n1 Northeast     NA      59.70000      64.78889      65.96667      62.03333\n2   Midwest     NA      59.25833      66.30000      66.70000      63.40000\n3     South     NA      51.29375      57.98750      60.65000      57.53750\n4      West     NA      55.55385      61.71538      62.17692      58.23846\n\n\nEjercicio\nAhora, repita la agregaci√≥n usando la variable religoin para grupos y hdi, gini10, dem_score14,lifeex_total, y frac_eth.\n\n\nCode\n# Selecciona las variables de w \nx &lt;- w[,c(\"religoin\",\"hdi\", \"gini10\", \"dem_score14\", \"lifeex_total\", \"frac_eth\")]\n\n# Calcula las medias para tales variables\naggregate(x, \n          by=list(\n                  region=x$religoin), \n          mean, \n          na.rm=T)\n\n\n              region religoin       hdi   gini10 dem_score14 lifeex_total\n1           Catholic       NA 0.6840980 42.12000    6.568269     72.25981\n2 Orthodox Christian       NA 0.7193750 35.02500    5.843750     71.73533\n3    Other Christian       NA 0.5891481 44.08148    6.363704     64.13963\n4             Muslim       NA 0.5515366 38.25556    3.806739     67.07556\n5           Buddhist       NA 0.6334000 38.91000    4.828182     71.17545\n6              Other       NA 0.6487500 36.62308    6.326154     70.82769\n   frac_eth\n1 0.3860660\n2 0.3502231\n3 0.4844296\n4 0.5359690\n5 0.3915778\n6 0.4669500\n\n\nEl paquete dplyr \nComo se mencion√≥ anteriormente, el paquete dplyr extiende la funcionalidad b√°sica de R aggregate() y nos permite usar varias funciones simult√°neamente para agregar los datos en grupos.\n\n\nCode\n# carga el paquete dplyr \nlibrary(dplyr)\n\n# Calcula la media POR REGION para vep00_turnout, la\n# desviaci√≥n est√°ndar para vep04_turnout, el valor m√≠nimo\n# para vep08_turnout, y el m√°ximo para vep12_turnout\nd |&gt;\n  group_by(region) |&gt;\n  summarize(mean=mean(vep00_turnout),\n            sd=sd(vep04_turnout),\n            min=min(vep08_turnout),\n            max=max(vep12_turnout))\n\n\n# A tibble: 4 √ó 5\n  region     mean    sd   min   max\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Northeast  59.7  5.16  58    70.1\n2 Midwest    59.3  6.24  59.4  75.7\n3 South      51.3  3.75  50.6  66.4\n4 West       55.6  6.73  50.5  70.3\n\n\nAhora, repita el procedimiento anterior para el conjunto de datos w usando la variable religoin para grupos y la media para hdi, la desviaci√≥n est√°ndar para gini10, la mediana para dem_score14, el m√≠nimo para lifeex_total, y el m√°ximo para frac_eth. No olvide excluir los casos faltantes:\n\n\nCode\n# carga dplyr\nlibrary(dplyr)\n\n# Calcula los agregados por religion\nw |&gt;\n  group_by(religoin) |&gt;\n  summarise(m_hdi=mean(hdi, na.rm = T),\n            sd_gini=sd(gini10, na.rm=T),\n            med_dem=median(dem_score14, na.rm=T),\n            min_life=min(lifeex_total, na.rm=T),\n            max_frac=max(frac_eth, na.rm=T)\n            )\n\n\n# A tibble: 7 √ó 6\n  religoin           m_hdi sd_gini med_dem min_life max_frac\n  &lt;fct&gt;              &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Catholic           0.684   10.0     6.96     38.8    0.930\n2 Orthodox Christian 0.719    7.05    6.28     51.6    0.617\n3 Other Christian    0.589   12.1     6.24     48.7    0.908\n4 Muslim             0.552    6.26    3.76     45.0    0.862\n5 Buddhist           0.633    4.28    4.87     62.4    0.634\n6 Other              0.649    6.91    7.63     48.7    0.863\n7 &lt;NA&gt;               0.902   NA       4.60     68.9    0.490"
  },
  {
    "objectID": "S_3_Analisis.html#medidas-de-asociaci√≥n",
    "href": "S_3_Analisis.html#medidas-de-asociaci√≥n",
    "title": "An√°lisis",
    "section": "Medidas de Asociaci√≥n",
    "text": "Medidas de Asociaci√≥n\nAntes de empezar\nEn los ejercicios dise√±ados para este tutorial usaremos dos conjuntos de datos. El primero es el data.frame d basado en el data.frame states del paquete polscidata (como en la secci√≥n anterior). El segundo es el conjunto de datos tt basado en el data.frame Titanic que contiene datos sobre pasajeros y tripulantes del Titanic (Clase, Edad, Sexo, y si sobrevivieron o no).\n\n¬øC√≥mo podemos medir la relaci√≥n entre variables?\n¬øCu√°l es la relaci√≥n entre el ejercicio f√≠sico y el peso corporal? ¬øY qu√© hay del tiempo de estudio y las calificaciones? ¬øHay alguna relaci√≥n entre la educaci√≥n y los ingresos? ¬øLa contaminaci√≥n del aire y las enfermedades respiratorias? Estas preguntas se refieren a la asociaci√≥n entre diferentes fen√≥menos. Usualmente usamos este tipo de preguntas cuando tratamos de establecer c√≥mo un evento o atributo impacta en otro.\nEn estad√≠stica, la forma de medir este concepto amplio es la covarianza. Se basa en un principio sencillo: ¬øcu√°nto y en qu√© direcci√≥n cambia la variable y cuando la otra variable x cambia? As√≠, si cada a√±o de escolaridad aumenta 100 Euros en ingresos futuros, podemos decir que hay una correlaci√≥n positiva entre educaci√≥n e ingresos. Esto se debe a que ambos aumentan. Lo contrario ocurre con el gasto p√∫blico en saneamiento y la mortalidad infantil. Cuanto m√°s gastan los gobiernos en saneamiento (agua limpia y alcantarillado), menor es el n√∫mero de muertes en ni√±os peque√±os. En este caso, hay una asociaci√≥n negativa.\nAsista al video corto sobre covarianza:\n\nEl coeficiente de correlaci√≥n de Pearson es una medida de la fuerza y direcci√≥n de la relaci√≥n lineal entre dos variables. En otras palabras, mide c√≥mo se relacionan dos variables cuantitativas. El valor de la correlaci√≥n de Pearson var√≠a entre -1 y 1. Un valor de 1 indica una correlaci√≥n positiva perfecta, mientras que un valor de -1 indica una correlaci√≥n negativa perfecta. Un valor de 0 indica que no hay relaci√≥n entre las dos variables.\nMira el video corto sobre correlaci√≥n de Pearson:"
  },
  {
    "objectID": "S_3_Analisis.html#mediciones-de-asociaci√≥n-en-r",
    "href": "S_3_Analisis.html#mediciones-de-asociaci√≥n-en-r",
    "title": "An√°lisis",
    "section": "Mediciones de Asociaci√≥n en R",
    "text": "Mediciones de Asociaci√≥n en R\nEn esta secci√≥n, exploraremos c√≥mo se pueden calcular en R las dos principales medidas de asociaci√≥n. La primera es la covarianza y la segunda la correlaci√≥n. Finalmente, aprenderemos a crear un correlograma, un gr√°fico que facilita la interpretaci√≥n de un gran n√∫mero de variables.\n\n\nCovarianza\nLa covarianza es una medida de la relaci√≥n entre dos variables. Es similar a la varianza, pero donde la varianza nos dice c√≥mo una sola variable var√≠a, la covarianza nos dice c√≥mo dos variables var√≠an juntas. La covarianza es positiva si las dos variables tienden a aumentar juntas y negativa si una variable disminuye cuando la otra aumenta. La covarianza es cero si no hay relaci√≥n entre las dos variables.\nEn R, la funci√≥n cov() es la responsable de calcular la covarianza de dos variables. El fragmento de c√≥digo a continuaci√≥n calcula la matriz de covarianza para las variables unemploy y urban, ambas pertenecientes al data.frame d.\n\n\nCode\ncov(d$unemploy, d$urban)\n\n\n[1] 1.631967\n\n\nEn el siguiente ejemplo, una de las variables relig_import (Porcentaje de personas que dicen que la religi√≥n juega un papel importante en sus vidas) tiene valores faltantes. Despu√©s de ejecutar el c√≥digo a continuaci√≥n, puede ver que la primera covarianza devuelve NA. Esto ocurre precisamente porque los NAs no se tratan. En las funciones mean(), median(), var(), y sd(), los NAs se manejan utilizando el par√°metro ‚Äúna.rm=T‚Äù. En el caso de la covarianza y la correlaci√≥n, se debe utilizar un nuevo par√°metro use=‚Äúpairwise.complete.obs‚Äù. Esta opci√≥n le dice a R que solo debe calcular la covarianza (o la correlaci√≥n) para aquellos pares de valores donde ambos son diferentes de NA.\n\n\nCode\n# Covarianza sin lidiar con casos perdidos NAs \ncov(d$unemploy, d$relig_import)\n\n\n[1] NA\n\n\nCode\n# Covarianza lidiando con NAs\ncov(d$unemploy, d$relig_import, use=\"pairwise.complete.obs\")\n\n\n[1] 1.538539\n\n\nPr√°ctica\nAhora es tu turno. Calcula la covarianza entre las variables obama08 (% de voto en Obama en 2008) y obama2012 (% de voto en Obama en 2012) en el data.frame d.\n\n\nCode\ncov(d$obama08, d$obama2012)\n\n\n[1] 95.55904\n\n\n\n\n\nCorrelaci√≥n\nDistintamente de la covarianza, el coeficiente de correlaci√≥n siempre var√≠a de -1 a 1 independientemente de la escala de las variables empleadas en los c√°lculos. Por lo tanto, somos capaces de evaluar no solo la direcci√≥n, sino tambi√©n la fuerza de la relaci√≥n entre estos fen√≥menos, como ya has visto en los videos.\nAhora, calculemos la correlaci√≥n entre las variables abort_rate08 (tasa de aborto en 2008) y obama08 (% de voto en Obama en 2008) en el data.frame d.\n\n\nCode\ncor(d$abort_rate08, d$obama08)\n\n\n[1] 0.6415203\n\n\nEl resultado es un coeficiente de correlaci√≥n (r) igual a 0.642. Parece que hay una asociaci√≥n moderada y positiva entre el aborto y el voto en Obama en 2008. M√°s claramente, cuanto mayor es la tasa de aborto, mayor es el voto potencial en Obama. La relaci√≥n no es perfecta (si este fuera el caso, r=1), pero es lo suficientemente fuerte como para llamar nuestra atenci√≥n sobre la relaci√≥n entre el aborto y el voto.\nRepita el c√°lculo de correlaci√≥n anterior, pero ahora use mccain08 (% de voto en John McCain en 2008) en lugar de obama08. ¬øQu√© obtienes como resultado?\n\n\nCode\ncor(d$abort_rate08, d$mccain08)\n\n\n[1] -0.6276876\n\n\nCorrelaci√≥n de m√∫ltiples variables\nEn muchas ocasiones queremos realizar muchas correlaciones al mismo tiempo para acelerar el an√°lisis. En esos casos, solo necesitamos proporcionar un data.frame o matriz con SOLO variables num√©ricas y la funci√≥n cor() devuelve una tabla con todas las correlaciones para estas variables.\n\n\nCode\n# Selecciona algunas variables \n# del data.frame d\nds &lt;- d[,c(\"urban\",\"unemploy\",\n           \"abort_rate08\",\"prcapinc\",\n           \"relig_high\",\"obama08\",\"mccain08\")]\n\n# Calcula la correlaci√≥n para esas\n# variables\nco &lt;- cor(ds)\n\n# Muestra los resultados\nround(co,3)\n\n\n              urban unemploy abort_rate08 prcapinc relig_high obama08 mccain08\nurban         1.000    0.109        0.663    0.526     -0.227   0.404   -0.404\nunemploy      0.109    1.000       -0.040   -0.228      0.208  -0.137    0.134\nabort_rate08  0.663   -0.040        1.000    0.589     -0.367   0.642   -0.628\nprcapinc      0.526   -0.228        0.589    1.000     -0.643   0.592   -0.590\nrelig_high   -0.227    0.208       -0.367   -0.643      1.000  -0.682    0.704\nobama08       0.404   -0.137        0.642    0.592     -0.682   1.000   -0.997\nmccain08     -0.404    0.134       -0.628   -0.590      0.704  -0.997    1.000\n\n\nComo puedes observar, el resultado es una matriz con la correlaci√≥n entre todas las variables. El coeficiente r para urban vs.¬†urban es 1.000 porque es la misma variable correlacionada consigo misma. Lo mismo ocurre con todas las dem√°s variables cuando se comparan consigo mismas. El d√≠ada urban vs.¬†unemploy, por otro lado, tiene un r=0.109, una asociaci√≥n peque√±a y positiva. Ahora, urban vs.¬†abort_rate08 presenta un r=0.663, positivo y moderado. El voto en McCain (mccain08) est√° negativamente y fuertemente correlacionado con el voto en Obama en 2008 (obama08). Dado que la pol√≠tica de los Estados Unidos es bipartidista, es normal esperar que cuando el voto en un candidato aumenta, el voto en el otro disminuya.\nPor lo tanto, tales resultados nos ayudan a identificar aquellas variables con relaciones fuertes (tanto positivas como negativas) y a determinar aquellas que, inicialmente, no parecen estar relacionadas."
  },
  {
    "objectID": "S_3_Analisis.html#trabajando-con-datos-categ√≥ricos-frecuencias-cruzadas",
    "href": "S_3_Analisis.html#trabajando-con-datos-categ√≥ricos-frecuencias-cruzadas",
    "title": "An√°lisis",
    "section": "Trabajando con datos categ√≥ricos: Frecuencias cruzadas",
    "text": "Trabajando con datos categ√≥ricos: Frecuencias cruzadas\n\nFrecuencias de datos categ√≥ricos\nVisualice el video sobre c√≥mo interpretar tablas de contingencia o frecuencias cruzadas:\n\n\n\nTablas de contingencia en R\nTablas de frecuencia son la forma m√°s adecuada de resumir datos categ√≥ricos. Una vez que tenemos las frecuencias, podemos usarlas para calcular una serie de otras estad√≠sticas e indicadores. La misma funci√≥n table() utilizada en sesiones anteriores se puede usar para tablas de contingencia para m√°s de una variable categ√≥rica.\nLa funci√≥n prop.table() devuelve la proporci√≥n de cada categor√≠a en una celda dada de la tabla:\n\n\nCode\ntb &lt;- table(d$gay_policy, d$region)\n\nprop.table(tb)*100\n\n\n                   \n                    Northeast Midwest South West\n  Most liberal             10       2     0    0\n  Liberal                   6       6     2   14\n  Conservative              2       6     6    6\n  Most conservative         0      10    24    6\n\n\n\nNo obstante, el resultado no es exactamente lo que necesitamos. Los porcentajes son relativos al total y no para la columna o la fila. La apariencia tambi√©n podr√≠a mejorarse significativamente.\nLa funci√≥n crosstable() del paquete crosstable produce una presentaci√≥n mucho m√°s agradable de los resultados:\n\n\nCode\nlibrary(crosstable)\n\ncrosstable(data = d,           # data = nombre del Data frame\n           cols = gay_policy,  # cols = Variable(s)\n           by= region) %&gt;%     # by = Variable que agrega los resultados\n  as_flextable()\n\n\n\nlabelvariableregionNortheastMidwestSouthWestgay_policyMost liberal5 (83.33%)1 (16.67%)0 (0%)0 (0%)Liberal3 (21.43%)3 (21.43%)1 (7.14%)7 (50.00%)Conservative1 (10.00%)3 (30.00%)3 (30.00%)3 (30.00%)Most conservative0 (0%)5 (25.00%)12 (60.00%)3 (15.00%)\n\n\n\nHazlo t√∫ mismo. Usando el c√≥digo en el fragmento anterior, crea una tabla cruzada para las variables pot_policy (Leyes de Marihuana) y obama_win12 (Obama gan√≥ el Estado en 2012).\n\n\nCode\nlibrary(crosstable)\n\ncrosstable(data = d, \n           cols = pot_policy, \n           by= obama_win12) %&gt;%\n  as_flextable()\n\n\n\nlabelvariableobama_win12NoYespot_policyNot legal15 (83.33%)3 (16.67%)Pending legis3 (37.50%)5 (62.50%)Decrim3 (50.00%)3 (50.00%)Medicinal3 (30.00%)7 (70.00%)Medicinal / Decrim.0 (0%)8 (100.00%)\n\n\n\nAhora, empleando los datos del Titanic (tt), crea una tabla de contingencia para las variables Sex (Sexo del Pasajero) y Survived (Sobrevivi√≥).\n\n\nCode\nlibrary(crosstable)\n\ncrosstable(data = tt, \n           cols = Sex, \n           by= Survived) %&gt;%\n  as_flextable()\n\n\n\nlabelvariableSurvivedNoYesSexMale1364 (78.80%)367 (21.20%)Female126 (26.81%)344 (73.19%)\n\n\n\nAhora, repite la operaci√≥n usando el conjunto de datos del Titanic (tt) para crear una tabla de contingencia para las variables Class (Clase del Pasajero) y Survived.\n\n\nCode\nlibrary(crosstable)\n\ncrosstable(data = tt, \n           cols = Class, \n           by = Survived) %&gt;%\n  as_flextable()\n\n\n\nlabelvariableSurvivedNoYesClass1st122 (37.54%)203 (62.46%)2nd167 (58.60%)118 (41.40%)3rd528 (74.79%)178 (25.21%)Crew673 (76.05%)212 (23.95%)\n\n\n\nPongamos un poco de pimienta en el ejercicio. Filtra los datos tt para incluir solo miembros de la tripulaci√≥n en un nuevo data.frame llamado cw. Luego, repite la operaci√≥n usando el conjunto de datos de la tripulaci√≥n del Titanic (cw) para crear una tabla de contingencia para las variables Sex (Sexo del miembro de la tripulaci√≥n) y Survived.\n\n\nCode\n# Selecciona solamente los tripulantes\n# en el data.frame cw\ncw &lt;- tt[tt$Class==\"Crew\",]\n\nlibrary(crosstable)\n\ncrosstable(data = cw, \n           cols = Sex, \n           by= Survived) %&gt;%\n  as_flextable()\n\n\n\nlabelvariableSurvivedNoYesSexMale670 (77.73%)192 (22.27%)Female3 (13.04%)20 (86.96%)"
  },
  {
    "objectID": "S_3_Analisis.html#hip√≥tesis-y-significancia-estad√≠stica",
    "href": "S_3_Analisis.html#hip√≥tesis-y-significancia-estad√≠stica",
    "title": "An√°lisis",
    "section": "Hip√≥tesis y Significancia Estad√≠stica",
    "text": "Hip√≥tesis y Significancia Estad√≠stica\nEl test de hip√≥tesis es un m√©todo estad√≠stico utilizado en las ciencias sociales para determinar si hay suficiente evidencia para respaldar una afirmaci√≥n o hip√≥tesis espec√≠fica sobre una poblaci√≥n. Implica formular una hip√≥tesis nula, que representa la suposici√≥n predeterminada o de no diferencia, y una hip√≥tesis alternativa, que representa la afirmaci√≥n o creencia que se est√° probando. Luego, se recopila una muestra de datos y se analiza utilizando pruebas estad√≠sticas para determinar la probabilidad de obtener los resultados observados bajo la hip√≥tesis nula. Dependiendo del resultado, la hip√≥tesis nula se acepta o rechaza, proporcionando o no soporte para la hip√≥tesis alternativa.\nAlgunas aplicaciones espec√≠ficas de las pruebas de hip√≥tesis en las ciencias sociales incluyen:\n\nPrueba de la efectividad de una nueva pol√≠tica o intervenci√≥n: Los investigadores pueden utilizar la prueba de hip√≥tesis para determinar si una nueva pol√≠tica o intervenci√≥n tiene el efecto deseado en una poblaci√≥n. Por ejemplo, un investigador podr√≠a probar la hip√≥tesis de que un nuevo programa educativo conducir√° a puntajes m√°s altos en las pruebas entre los estudiantes.\nEvaluaci√≥n de la relaci√≥n entre variables: Los investigadores pueden utilizar la prueba de hip√≥tesis para investigar la relaci√≥n entre diferentes variables. Por ejemplo, un investigador podr√≠a probar la hip√≥tesis de que hay una relaci√≥n positiva entre el ingreso y la felicidad.\nInvestigaci√≥n de diferencias entre grupos: Los investigadores pueden utilizar la prueba de hip√≥tesis para determinar si hay diferencias significativas entre diferentes grupos. Por ejemplo, un investigador podr√≠a probar la hip√≥tesis de que hay diferencias en los patrones de votaci√≥n entre hombres y mujeres.\nEvaluaci√≥n de la validez de una herramienta de medici√≥n: Los investigadores pueden utilizar la prueba de hip√≥tesis para determinar si una herramienta de medici√≥n, como una encuesta o cuestionario, es confiable y v√°lida.\nExploraci√≥n del impacto de factores demogr√°ficos: Los investigadores pueden utilizar la prueba de hip√≥tesis para investigar el impacto de factores demogr√°ficos, como la edad, el g√©nero y la raza, en un resultado espec√≠fico."
  },
  {
    "objectID": "S_3_Analisis.html#p-values-y-nivel-de-significancia",
    "href": "S_3_Analisis.html#p-values-y-nivel-de-significancia",
    "title": "An√°lisis",
    "section": "P-values y nivel de significancia",
    "text": "P-values y nivel de significancia\n\nHip√≥tesis nula\nUna hip√≥tesis nula es una afirmaci√≥n que representa la suposici√≥n predeterminada o de no diferencia en un test de hip√≥tesis. Es la hip√≥tesis que se prueba para determinar si hay suficiente evidencia para rechazarla en favor de la hip√≥tesis alternativa. La hip√≥tesis nula se denota como H0 y generalmente se formula como una afirmaci√≥n de igualdad. Por ejemplo, una hip√≥tesis nula podr√≠a afirmar que no hay diferencia en los puntajes de prueba entre dos grupos de estudiantes.\n\n\nHip√≥tesis alternativa\nUna hip√≥tesis alternativa es una afirmaci√≥n que representa la creencia o afirmaci√≥n que se est√° probando en un test de hip√≥tesis. Representa la posibilidad de que haya una diferencia o efecto en la poblaci√≥n. La hip√≥tesis alternativa se denota como H1 y generalmente se formula como una afirmaci√≥n de desigualdad. Por ejemplo, una hip√≥tesis alternativa podr√≠a afirmar que hay una diferencia en los puntajes de prueba entre dos grupos de estudiantes.\nEl objetivo de un test de hip√≥tesis es determinar si hay suficiente evidencia para rechazar la hip√≥tesis nula en favor de la hip√≥tesis alternativa. Si la hip√≥tesis nula se rechaza, significa que hay evidencia para respaldar la hip√≥tesis alternativa. Si la hip√≥tesis nula no se rechaza, significa que no hay suficiente evidencia para respaldar la hip√≥tesis alternativa.\nResulta importante tener en cuenta que un fallo en rechazar la hip√≥tesis nula no significa que la hip√≥tesis nula sea verdadera, sino que la evidencia no es lo suficientemente fuerte como para rechazarla.\n\n\nEl valor p\nEl valor p es una medida de la evidencia en contra de una hip√≥tesis nula. Representa la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado, asumiendo que la hip√≥tesis nula es verdadera.\nEl valor p se utiliza para determinar si hay suficiente evidencia para rechazar la hip√≥tesis nula en favor de la hip√≥tesis alternativa. Si el valor p es menor que un nivel de significancia predeterminado (generalmente 0.05 o 0.01), se rechaza la hip√≥tesis nula y se acepta la hip√≥tesis alternativa. Si el valor p es mayor que el nivel de significancia, no se rechaza la hip√≥tesis nula.\nPor otro lado, un valor p mayor que el nivel de significancia significa que no hay suficiente evidencia para rechazar la hip√≥tesis nula, y los resultados pueden haber ocurrido por casualidad. Por lo tanto, el investigador no rechaza la hip√≥tesis nula.\nEs importante tener en cuenta que un valor p bajo no significa que la hip√≥tesis alternativa sea verdadera, sino que hay suficiente evidencia para rechazar la hip√≥tesis nula en favor de la hip√≥tesis alternativa.\nTambi√©n resulta importante se√±alar que un valor p bajo no significa que la hip√≥tesis sea verdadera, simplemente significa que los datos son poco probables bajo la hip√≥tesis nula.\n\n\nNiveles de significancia\nLos niveles de significancia se refieren a los niveles de significancia estad√≠stica en las pruebas de hip√≥tesis. En las pruebas de hip√≥tesis, un nivel de significancia es un umbral utilizado para determinar si una diferencia o relaci√≥n observada es estad√≠sticamente significativa. Un nivel de significancia com√∫nmente utilizado en la investigaci√≥n es 0.05, lo que significa que hay un 5% de probabilidad de que la diferencia o relaci√≥n observada sea debida al azar. Si la probabilidad de obtener un resultado tan extremo o m√°s extremo que el observado, si la hip√≥tesis nula es verdadera, es menor o igual al nivel de significancia, se rechaza la hip√≥tesis nula y se acepta la hip√≥tesis alternativa.\nPor ejemplo, en un estudio que investiga la relaci√≥n entre el ingreso y la felicidad, los investigadores podr√≠an utilizar un nivel de significancia de 0.05 para determinar si la relaci√≥n observada entre el ingreso y la felicidad es estad√≠sticamente significativa. Si la probabilidad de observar una relaci√≥n tan fuerte o m√°s fuerte que la observada, si la hip√≥tesis nula es verdadera, es menor o igual a 0.05, los investigadores rechazar√≠an la hip√≥tesis nula y concluir√≠an que hay una relaci√≥n estad√≠sticamente significativa entre el ingreso y la felicidad.\n\n\nVideo\nAsiste al siguiente video para aprender m√°s sobre el concepto de valor p:\n\n\n\nEjercicio\n\n¬øEs mayor la tasa de abortos en los estados donde Obama gan√≥ en 2008?\n\nFormula la pregunta como un conjunto de hip√≥tesis nula y alternativa:\nH0: Estados que votaron por Obama y McCain tienen la misma tasa de abortos.\nH1: Estados donde Obama gan√≥ tienen una tasa de abortos mayor que los estados donde McCain gan√≥.\n\n\nCode\n# Testa la hip√≥tesis nula de que la tasa de abortos es la misma en los estados donde Obama y McCain ganaron en 2008\ntt &lt;- t.test(d$abort_rate08~d$obama_win08)\n\n# Examina el valor p\n# Te informa la probabilidad de aceptar \n# que H0 sea verdadera:\ntt$p.value\n\n\n[1] 7.182965e-06\n\n\nCode\n# Ahora, redondea a 3 decimales\nround(tt$p.value,3)\n\n\n[1] 0"
  },
  {
    "objectID": "S_3_Analisis.html#el-test-de-chi-cuadrado",
    "href": "S_3_Analisis.html#el-test-de-chi-cuadrado",
    "title": "An√°lisis",
    "section": "El test de Chi-Cuadrado",
    "text": "El test de Chi-Cuadrado\n\nDefinici√≥n\nUn test de Chi-Cuadrado es una prueba estad√≠stica que se utiliza para determinar si hay una diferencia significativa entre las frecuencias esperadas y observadas en un conjunto de datos categ√≥ricos. La prueba se basa en la distribuci√≥n de Chi-Cuadrado, que es una distribuci√≥n de probabilidad que describe la distribuci√≥n de la suma de los cuadrados de k variables normales est√°ndar independientes.\nEl teste de Chi-Cuadrado es com√∫nmente utilizado en pruebas de hip√≥tesis para probar la bondad de ajuste de un modelo a los datos observados, o para probar la independencia en una tabla de contingencia.\nCuando se prueba la bondad de ajuste, la hip√≥tesis nula es que los datos siguen una distribuci√≥n de probabilidad espec√≠fica, y la hip√≥tesis alternativa es que los datos no siguen esa distribuci√≥n.\nCuando se prueba la independencia en una tabla de contingencia, la hip√≥tesis nula es que no hay asociaci√≥n entre las dos variables categ√≥ricas y la hip√≥tesis alternativa es que hay una asociaci√≥n entre las dos variables.\nEl estad√≠stico de prueba utilizado en un test de Chi-Cuadrado se calcula sumando las diferencias al cuadrado entre las frecuencias observadas y esperadas, divididas por las frecuencias esperadas. El estad√≠stico de prueba calculado se compara entonces con la distribuci√≥n de Chi-Cuadrado con un cierto grado de libertad para determinar el valor p.\nUn valor p menor que un nivel de significancia elegido (generalmente 0.05) se toma como evidencia para rechazar la hip√≥tesis nula y aceptar la hip√≥tesis alternativa.\nEs importante tener en cuenta que el test de Chi-Cuadrado asume que el tama√±o de la muestra es lo suficientemente grande, de lo contrario no es apropiado utilizarlo.\n\n\nEjemplos\nUn ejemplo proviene de la prueba de Independencia en Encuestas de Votantes. Un investigador puede querer probar si la afiliaci√≥n pol√≠tica de un votante es independiente de su edad. Recopilar√≠an datos sobre la edad y la afiliaci√≥n pol√≠tica de una muestra de votantes y crear√≠an una tabla de contingencia. La hip√≥tesis nula ser√≠a que no hay asociaci√≥n entre la edad y la afiliaci√≥n pol√≠tica y la hip√≥tesis alternativa ser√≠a que hay una asociaci√≥n. Se podr√≠a utilizar una prueba de Chi-Cuadrado para determinar si las frecuencias observadas difieren significativamente de lo que se esperar√≠a si la hip√≥tesis nula fuera verdadera.\n\n\nVideo\nAsiste al video siguiente sobre el test de Chi-Cuadrado:\n\n\n\nEl Chi-Cuadrado en R\nEn R, puedes realizar un test de Chi-Cuadrado utilizando la funci√≥n chisq.test(). La funci√≥n toma una tabla de contingencia como argumento, que es una tabla que muestra la distribuci√≥n de frecuencias de dos o m√°s variables categ√≥ricas. La tabla de contingencia se puede introducir como una matriz o un data frame.\nPor ejemplo, si tenemos un data frame llamado d con dos columnas abort_rank3 y religiosity3, y queremos probar si hay una asociaci√≥n significativa entre las dos variables, usar√≠amos el siguiente c√≥digo:\n\n\nCode\n# Realiza el test de chi-cuadrado\nchisq.test(d$abort_rank3, d$religiosity3)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  d$abort_rank3 and d$religiosity3\nX-squared = 23.443, df = 4, p-value = 0.0001033\n\n\n\n\nEjercicio\nInt√©ntalo t√∫\nEmpleando nuestros datos sobre pa√≠ses del mundo (w), proporciona una respuesta a la siguiente pregunta:\n¬øEst√° relacionado el nivel de PIB per c√°pita en 2008 (gdpcap3_08) con el tipo de r√©gimen (dem_level4)? ¬øVar√≠a la riqueza seg√∫n el tipo de r√©gimen? Recuerda, cada pregunta tiene sus propias hip√≥tesis nula y alternativa:\nH0: El nivel de riqueza (PIB per c√°pita) no afecta al tipo de r√©gimen\nH1: El nivel de riqueza var√≠a seg√∫n el tipo de r√©gimen\nIntenta realizar el test de Chi-Cuadrado en R para probar estas hip√≥tesis:\n\n\nCode\n# Realiza el test chi-cuadrado\nchisq.test(w$gdpcap3_08, w$dem_level4)\n\n\n\n    Pearson's Chi-squared test\n\ndata:  w$gdpcap3_08 and w$dem_level4\nX-squared = 64.821, df = 6, p-value = 4.693e-12"
  },
  {
    "objectID": "S_3_Analisis.html#el-test-t-de-student",
    "href": "S_3_Analisis.html#el-test-t-de-student",
    "title": "An√°lisis",
    "section": "El test t de Student",
    "text": "El test t de Student\n\nDefinici√≥n\nEl test t de Student es una prueba estad√≠stica utilizada para determinar si hay una diferencia significativa entre las medias de dos grupos. Se utiliza para comparar las medias de dos muestras, cuando las varianzas de las dos poblaciones son desconocidas y el tama√±o de la muestra es peque√±o. Se basa en la distribuci√≥n t, que es una distribuci√≥n de probabilidad que es similar a la distribuci√≥n normal est√°ndar, pero con una cola ligeramente m√°s plana.\nExisten dos tipos de test t: el test t de muestras independientes y el test t de muestras dependientes.\n1. Test t de muestras independientes: Se utiliza cuando las dos muestras son independientes entre s√≠, como comparar el PIB per c√°pita entre dos pa√≠ses diferentes. Por ejemplo, un investigador puede querer comparar el PIB per c√°pita de Estados Unidos con el de China. La hip√≥tesis nula ser√≠a que no hay diferencia en el PIB per c√°pita entre los dos pa√≠ses y la hip√≥tesis alternativa ser√≠a que hay una diferencia.\n2. Test t de muestras dependientes: Este test se utiliza cuando los dos grupos est√°n relacionados de alguna manera, como comparar el PIB per c√°pita antes y despu√©s de la implementaci√≥n de una cierta pol√≠tica. Por ejemplo, se puede comparar el PIB per c√°pita de un pa√≠s antes y despu√©s de la firma de un acuerdo comercial. La hip√≥tesis nula ser√≠a que no hay diferencia en el PIB per c√°pita antes y despu√©s del acuerdo comercial y la hip√≥tesis alternativa ser√≠a que hay una diferencia.\nResulta importante tener en cuenta que el test t asume que los datos son aproximadamente distribuidos normalmente y que las varianzas de los dos grupos son iguales. Si estas suposiciones no se cumplen, puede ser m√°s apropiado utilizar una prueba no param√©trica como el test de rangos de Wilcoxon (Wilcoxon rank-sum test).\nm test may be more appropriate.\n\n\nVideo\nAsiste al siguiente video sobre el test t:\n\n\n\nEl test t de Student en R\nEn R, puedes realizar un test t de Student utilizando la funci√≥n t.test(). La funci√≥n se puede utilizar para comparar las medias de dos muestras independientes o la media de una sola muestra con un valor conocido.\nCuesti√≥n: ¬øSon los pa√≠ses con mayor√≠as musulmanas menos democr√°ticos que otros?\nHip√≥tesis:\nH0: Los pa√≠ses musulmanes son tan democr√°ticos como los dem√°s pa√≠ses\nH1: Los pa√≠ses musulmanes son menos democr√°ticos que los dem√°s pa√≠ses\n\n\nCode\n# Ejecuta el test t.\nt.test(w$dem_score14~w$muslim, conf.level=0.99)\n\n\n\n    Welch Two Sample t-test\n\ndata:  w$dem_score14 by w$muslim\nt = 8.6908, df = 120.77, p-value = 2.104e-14\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n99 percent confidence interval:\n 1.679539 3.126983\nsample estimates:\n mean in group No mean in group Yes \n         6.210000          3.806739"
  },
  {
    "objectID": "S_3_Analisis.html#el-an√°lisis-de-varianza-anova",
    "href": "S_3_Analisis.html#el-an√°lisis-de-varianza-anova",
    "title": "An√°lisis",
    "section": "El an√°lisis de varianza (ANOVA)",
    "text": "El an√°lisis de varianza (ANOVA)\nEl ANOVA (An√°lisis de Varianza) es un m√©todo estad√≠stico utilizado para determinar si hay una diferencia significativa entre las medias de dos o m√°s grupos. Se utiliza para comparar las medias de m√∫ltiples muestras, cuando las varianzas de las poblaciones son desconocidas y el tama√±o de la muestra es peque√±o.\nExisten tres tipos de ANOVA: ANOVA de un factor, ANOVA de dos factores y ANOVA de varios factores.\n1. ANOVA de un factor: Se utiliza cuando hay un solo factor o variable independiente, como comparar el PIB per c√°pita de varios pa√≠ses. Por ejemplo, un investigador puede querer comparar el PIB per c√°pita de Estados Unidos, China y Jap√≥n. La hip√≥tesis nula ser√≠a que no hay diferencia en el PIB per c√°pita entre los tres pa√≠ses y la hip√≥tesis alternativa ser√≠a que hay una diferencia.\n2. ANOVA de dos factores: Este test se utiliza cuando hay dos variables independientes, como comparar el PIB per c√°pita de varios pa√≠ses antes y despu√©s de la implementaci√≥n de una cierta pol√≠tica. Por ejemplo, un investigador de estudios globales puede querer comparar el PIB per c√°pita de Estados Unidos, China y Jap√≥n antes y despu√©s de la firma de un acuerdo comercial. La hip√≥tesis nula ser√≠a que no hay diferencia en el PIB per c√°pita entre los tres pa√≠ses antes y despu√©s del acuerdo comercial y la hip√≥tesis alternativa ser√≠a que hay una diferencia.\n3. ANOVA de varios factores: Este test se utiliza cuando hay m√°s de dos variables independientes, como comparar el PIB per c√°pita de varios pa√≠ses antes y despu√©s de la implementaci√≥n de una cierta pol√≠tica y tambi√©n el efecto de la poblaci√≥n en el PIB per c√°pita.\nEs importante tener en cuenta que el ANOVA asume que los datos est√°n distribuidos normalmente y que las varianzas de los grupos son iguales. Si estas suposiciones no se cumplen, puede ser m√°s apropiado utilizar una prueba no param√©trica como el test de Kruskal-Wallis.\nTambi√©n resulta importante tener en cuenta que estos ejemplos son solo ejemplos y que los resultados del test ANOVA deben ser interpretados cuidadosamente, considerando otros factores como el tama√±o de la muestra, la potencia del test y el tama√±o del efecto.\n\nVideo\nAsiste al siguiente video sobre los tests ANOVA:\n\n\n\nANOVA en R\nEn R, puedes realizar un test ANOVA utilizando las funciones aov() o Anova() del paquete car, o la funci√≥n oneway.test(). El ANOVA se utiliza para determinar si las medias de dos o m√°s grupos son iguales.\nPor ejemplo, si tienes una variable llamada ‚Äúdata‚Äù que contiene las respuestas de un experimento, y una variable llamada ‚Äúgroup‚Äù que indica el grupo al que pertenece cada respuesta, y quieres probar si las medias de los grupos son iguales, utilizar√≠as el siguiente c√≥digo con la funci√≥n aov():\n\n\nCode\n# Realiza el an√°lisis\nan &lt;- aov(dem_score14~religoin, data = w)\n\n# Recupera los resultados\nsummary(an)\n\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nreligoin      5  226.5   45.30    13.5 5.62e-11 ***\nResiduals   159  533.5    3.36                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\nLa funci√≥n aov() ajusta un modelo ANOVA a los datos, y la funci√≥n summary() devuelve un resumen del modelo que incluye el estad√≠stico F y el valor p para el test. El valor p te indica la probabilidad de observar un estad√≠stico F tan extremo o m√°s extremo que el calculado a partir de tus datos, asumiendo que la hip√≥tesis nula (es decir, que las medias de los grupos son iguales) es verdadera. Un valor p peque√±o (t√≠picamente menor que 0.05) indica que puedes rechazar la hip√≥tesis nula y concluir que hay una diferencia significativa en las medias entre los grupos.\nSi los resultados del ANOVA muestran una diferencia significativa entre los grupos, se recomienda realizar pruebas post-hoc para identificar qu√© grupos son significativamente diferentes. Hay varias pruebas post-hoc disponibles en R como Tukey HSD, Bonferroni, Scheffe, entre otras.\nUn test Tukey HSD es una prueba post-hoc que se utiliza para comparar las medias de m√∫ltiples grupos despu√©s de que un test ANOVA ha revelado una diferencia significativa entre los grupos. Se utiliza para determinar qu√© pares espec√≠ficos de grupos son significativamente diferentes entre s√≠.\nEn R, puedes realizar un test Tukey HSD utilizando la funci√≥n TukeyHSD() del paquete stats. La funci√≥n toma como entrada el resultado de un test ANOVA.\nPor ejemplo, repitamos el ANOVA y agreguemos una prueba Tukey HSD en los grupos:\n\n\nCode\n# Repite el test ANOVA \nan &lt;- aov(dem_score14~religoin, data = w)\n\n# Realiza el test Tukey HSD con un nivel\n# de significancia de 99% o p=0.01.\ntk&lt;-TukeyHSD(an, conf.level = 0.99)\n\n# Guarda los resultados en un  data.frame \ndtk &lt;- data.frame(tk$religoin)\n\n# Redondea los valores para facilitar la interpretaci√≥n\ndtk$p.adj &lt;- round(dtk$p.adj,3)\n\n# Muestra los resultados\ndtk\n\n\n                                          diff        lwr        upr p.adj\nOrthodox Christian-Catholic        -0.72451923 -2.5181276  1.0690891 0.737\nOther Christian-Catholic           -0.20456553 -1.6927776  1.2836465 0.997\nMuslim-Catholic                    -2.76153010 -4.0314235 -1.4916367 0.000\nBuddhist-Catholic                  -1.74008741 -3.8222138  0.3420390 0.053\nOther-Catholic                     -0.24211538 -2.1875568  1.7033260 0.998\nOther Christian-Orthodox Christian  0.51995370 -1.4594172  2.4993246 0.946\nMuslim-Orthodox Christian          -2.03701087 -3.8579346 -0.2160871 0.002\nBuddhist-Orthodox Christian        -1.01556818 -3.4728806  1.4417442 0.718\nOther-Orthodox Christian            0.48240385 -1.8602178  2.8250255 0.981\nMuslim-Other Christian             -2.55696457 -4.0779864 -1.0359427 0.000\nBuddhist-Other Christian           -1.53552189 -3.7796539  0.7086101 0.183\nOther-Other Christian              -0.03754986 -2.1554782  2.0803785 1.000\nBuddhist-Muslim                     1.02144269 -1.0842597  3.1271451 0.559\nOther-Muslim                        2.51941472  0.5487613  4.4900681 0.000\nOther-Buddhist                      1.49797203 -1.0722606  4.0682046 0.349\n\n\n\n\nEl gr√°fico Tukey HSD\nUn gr√°fico Tukey HSD, tambi√©n conocido como un gr√°fico de comparaci√≥n m√∫ltiple de Tukey, es una representaci√≥n gr√°fica de los resultados de una prueba Tukey HSD. Se utiliza para comparar visualmente las medias de m√∫ltiples grupos e identificar qu√© pares espec√≠ficos de grupos son significativamente diferentes entre s√≠.\nUn gr√°fico de Tukey HSD t√≠picamente consiste en una serie de l√≠neas, una para cada grupo. Las l√≠neas muestran los valores m√≠nimo y m√°ximo del intervalo de confianza generado por la prueba. El punto en el centro de la l√≠nea es la diferencia media entre los dos grupos que se est√°n comparando.\nEn ese tipo de gr√°fico, las l√≠neas para los grupos que no son significativamente diferentes entre s√≠ se encuentran conectadas por una l√≠nea horizontal, llamada ‚Äúpromedio com√∫n‚Äù. Esta l√≠nea representa la diferencia media que no se considera estad√≠sticamente significativa. Las l√≠neas para los grupos que son significativamente diferentes entre s√≠ no est√°n conectadas por una l√≠nea horizontal, y la diferencia en las medias se representa por la distancia al promedio com√∫n.\nEl gr√°fico de Tukey HSD tambi√©n suele incluir asteriscos, letras u otros s√≠mbolos para identificar qu√© pares espec√≠ficos de grupos son significativamente diferentes entre s√≠.\nEn R, hay muchas formas diferentes de generar un gr√°fico Tukey HSD. No obstante, dado que utilizaremos el ambiente ggplot en todos nuestros tutoriales (y en el curso de visualizaci√≥n de datos), emplearemos aqu√≠ la funci√≥n ggHSD() del paquete ggiraphExtra:\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggiraphExtra)\n\n# Repite el test de ANOVA\nan &lt;- aov(dem_score14~religoin, data = w)\n\n# Realiza el test Tukey HSD con un nivel\n# de significancia de 99% o p=0.01.\ntk&lt;-TukeyHSD(an, conf.level = 0.99)\n\n\n# Crea un gr√°fico que representa los \n# intervalos de confianza informados\n# por el test Tukey HSD\nggHSD(tk) +\n    theme(axis.text.y = element_text(angle = 0, hjust = 1, size = 10))+\n    theme_classic()\n\n\n\n\n\n\n\nEjercicio\nAhora te toca a ti.\nPrimero, repite el test ANOVA y agrega una prueba Tukey HSD para los grupos dem_score14 y gdp_cap3 del conjunto de datos w.\n\n\nCode\n# Realiza el an√°lisis\nan &lt;- aov(dem_score14~gdp_cap3, data = w)\n\n# Muestra los resultados\nsummary(an)\n\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ngdp_cap3      2  215.4  107.71   33.19 1.32e-12 ***\nResiduals   146  473.9    3.25                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n18 observations deleted due to missingness\n\n\nSegundo, genera las diferencias para cada par de categor√≠as utilizando el test Tukey HSD:\n\n\nCode\n# Repite el test de ANOVA\nan &lt;- aov(dem_score14~gdp_cap3, data = w)\n\n# Realiza el test Tukey HSD con un nivel\n# de significancia de 99% o p=0.01.\ntk&lt;-TukeyHSD(an, conf.level = 0.99)\n\n# Guarda los resultados en un  data.frame \ndtk &lt;- data.frame(tk$gdp_cap3)\n\n# Redondea los valores para facilitar la interpretaci√≥n\ndtk$p.adj &lt;- round(dtk$p.adj,3)\n\n# Muestra los resultados\ndtk\n\n\n                diff         lwr      upr p.adj\nMiddle-Low  1.018329 -0.04407901 2.080738 0.014\nHigh-Low    2.896038  1.83362933 3.958446 0.000\nHigh-Middle 1.877708  0.78932033 2.966096 0.000\n\n\nTercero, crea el gr√°fico para representar los coeficientes:\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggiraphExtra)\n\n# Repite el test de ANOVA\nan &lt;- aov(dem_score14~gdp_cap3, data = w)\n\n# Realiza el test Tukey HSD con un nivel\n# de significancia de 99% o p=0.01.\ntk&lt;-TukeyHSD(an, conf.level = 0.99)\n\n# Crea un gr√°fico que representa los \n# intervalos de confianza informados\n# por el test Tukey HSD\nggHSD(tk) +\n    theme(axis.text.y = element_text(angle = 0, hjust = 1, size = 10))+\n    theme_classic()"
  },
  {
    "objectID": "basico.html",
    "href": "basico.html",
    "title": "Fundamentosde visualizaci√≥n de datos",
    "section": "",
    "text": "El documental de PBS ‚ÄúEl arte de la visualizaci√≥n de datos‚Äù resulta muy informativo sobre la importancia de la visualizaci√≥n de datos:\n\n\nTodos los d√≠as vemos c√≥mo se manipula la informaci√≥n para intentar convencer a la gente. Los gr√°ficos no se quedan fuera de esa tendencia. El corto video abajo nos muestra algunas de las estrategias m√°s comunes para descubrir intentos de mentir con gr√°ficos:"
  },
  {
    "objectID": "basico.html#por-qu√©-visualizar-datos",
    "href": "basico.html#por-qu√©-visualizar-datos",
    "title": "Fundamentosde visualizaci√≥n de datos",
    "section": "",
    "text": "El documental de PBS ‚ÄúEl arte de la visualizaci√≥n de datos‚Äù resulta muy informativo sobre la importancia de la visualizaci√≥n de datos:\n\n\nTodos los d√≠as vemos c√≥mo se manipula la informaci√≥n para intentar convencer a la gente. Los gr√°ficos no se quedan fuera de esa tendencia. El corto video abajo nos muestra algunas de las estrategias m√°s comunes para descubrir intentos de mentir con gr√°ficos:"
  },
  {
    "objectID": "basico.html#qu√©-es-la-visualizaci√≥n-de-datos",
    "href": "basico.html#qu√©-es-la-visualizaci√≥n-de-datos",
    "title": "Fundamentosde visualizaci√≥n de datos",
    "section": "¬øQu√© es la visualizaci√≥n de datos?",
    "text": "¬øQu√© es la visualizaci√≥n de datos?\nLa visualizaci√≥n de datos es una forma de comunicar informaci√≥n de manera efectiva utilizando elementos visuales como gr√°ficos, mapas y tablas. Se trata de una parte esencial del trabajo cient√≠fico, puesto que representa tanto una herramienta de an√°lisis como un instrumento de comunicaci√≥n de los resultados.\nDentro de los √°mbitos cient√≠ficos, los gr√°ficos se consideran como parte del proceso de exploraci√≥n de datos. Resultan muy √∫tiles para descubrir patrones, validar la calidad de los datos y entender procesos que ser√≠an m√°s dif√≠ciles de entender si se presentaran en forma de tablas o texto.\nM√°s recientemente, su uso se ha extendido a la comunicaci√≥n de resultados y a la divulgaci√≥n cient√≠fica, ya que permiten presentar de manera clara y efectiva los hallazgos de un an√°lisis de datos tanto a expertos como a un p√∫blico no especializado."
  },
  {
    "objectID": "basico.html#por-qu√©-es-importante-la-visualizaci√≥n-de-datos",
    "href": "basico.html#por-qu√©-es-importante-la-visualizaci√≥n-de-datos",
    "title": "Fundamentosde visualizaci√≥n de datos",
    "section": "¬øPor qu√© es importante la visualizaci√≥n de datos?",
    "text": "¬øPor qu√© es importante la visualizaci√≥n de datos?\nTomemos como ejemplo, el gr√°fico ‚ÄúWarming Stripes‚Äù, creado por Edward Hakwings en 2018 para representar los cambios en las temperaturas medias anuales entre 1850 y 2017.\n \nEste gr√°fico se ha convertido en un s√≠mbolo de la lucha contra el cambio clim√°tico y ha sido utilizado por organizaciones como la ONU y la NASA para concienciar sobre el problema. ¬øPor qu√©? Examinemos algunos elementos que hacen este gr√°fico tan efectivo:\n\nSimplicidad: El gr√°fico es simple y f√°cil de entender. No hay elementos de distracci√≥n, comentarios o decoraciones indeseadas, ni siquiera hace falta una escala informando qu√© se mide. Por solo mirarlo, ya nos damos cuenta de que se trata de una secuencia lineal de temperatura. Aqu√≠, la regla de ‚Äúmenos es m√°s‚Äù se afirma con mucha potencia.\nEl uso del color: El uso del color es muy efectivo. El color azul representa temperaturas m√°s bajas, mientras que el rojo representa temperaturas m√°s altas. La elecci√≥n de estos colores es muy acertada, ya que el azul y el rojo son colores que se asocian com√∫nmente con el fr√≠o y el calor. Por lo tanto, no hace falta una leyenda para explicar qu√© representa cada barra.\nEl uso de la escala: Por tratarse de cambios (y no de valores absolutos), la variaci√≥n entre las observaciones aumenta, lo que facilita la visualizaci√≥n de un patr√≥n claro e inequ√≠voco de calentamiento global.\n\nEn resumen, aunque siempre haya habido grupos contrarios a la tesis del calentamiento global, a partir de la creaci√≥n de esta visualizaci√≥n, cualquiera que quiera argumentar en contra tendr√° mucha mayor dificultad en hacerlo y necesitar√° argumentos muy convincentes para disuadir a la gente.\nTeniendo en mente el ejemplo anterior, podemos decir que la visualizaci√≥n de datos es importante por varias razones:\n\nFacilita la comprensi√≥n de los datos: Los gr√°ficos y las visualizaciones permiten comprender mejor los datos y descubrir patrones y relaciones que ser√≠an dif√≠ciles de detectar de otra manera. Es cada vez m√°s com√∫n trabajar con una cantidad enorme de datos que ser√≠an inabarcables sin estrategias heur√≠sticas que posibilitaran su s√≠ntesis de manera efectiva. Los gr√°ficos son una de las formas de abstracci√≥n m√°s poderosas. Vemos que se trata de un gr√°fico muy f√°cil de leer.\nFacilita la comunicaci√≥n de resultados: Los gr√°ficos y las visualizaciones permiten comunicar de manera clara los resultados de un an√°lisis de datos a expertos y a un p√∫blico no especializado. No hace falta ser un experto en climatolog√≠a para entender que las barras rojas son cada vez m√°s largas y que eso significa que las temperaturas est√°n aumentando. Personas con muy distintos niveles educativos pueden entender el mensaje.\nFacilita la toma de decisiones: Los gr√°ficos y las visualizaciones permiten tomar decisiones informadas basadas en datos y evidencia. El gr√°fico de las barras de temperatura deja claro que tenemos un problema y que hace falta tomar cartas en el asunto, pues el crecimiento parece ser exponencial.\nFacilita la identificaci√≥n de problemas: Los gr√°ficos y las visualizaciones permiten identificar problemas y errores en los datos, como valores at√≠picos y datos faltantes.\nFacilita la identificaci√≥n de oportunidades: Los gr√°ficos y las visualizaciones permiten identificar oportunidades y tendencias que pueden ser aprovechadas para mejorar los procesos y los resultados.\n\n\nPor lo tanto, no hace falta tener un super gr√°fico lleno de parafernalia y ‚Äúcachibaches‚Äù para comunicar efectivamente un mensaje. La simplicidad y la claridad son las claves para una visualizaci√≥n efectiva."
  },
  {
    "objectID": "basico.html#reglas-b√°sicas",
    "href": "basico.html#reglas-b√°sicas",
    "title": "Fundamentosde visualizaci√≥n de datos",
    "section": "Reglas b√°sicas",
    "text": "Reglas b√°sicas\nExiste un conjunto de reglas b√°sicas que nos ayudan a la hora de crear visualizaciones de alta calidad. Si uno se adhiere a estos principios b√°sicos, es mucho m√°s probable que sea capaz de comunicar de manera efectiva la informaci√≥n que se desea transmitir.\n\nTenga una historia que contar o buscar\nYa s√© que parece discurso de vendedor de autos usados o de conferenciante de las charlas TED, pero es cierto. ¬øPor qu√© el gr√°fico es importante? ¬øQu√© pretende descubrir o revelar? No es necesario que sea una historia compleja o sumamente elaborada, sino que sea clara, f√°cil de entender y, sobre todo, que importe a la gente. Y para que importe a la gente, debes saber a qu√© gente te diriges, aunque, a veces, uno termina sorprendi√©ndose de la diversidad de personas que se interesan por un tema.\nEn 2018, terminadas las elecciones presidenciales de Brasil en las que gan√≥ Jair Bolsonaro, empez√≥ una discusi√≥n en los medios y las redes sociales sobre cu√°l habr√≠a sido el apoyo efectivo del tercer candidato en la disputa, Ciro Gomes, al candidato del Partido de los Trabajadores (PT), Fernando Haddad, en la segunda vuelta de los comicios. Muchos apoyadores del PT dec√≠an que Ciro Gomes hab√≠a sido el responsable de la derrota de Haddad, mientras que otros dec√≠an que no hab√≠a sido as√≠. Entonces, he decidido aplicar una t√©cnica de inferencia ecol√≥gica, que intenta descubrir patrones a partir de datos agregados, para ver si pod√≠a descubrir algo.\nPara casa mesa, he calculado la cantidad de votos que se habr√≠an transferidos de unos a otros. Con esas informaciones, pod√≠a estimar cu√°l proporci√≥n de votos de cada candidato se transfer√≠a a otros, los blancos y nulos y las abstenciones. Con esos datos, he creado el siguiente gr√°fico cordas que revela la transferencia estimada de votos entre candidatos:\n\nEn la izquierda del gr√°fico vemos la red completa de transferencias, con los candidatos derrotados en la primera vuelta en la izquierda y las opciones de voto en la segunda vuelta a la derecha. En la derecha de la imagen, vemos la transferencia de cada candidato por separado. He decidido separar cada uno de ellos para facilitar la visualizaci√≥n de los patrones.\nVemos que las secciones electorales que votaron en mayor medida a Ciro Gomes han sido las √∫nicas que inequ√≠vocamente han transferido votos a Fernando Haddad. Los patrones de los dem√°s candidatos favorecen a Bolsonaro o son m√°s complejos, sin una preferencia clara.\nAunque se tratara de una publicaci√≥n privada en facebook, destinada solamente a mis amigos polit√≥logos, en poco tiempo el gr√°fico se ha vuelto viral (infelizmente, sin la explicaci√≥n metodol√≥gica que lo acompa√±aba). Muchos de los apoyadores de Ciro lo compart√≠an y comentaban para contrarrestar las acusaciones de los del PT de que los ‚Äúciristas‚Äù hab√≠an votado nulo o apoyado a Bolsonaro. Este impacto inesperado solo fue posible porque el gr√°fico ten√≠a una historia que contar y que importaba a la gente.\n\n\nQue tus datos sean de calidad\nEn la comunidad de an√°lisis de datos en ingl√©s, se suele emplear una expresi√≥n que me parece excelente para entender los problemas y virtudes de cualquier investigaci√≥n o gr√°fico: ‚Äúgarbage in, garbage out‚Äù (algo en espa√±ol como ‚Äúaunque la mona se vista de seda, mona se queda‚Äù o quod natura non dat, Salmantica non praestat). Es decir, si no eres Mois√©s, no puedes sacar agua de piedra. Creo que las referencias populares nos quieren decir es: un an√°lisis basado en datos de mala calidad no puede aportar nada de interesante. No resulta casual que la mayor parte del trabajo de investigaci√≥n se dedique a la recolecci√≥n y limpieza de datos y en las revisiones por pares se hace hincapi√© en la consistencia de los aspectos metodol√≥gicos. Tienen que ser interesantes y confiables para ser v√°lidos.\n\n\n¬°Esto son gr√°ficos, no pinturas Rococ√≥, se√±ores!\nA m√≠, personalmente, me gusta el Rococ√≥. Esos palacios decorados, esas pinturas de Fragonard o Watteau, todo muy bonito, un lujazo manifiesto en colores y formas. No obstante, un gr√°fico (al menos en un principio) no deber√≠a ser algo que recargue los sentidos. Obviamente, hay controversias y algunos dise√±adores defienden la idea de que un gr√°fico es una forma de expresi√≥n visual m√°s y, por lo tanto, puede asumir cualquier estilo est√©tico que se desee.\nNo obstante, si queremos comunicar de forma r√°pida y efectiva a un p√∫blico que no tiene tiempo ni busca una contemplaci√≥n est√©tica en nuestros gr√°ficos, lo mejor es mantenerlos simples y claros. No es necesario que sean aburridos, pero s√≠ que sean efectivos.\n¬øQu√© quiero decir simples y claros? Primero, que no se debe abusar de los colores, las formas y los elementos decorativos. Un gr√°fico debe ser f√°cil de leer y de entender. Si el lector tiene que esforzarse para entender lo que se quiere comunicar, es probable que no lo haga. Llenar los gr√°ficos de elementos visuales vac√≠os de significado (para evitar el horror vacui) resultar√≠a contraproducente. Eso no quiere decir que no se puedan emplear elementos est√©ticos para facilitar el entendimiento y causar una impresi√≥n placentera en los lectores. Como dijo Edward Tufte en el documental de la PBS, ‚Äúel contenido siempre viene primero, la belleza naturalmente le seguir√°‚Äù.\n\n\nHuye de las plantillas de Excel, SPSS, Stata o R\n¬°Pero, tampoco nos pasemos de dejados! Si examinamos una muestra de publicaciones cient√≠ficas en las ciencias sociales resulta impresionante ver el poco cuidado est√©tico que se tiene con los gr√°ficos. Aunque no es necesario que sean obras de arte, s√≠ es importante que sean f√°ciles de leer y que aprovechen para informar lo mejor posible. No es necesario que sean muy elaborados, pero s√≠ que sean claros, efectivos y atractivos.\nEn la mayor√≠a de los casos, los autores simplemente copian y pegan los resultados de Excel, SPSS o Stata (incluso R) en sus documentos sin preocuparse por c√≥mo el perfeccionamento de elementos visuales como el color, el tipo de fuente o la disposici√≥n de los s√≠mbolos puede mejorar la comprensi√≥n de los datos. Un gr√°fico atractivo, adem√°s de limpio y efectivo, resulta agradable y llama la atenci√≥n por el placer est√©tico que produce en el observador. Tambi√©n es una forma de demostrar cierto estilo o sofisticaci√≥n en el trabajo de un autor. Es como su ‚Äúmarca‚Äù personal. Es la impresi√≥n que suelo tener cuando veo un gr√°fico de dise√±adoras como Federica Fragapane, Giorgia Lupi o Nadieh Bremer.\nAtraer la atenci√≥n del lector no es cosa menor. Tenemos a nuestra disposici√≥n miles de art√≠culos y libros para leer, y si no logramos captar la atenci√≥n del lector, es probable que nuestro trabajo no sea le√≠do. Gr√°ficos bien acabados revelan atenci√≥n al detalle y preocupaci√≥n por la calidad del trabajo que se lleva a cabo. Utilizando una analog√≠a con la moda, ser√≠a como hacer una ‚Äúoperaci√≥n bikini‚Äù y luego ir a la playa en ch√°ndal de andar por casa.\nNo digo que te conviertas en un dise√±ador para hacer un gr√°fico atractivo, pero s√≠ es necesario tener en cuenta algunos principios b√°sicos de dise√±o y visualizaci√≥n de datos. Existe una infinitud de manuales de visualizaci√≥n de datos con cap√≠tulos espec√≠ficos sobre la elecci√≥n de colores, fuentes, tama√±os, formas, etc. Mi sugerencia es que consult√©is algunas de esas obras para aprender los principios b√°sicos, valer√° mucho la pena (Brewer 2005; Healy 2019; Brewer, Hatchard, and Harrower 2003; Yau 2011, 2013; Tufte 2001; Cleveland 1993; Munzner 2014; Few 2004). Ver√©is que a partir de cierto momento se empiezan a repetir los mismos consejos y recomendaciones. En ese instante, ya tendr√°s lo suficiente para aplicar en tus propios gr√°ficos.\n\n\n\n\n\n\n\n\n\nEn el gr√°fico anterior, he comparado tres gr√°ficos realizados con plantillas de Excel, Stata y ggplot2 con uno hecho por m√≠. Aunque los tres primeros gr√°ficos son correctos y cumplen con su funci√≥n, pueden mejorar mucho.\nA√±adimos dos variables m√°s: urbanizaci√≥n para el tama√±o y si se trata de un pa√≠s de mayor√≠a musulmana. Adem√°s, incorporamos un t√≠tulo en negrita, un subt√≠tulo y una fuente. Tambi√©n hemos cambiado los colores y la posici√≥n de la leyenda y lo hemos convertido en una versi√≥n interactiva con un ‚Äútooltip‚Äù con los datos representados de forma detallada."
  },
  {
    "objectID": "ciencia_datos.html",
    "href": "ciencia_datos.html",
    "title": "Ciencia de datospol√≠ticos",
    "section": "",
    "text": "El an√°lisis de datos no representa una gran innovaci√≥n para los cient√≠ficos sociales. Desde hace d√©cadas, empleamos t√©cnicas de recolecci√≥n y an√°lisis de datos que nos permiten identificar patrones y llevar a cabo inferencias sobre c√≥mo funciona la sociedad, la pol√≠tica o la econom√≠a. Empleamos t√©cnicas cualitativas y estad√≠sticas para analizar los datos, as√≠ como diferentes m√©todos de comunicaci√≥n de resultados, como la visualizaci√≥n de datos o la narrativa basada en datos. Adem√°s, empleamos datos secundarios o controlamos t√©cnicas de recolecci√≥n de datos como encuestas, entrevistas o experimentos.\nNo obstante, ¬øpor qu√© ahora se ha puesto de moda el t√©rmino ciencia de datos? En gran medida, la respuesta se encuentra en un cambio de paradigma entre los profesionales de tecnolog√≠a de informaci√≥n (TI). Antes, el TI se dedidaba fundamentalmente en la gesti√≥n de bases de datos y en la programaci√≥n de aplicaciones. El an√°lisis de datos se debaja en manos de los departamentos especializados de grandes corporaciones, como financiero, contabilidad, etc. No obstante, hoy, las fronteras entre el tratamiento y recolecci√≥n de datos y su an√°lisis se han difuminado. M√°s y m√°s profesionales de TI se dedican a analizar datos y desarrollan nuevos m√©todos a partir de la combinaci√≥n de una cantidad creciente de datos con t√©cnicas estad√≠sticas tradicionales. Modelos estad√≠sticos tradicionales, como la regresi√≥n log√≠stica, por ejemplo, se han empleado de forma innovadora utilizando cantidades ingentes de datos para no solo explicar fen√≥menos, sino para predecir comportamientos futuros.\nLa difusi√≥n de Internet y la digitalizaci√≥n de diversos procesos pol√≠ticos, econ√≥micos y sociales han generado un volumen sin precedente de datos que exig√≠an nuevos m√©todos de an√°lisis. De golpe, un polit√≥logo ten√≠a acceso a todas las series de votaci√≥n por candidato y mesa desde hace 30 a√±os o todos los diarios de sesiones de un parlamento desde la redemocratizaci√≥n. Este aluvi√≥n de datos trajo consigo nuevos retos para el an√°lisis. Los m√©todos tradicionales de organizaci√≥n de datos (planillas Excel, documentos Word o bases de datos de SPSS) se han quedado cortos frente a nuevos formatos y la exigencia de conocimientos de programaci√≥n para convertir, por ejemplo, texto en informaci√≥n que permita el an√°lisis.\nPor esa raz√≥n, investigadores y cient√≠ficos sociales han percibido las ventajas y oportunidades ofrecidas por mejores conocimientos de programaci√≥n y tratamiento de datos. De golpe, result√≥ posible tratar, estructurar y analizar cantidades de datos hasta poco tiempo impensables. ¬øC√≥mo mapear la evoluci√≥n de los derechos femeninos en 30 a√±os de debates parlamentarios en cinco pa√≠ses de Am√©rica Latina? Si consideramos que una sola legislatura puede generar alrededor de 30 mil p√°ginas de debates, un an√°lisis manual resulta imposible. No obstante, con t√©cnicas de procesamiento de lenguaje natural y an√°lisis de redes, tal an√°lisis se ha viable.\nComo hemos podido ver en el video arriba, nuestro trabajo se asemeja m√°s al de un analista de datos que al de un cient√≠fico de datos de forma m√°s general. Utilizamos diferentes herramientas para encontrar patrones en los datos, desarrollar modelos explicativos y empleamos t√©cnicas de visualizaci√≥n tanto para explorar como para comunicar nuestros resultados. Adem√°s, somos expertos en la construcci√≥n de narrativas coherentes que articulan una multiplicidad de datos en un relato comprensible y que sirve de base para la toma de decisi√≥n de distintos actores, tanto p√∫blicos como privados.\nNo obstante, resulta cada vez m√°s interesante navigar por ambos mundos y conocer las t√©cnicas de manejo y modelaje de datos existentes. Tal necesidad se hace incluso m√°s premente por los cambios del modo de hacer ciencia en las ciencias sociales, que se acercan a pasos agigantados a las ciencias naturales. Grupos de investigaci√≥n multidisciplinarios y laboratorios, antes raros, se han convertido en el foco de financiaci√≥n por gobiernos y otras entidades. La colaboraci√≥n entre polit√≥logos, inform√°ticos, soci√≥logos y estad√≠sticos resulta m√°s com√∫n y deseada."
  },
  {
    "objectID": "ciencia_datos.html#qu√©-es-ciencia-de-datos",
    "href": "ciencia_datos.html#qu√©-es-ciencia-de-datos",
    "title": "Ciencia de datospol√≠ticos",
    "section": "",
    "text": "El an√°lisis de datos no representa una gran innovaci√≥n para los cient√≠ficos sociales. Desde hace d√©cadas, empleamos t√©cnicas de recolecci√≥n y an√°lisis de datos que nos permiten identificar patrones y llevar a cabo inferencias sobre c√≥mo funciona la sociedad, la pol√≠tica o la econom√≠a. Empleamos t√©cnicas cualitativas y estad√≠sticas para analizar los datos, as√≠ como diferentes m√©todos de comunicaci√≥n de resultados, como la visualizaci√≥n de datos o la narrativa basada en datos. Adem√°s, empleamos datos secundarios o controlamos t√©cnicas de recolecci√≥n de datos como encuestas, entrevistas o experimentos.\nNo obstante, ¬øpor qu√© ahora se ha puesto de moda el t√©rmino ciencia de datos? En gran medida, la respuesta se encuentra en un cambio de paradigma entre los profesionales de tecnolog√≠a de informaci√≥n (TI). Antes, el TI se dedidaba fundamentalmente en la gesti√≥n de bases de datos y en la programaci√≥n de aplicaciones. El an√°lisis de datos se debaja en manos de los departamentos especializados de grandes corporaciones, como financiero, contabilidad, etc. No obstante, hoy, las fronteras entre el tratamiento y recolecci√≥n de datos y su an√°lisis se han difuminado. M√°s y m√°s profesionales de TI se dedican a analizar datos y desarrollan nuevos m√©todos a partir de la combinaci√≥n de una cantidad creciente de datos con t√©cnicas estad√≠sticas tradicionales. Modelos estad√≠sticos tradicionales, como la regresi√≥n log√≠stica, por ejemplo, se han empleado de forma innovadora utilizando cantidades ingentes de datos para no solo explicar fen√≥menos, sino para predecir comportamientos futuros.\nLa difusi√≥n de Internet y la digitalizaci√≥n de diversos procesos pol√≠ticos, econ√≥micos y sociales han generado un volumen sin precedente de datos que exig√≠an nuevos m√©todos de an√°lisis. De golpe, un polit√≥logo ten√≠a acceso a todas las series de votaci√≥n por candidato y mesa desde hace 30 a√±os o todos los diarios de sesiones de un parlamento desde la redemocratizaci√≥n. Este aluvi√≥n de datos trajo consigo nuevos retos para el an√°lisis. Los m√©todos tradicionales de organizaci√≥n de datos (planillas Excel, documentos Word o bases de datos de SPSS) se han quedado cortos frente a nuevos formatos y la exigencia de conocimientos de programaci√≥n para convertir, por ejemplo, texto en informaci√≥n que permita el an√°lisis.\nPor esa raz√≥n, investigadores y cient√≠ficos sociales han percibido las ventajas y oportunidades ofrecidas por mejores conocimientos de programaci√≥n y tratamiento de datos. De golpe, result√≥ posible tratar, estructurar y analizar cantidades de datos hasta poco tiempo impensables. ¬øC√≥mo mapear la evoluci√≥n de los derechos femeninos en 30 a√±os de debates parlamentarios en cinco pa√≠ses de Am√©rica Latina? Si consideramos que una sola legislatura puede generar alrededor de 30 mil p√°ginas de debates, un an√°lisis manual resulta imposible. No obstante, con t√©cnicas de procesamiento de lenguaje natural y an√°lisis de redes, tal an√°lisis se ha viable.\nComo hemos podido ver en el video arriba, nuestro trabajo se asemeja m√°s al de un analista de datos que al de un cient√≠fico de datos de forma m√°s general. Utilizamos diferentes herramientas para encontrar patrones en los datos, desarrollar modelos explicativos y empleamos t√©cnicas de visualizaci√≥n tanto para explorar como para comunicar nuestros resultados. Adem√°s, somos expertos en la construcci√≥n de narrativas coherentes que articulan una multiplicidad de datos en un relato comprensible y que sirve de base para la toma de decisi√≥n de distintos actores, tanto p√∫blicos como privados.\nNo obstante, resulta cada vez m√°s interesante navigar por ambos mundos y conocer las t√©cnicas de manejo y modelaje de datos existentes. Tal necesidad se hace incluso m√°s premente por los cambios del modo de hacer ciencia en las ciencias sociales, que se acercan a pasos agigantados a las ciencias naturales. Grupos de investigaci√≥n multidisciplinarios y laboratorios, antes raros, se han convertido en el foco de financiaci√≥n por gobiernos y otras entidades. La colaboraci√≥n entre polit√≥logos, inform√°ticos, soci√≥logos y estad√≠sticos resulta m√°s com√∫n y deseada."
  },
  {
    "objectID": "ciencia_datos.html#c√≥mo-se-aplica-a-la-pol√≠tica",
    "href": "ciencia_datos.html#c√≥mo-se-aplica-a-la-pol√≠tica",
    "title": "Ciencia de datospol√≠ticos",
    "section": "¬øC√≥mo se aplica a la pol√≠tica?",
    "text": "¬øC√≥mo se aplica a la pol√≠tica?\n\nEmpezamos esta secci√≥n con el v√≠deo de Cambridge Analytica, porque no hay nadie mejor que ellos para explicarnos c√≥mo esa nueva perspectiva de datos puede ser (mal)empleada en la pol√≠tica. La empresa ha sido objeto de un esc√°ndalo al recolectar datos de forma no autorizada y emplearlos para influir en las elecciones estadunidenses de 2016. A trav√©s de la recolecci√≥n de datos de millones de usuarios de Facebook, la empresa fue capaz de desarrollar perfiles psicol√≥gicos de los votantes y dirigir mensajes espec√≠ficos a cada uno de ellos. Aunque no sabemos exactamente cu√°nto y c√≥mo influy√≥ en el voto, la publicidad recibida por el caso ha abierto un debate importante sobre la √©tica en el uso de los datos personales y c√≥mo estos pueden ser empleados para influir en la toma de decisiones de los ciudadanos.\nNuevas aplicaciones de la ciencia de datos en la pol√≠tica se han vuelto comunes. Modelos de an√°lisis de texto permiten identificar patrones en discursos pol√≠ticos y debates parlamentarios. An√°lisis de redes de coautor√≠a de leyes se emplean para medir cambios en la polarizaci√≥n de los diputados. Nuevos datos + nuevas t√©cnicas de an√°lisis = nuevas preguntas y m√©todos para entender c√≥mo funciona la pol√≠tica.\nLo mismo pasa en las pol√≠ticas p√∫blicas. Aunque el an√°lisis de datos aplicado a la evaluaci√≥n de pol√≠ticas p√∫blicas no sea algo nuevo, la cantidad de datos disponibles y las t√©cnicas de an√°lisis han cambiado radicalmente. Hoy, es posible evaluar el impacto de una pol√≠tica p√∫blica en tiempo real, a trav√©s de la recolecci√≥n de datos en l√≠nea y sistemas de informaci√≥n integrados. Muchas universidades han desarrollado incluso grados o posgrados especializados en el an√°lisis de datos orientado hacia las pol√≠ticas p√∫blicas:\n\nComo vemos, los cambios en la forma de hacer ciencia han sido radicales y han abierto un abanico de posibilidades para los investigadores de ciencias sociales. Los modelos de Inteligencia Artificial prometen ser a√∫n m√°s disruptivos en un futuro cercano. Por ello, resulta necesario, al menos, tener un conocimiento b√°sico de tales tecnolog√≠as y c√≥mo se aplican a distintos √°mbitos de la ciencia pol√≠tica y las pol√≠ticas p√∫blicas."
  },
  {
    "objectID": "ciencia_datos.html#paquetes-estad√≠sticos-o-lenguajes-de-programaci√≥n",
    "href": "ciencia_datos.html#paquetes-estad√≠sticos-o-lenguajes-de-programaci√≥n",
    "title": "Ciencia de datospol√≠ticos",
    "section": "Paquetes estad√≠sticos o lenguajes de programaci√≥n",
    "text": "Paquetes estad√≠sticos o lenguajes de programaci√≥n\nNo s√© si por mero h√°bito o puro vicio, muchos programas de grado y posgrado en ciencias sociales siguen ense√±ando a sus estudiantes a usar paquetes estad√≠sticos como el SPSS en lugar de lenguajes de programaci√≥n como R o Python. El principal motivo es quizas la facilidad de uso de los primeros, que permiten hacer an√°lisis estad√≠sticos sin necesidad de programar. Las interfaces basadas en men√∫s y ventanas emergentes pasan una impresi√≥n de control y familiaridad con los an√°lisis estad√≠sticos, algo que ni siempre es cierto.\nLos lenguajes de programaci√≥n, por otra parte, resultan m√°s dif√≠ciles de aprender, sobre todo si uno nunca ha programado en su vida. Sin embargo, amplian el abanico de posibilidades de an√°lisis mucho m√°s all√° de lo que podr√≠a so√±ar alguien con fluencia en SPSS, por ejemplo. El video abajo ayuda a entender las diferencias entre ambos y por qu√© deber√≠amos abandonar los paquetes estad√≠sticos en favor de los lenguajes de programaci√≥n:\n\nSi uno est√° convencido de que debe aprender a programar, emerge otro debate: ¬øR o Python? Ambos lenguajes son muy √∫tiles para el an√°lisis de datos, ambos se utilizan en aplicaciones punteras de IA y ambos tienen una comunidad de usuarios muy activa. R es m√°s empleado entre investigadores, mientras que Python es m√°s popular en la industria. Las capacidades de gr√°ficos de R son superiores a las de Python, pero Python es m√°s vers√°til y se emplea en una gama m√°s amplia de aplicaciones. El video abajo ayuda a entender las diferencias entre ambos:\n\nLa principal raz√≥n para aprender R en la ciencia pol√≠tica se encuentra en que la mayor√≠a de los art√≠culos y an√°lisis de datos se programan en R. No obstante, tal preponderancia puede desaparecer en el futuro. Muchos modelos de IA se programan en Python y algunos investigadores empiezan a mezclar ambos lenguajes en sus an√°lisis."
  },
  {
    "objectID": "ciencia_datos.html#tengo-que-aprender-a-programar-c√≥mo-empiezo",
    "href": "ciencia_datos.html#tengo-que-aprender-a-programar-c√≥mo-empiezo",
    "title": "Ciencia de datospol√≠ticos",
    "section": "Tengo que aprender a programar, ¬øc√≥mo empiezo?",
    "text": "Tengo que aprender a programar, ¬øc√≥mo empiezo?\nMuchos investigadores de ciencias sociales se sienten impulsados a adquirir nuevos conocimientos en programaci√≥n y an√°lisis de datos. Dicha tarea muchas veces puede parecer abrumadora. No obstante, existe un enorme abanico de recursos gratuitos y de pago que facilitan enormemente el proceso de aprendizaje.\n\nJugando\nUna forma de aprender a programar cuando uno no tiene ninguna experiencia previa es jugando. Existen varios juegos educativos que te permiten aprender conceptos b√°sicos de programaci√≥n de forma muy divertida y progresiva. En esta secci√≥n, presentamos algunos juegos, algunos gratuitos y otros de pago, que te pueden ayudar a aprender a programar de forma muy divertida y progresiva. Con estos juegos, no aprender√°s a programar en un lenguaje de programaci√≥n real, pero s√≠ a pensar de forma algor√≠tmica y a resolver problemas de forma estructurada. Se trata de un paso irreemplazable en el proceso de aprendizaje de la programaci√≥n. Aunque puedan parecer ‚Äúinfantiles‚Äù y la publicidad vaya dirigida a padres que quieren que sus hijos aprendan principios de programaci√≥n y ciencia de la computaci√≥n, tengo a doctorandos m√≠os enganchados a algunos de estos juegos.\nRabbids Coding\n\nRabbids Coding es quiz√°s el m√°s f√°cil de obtener y jugar. Se trata de un juego educativo en el que puedes aprender algunos conceptos b√°sicos de programaci√≥n como el de algoritmo, reiteraci√≥n, condiciones, bucles jugando. El juego tiene dos grandes puntos fuertes. Primero, es totalmente gr√°tis y se puede jugar en cualquier ordenador o m√≥vil. Segundo, es muy divertido y adictivo. Empieza en un nivel muy f√°cil, pero va a aumentando la complejidad a medida en que vas superando niveles.\n7 Billion Humans\n\nDisponible en las plataformas Steam, Nintengo Switch o en la App Store de Apple, 7 billion humans es un juego de programaci√≥n un poco m√°s avanzado que Rabbids Coding. Aunque sea de pago (alrededor 6 o 7 d√≥lares en la App Store de Apple o 15 en Steam), en el puedes aprender conceptos m√°s avanzados de programaci√≥n de forma muy divertida y progresiva. Los conceptos son los mismos: algoritmo, reiteraci√≥n, condiciones, bucles, funciones, entre otros. Aprender√°s a pensar de forma algor√≠tmica y a resolver problemas de forma estructurada como en un lenguaje de programaci√≥n real, pero utilizando bloques, lo que facilita el aprendizaje.\nSwift Playgrounds\n\nSwift Playgrounds es un juego educativo de Apple que te permite aprender a programar en Swift, el lenguaje de programaci√≥n de Apple. Lo m√°s interesante no est√° en aprender Swift, sino en entrar en contacto con un lenguaje de script, algo m√°s avanzado que los juegos anteriores. El juego trata de ayudar a un personaje a resolver problemas de programaci√≥n de forma progresiva: recolectar yemas, abrir portales, etc. Para ello, tienes que crear programas en Swift, algo que resulta muy sencillo gracias a la interfaz gr√°fica del juego. Adem√°s, no hay l√≠mite. La interfaz de Playgrounds permite que puedas escribir incluso aplicaciones profesionales, si avanzas lo suficiente. La aplicaci√≥n es totalmente gratis, pero solo est√° disponible en ordenadores Mac o en iPads.\n\n\nAsistiendo a cursos online\nExiste una enorme cantidad de recursos online para el aprendizaje de R y de programaci√≥n en general. Se pueden encontrar una multitud de videos y tutoriales en Youtube o libros online gratuitos que te pueden ayudar a aprender a programar. Los cursos online representa una opci√≥n m√°s estructurada y progresiva de estudiar. Aunque sean de pago, el coste no suele ser muy elevado (cuesta lo mismo o incluso menos que un libro t√©cnico impreso) y la calidad suele ser alta, especialmente aquellos organizados por universidades o empresas de tecnolog√≠a. En esta sesi√≥n recomiendo dos que pueden ser √∫tilies para los iniciantes. Ambos se encuentran en Coursera, aunque se pueden encontrar otras alternativas en EdX, Udemy, Codecademy, etc. Aunque est√©n en ingl√©s, poseen subt√≠tulos en espa√±ol que permiten entender todo el contenido sin problemas.\nEl primero es la especializaci√≥n en ciencia de datos de la Universidad Johns Hopkins. Ha sido el que he cursado yo en 2011 cuando hice la transici√≥n desde Stata a R. El curso es bastante completo y bien evaluado, los ejercicios son muy pr√°cticos y los profesores muy did√°cticos. Cubren desde los principios hasta programaci√≥n m√°s avanzada en R.\nEl segundo es la introducci√≥n al R hecha por Google. Es un curso m√°s corto y menos completo que el anterior, pero tambi√©n muy bien valorado. Los materiales son creados de modo profesional y muy bien cuidados en sus aspectos est√©ticos y did√°cticos.\n\n\nPracticando con tus datos\nLo m√°s importante para aprender a programar es emplear tus propios datos o resolver problemas reales de an√°lisis de datos con el lenguaje que deseas manipular. La estrategia ideal consiste en combinar\nAlgunos consejos clave para consolidar el proceso de aprendizaje:\n\nTrabaja con un problema y datos reales. Intenta integrar el uso de la herramienta en tu trabajo cotidiano. Esto te permitir√° emplear tu horario laboral para aprender y, al mismo tiempo, resolver problemas reales. De inicio no se trata de hacer todo de golpe en un nuevo lenguaje, pero ir integrando poco a poco el uso de la herramienta en tu trabajo cotidiano.\nElige problemas concretos para empezar. Resulta mucho m√°s f√°cil aprender si restringes el proyecto a un conjunto abarcable de tareas o problemas concretos, como abrir y limpiar los datos o llevar a cabo ciertos an√°lisis b√°sicos. Quiz√°s, al principio, empiezas a abrir y transformar los datos o hacer gr√°ficos con R y, luego, te dedicas a hacer an√°lisis m√°s complejos o integrar otras fases del proceso.\nDefine objetivos claros. Establezca metas de aprendizaje claras y alcanzables. Por ejemplo, abrir datos de Excel, SPSS, Stata y CSV en R. Luego, limpiar los datos y calcular algunos indicadores y as√≠ sucesivamente. Elegir objetivos peque√±os, concretos y que permitan la visualizaci√≥n de resultados r√°pidos es muy buena estrategia para no perder el √°nimo en procesos de aprendizaje complejos como puede ser aprender un lenguaje de programaci√≥n por primera vez.\nTrabaja en equipo. La colaboraci√≥n entre individuos con diferentes niveles y habilidades hace el proceso de aprendizaje m√°s ameno, divertido y, por ende, efectivo. Elige bien el grupo de personas, integra a gente con distintos niveles de conocimiento y experiencia y los resultados pueden ser enormemente sorpreendentes. Los compa√±eros ayudan tanto en la motivaci√≥n como un primer recurso para resolver problemas. Pod√©is incluso establecer mecanismos l√∫dicos para aumentar la colaboraci√≥n o la competencia entre los miembros del grupo. Por ejemplo, ‚Äúel individuo o equipo dentro del grupo que resuelva primero el problema elige el pr√≥ximo reto o no paga la primera ronda de cervezas‚Äù.\nMant√©n el foco en aprender. Por m√°s que emplees la herramienta en tu trabajo cotidiano, no pierdas de vista que el objetivo es aprender. Tampoco te frustres por la p√©rdida inicial de productividad. La peor tentaci√≥n viene cuando uno piensa: ‚ÄúYo lo hago en 10 minutos en SPSS, ¬øpor qu√© tengo que perderme horas intentando hacer lo mismo en R?‚Äù. Es verdad, pero una vez aprendido, la misma tarea la prodr√°s hacer en pocos segundos o ser mucho m√°s efectivo en el proceso de an√°lisis de datos como un todo: de la recolecci√≥n a la publicaci√≥n de los resultados."
  },
  {
    "objectID": "gramatica.html#gr√°ficos-por-capas",
    "href": "gramatica.html#gr√°ficos-por-capas",
    "title": "Gram√°ticade los gr√°ficos",
    "section": "Gr√°ficos por capas",
    "text": "Gr√°ficos por capas\nComo se puede ver en el v√≠deo, la mejor manera de pensar en la gram√°tica de los gr√°ficos es a partir de una estructura de capas superpuestas. La idea es muy sencilla: cada gr√°fico se construye a partir de una serie de capas que se van sumando una a una, de modo que uno puede ir a√±adiendo mayor sofisticaci√≥n y complejidad en la medida que ya tiene resueltos los temas anteriores.\nCada capa de un gr√°fico es un componente independiente que se puede modificar y combinar con otras capas para crear un gr√°fico m√°s complejo. La figura abajo nos brinda una representaci√≥n visual de la gram√°tica de los gr√°ficos:\n\nEn la base se encuentra la capa de datos. Cualquier visualizaci√≥n depende fundamentalmente de la informaci√≥n que se desea comunicar. Esta capa condiciona todo lo que viene despu√©s: las geometr√≠as que podemos emplear, las estad√≠sticas, la capacidad de dividir en diferentes grupos, etc.\nImaginemos nuestra base de datos w con los datos de los pa√≠ses. Queremos crear un diagrama de dispersi√≥n para analizar la relaci√≥n entre la esperanza de vida (lifeex_total) y el nivel de democracia (dem_score14). imaginemos que queremos contrastar esas dos variables con el IDH (hdi) y el nivel del PIB per c√°pita (gdpcap3_08). Nuestro gr√°fico solo se importar√° con esas variables y ninguna m√°s, pues no las emplearemos.\n\n\nCode\n# Carga los datos\nlibrary(poliscidata)\n\n# Crea una base w a partir\n# de la original world\nw &lt;- world\n\n# Visualiza el nombre del pa√≠s,\n# la esperanza de vida y el nivel\n# de democracia\nreactable(w[, c(\"country\", \"lifeex_total\", \"dem_score14\",\"hdi\",\"gdpcap3_08\")])\n\n\n\n\n\n\n\nEsta ser√≠a nuestra capa de datos. Tenemos cinco variables, dos en formato texto (factor) y dos num√©ricas: el nombre del pa√≠s, la esperanza de vida, el nivel de democracia, el IDH y la desigualdad de g√©nero. Para crearla formalmente en R, debemos decir que la base de datos que vamos a emplear es la que se llama w en la funci√≥n ggplot del paquete ggplot2.\n\n\nCode\n# Carga el paquete\nlibrary(ggplot2)\n\n# Crea la capa de datos \ng &lt;- ggplot(w)\n\n\nEste procedimiento crea un nuevo objeto llamado g (g de gr√°fico, pero podr√≠a ser cualquier otro nombre) que contiene solamente la indicaci√≥n de que w es la capa de datos.\nLa siguiente capa es la de est√©tica. En esta capa se definen las variables que se van a visualizar y c√≥mo. Tambi√©n se refieren a ese nivel como el ‚Äúmapeo‚Äù de las variables. En nuestro caso, queremos visualizar la esperanza de vida en el eje x y el nivel de democracia en el eje y. Ya tenemos para un gr√°fico de dispersi√≥n (scatterplot).\nNo obstante, tambi√©n queremos que el tama√±o de cada punto sea proporcional al IDH, siendo que los pa√≠ses con mayor desarrollo humano tendr√°n puntos m√°s grandes y los de menos, m√°s peque√±os. Aprovechamos para definir que el color de los puntos corresponda al valor del nivel del PIB per c√°pita (Bajo, Mediano, Alto).\nPara crear la capa de est√©tica en R, ser√≠a tan sencillo como ‚Äúsumar‚Äù la definici√≥n de la est√©tica a la capa de datos:\n\n\nCode\n# A√±ade una capa de est√©tica\n# para la relaci√≥n entre la esperanza\n# de vida y el nivel de democracia\n# con el IDH establecido como tama√±o \n# y el PIB per c√°pita como color\ng &lt;- g + \n     aes(x=lifeex_total,\n         y=dem_score14,\n         size=hdi,\n         color=gdpcap3_08)\n\n# visualiza el gr√°fico\ng\n\n\n\n\n\n‚Äú¬°Pero no veo nada m√°s que el fondo y los ejes!‚Äù Claro que no. Est√°s en el backstage todav√≠a. Solo dijiste al R que quer√≠as visualizar la esperanza de vida en el eje x, el nivel de democracia en el eje y, el tama√±o de los puntos proporcional al IDH y el color de los puntos proporcional a la desigualdad de g√©nero. Pero no le dijiste c√≥mo quer√≠as visualizarlo. Para ello necesitas definir que tipo de representaci√≥n visual quieres: pueden ser puntos, l√≠neas, barras, florecitas, avioncitos‚Ä¶ ¬øC√≥mo el R va a adivinar lo que Ud.? Eso es lo que viene a continuaci√≥n.\nA√±adiremos una capa de geometr√≠a, representada por la funci√≥n geom_ seguida del tipo de geometr√≠a que queremos. En nuestro caso, queremos puntos, por lo que usaremos la funci√≥n geom_point.\n\n\nCode\n# A√±ade la capa de geometr√≠a\n# que ser√°n los puntos\ng &lt;- g + geom_point()\n\n# Visualiza el gr√°fico\ng\n\n\n\n\n\n\nAhora s√≠, ¬°habemus gr√°fico! Hemos sumado a geometr√≠a de puntos a las capas anteriores de datos y est√©tica. Pero, nos result√≥ un gr√°fico que da miedo (ya lidiaremos con eso m√°s tarde).\nMuchos parar√≠an aqu√≠, pero desperdiciar√≠amos la oportunidad de hacer un gr√°fico m√°s informativo. Todav√≠a podemos a√±adir m√°s capas y cambios a nuestra visualizaci√≥n para que sea m√°s bonita e eficaz.\nImaginemos que nos gustar√≠a separar los pa√≠ses seg√∫n regiones. Para ello, necesitamos una nueva capa: la capa de facetas. En esta capa, se definen las variables que se van a utilizar para separar los datos en diferentes paneles. En nuestro caso, queremos separar los pa√≠ses por regiones.\nPara ello, empleamos la funci√≥n facet_wrap y le decimos que queremos dividir los pa√≠ses por la variable regionun. La capa de facetas se ver√≠a as√≠:\n\n\nCode\n# A√±ade la capa de facetas para\n# dividir el gr√°fico por regiones\ng &lt;- g + facet_wrap(~regionun)\n\n# Visualiza el gr√°fico\ng\n\n\n\n\n\nComo hab√©is visto, he ido a√±adiendo capas al gr√°fico y √©l estaba de lo m√°s contento. Ahora quiero a√±adir alguna estad√≠stica chula que me permita visualizar mejor los resultados, como una elipse que circule los puntos de cada grupo de PIB per c√°pita. Lo hago por medio de una capa de estad√≠stica:\n\n\nCode\n# A√±ado la capa de estad√≠stica\ng &lt;- g + stat_ellipse()\n\n# visualizo el gr√°fico\ng\n\n\n\n\n\nYa tengo muchos decorados. Ahora toca cambiar un poco la representaci√≥n jugando con la capa de coordenadas.\n\n\nCode\n# Cambia las coordenadas\n# a polares\ng &lt;- g + coord_polar()\n\n# Visualiza el gr√°fico\ng\n\n\n\n\n\n¬øDemasiado liado para ti? Para mi tambi√©n. Mi experimento no ha sido muy exitoso. No hay problema, volvemos al tipo de coordenadas anterior:\n\n\nCode\n# Superpone las coordenadas \n# cartesianas a las anteriores\ng &lt;- g + coord_cartesian()\n\n# Visualiza el gr√°fico\ng\n\n\n\n\n\nEsto nos advierte tambi√©n que la estructura de capas no resulta obligatoria. Las √∫nicas capas que son estrictamente necesarias son la de datos, est√©tica y geometr√≠a. Las dem√°s son opcionales y pueden ser a√±adidas o quitadas seg√∫n la necesidad.\nAhora nos toca mejorar la apariencia del gr√°fico. Para ello, a√±adiemos una capa de tema. En esta capa, se definen los elementos que se van a utilizar para mejorar la apariencia del gr√°fico. Necesitamos quitar ese fondo feo, cambiar los colores, a√±adir un t√≠tulo, cambiar el nombre de los ejes, etc. Hagamoslo:\n\n\nCode\n# A√±adimos un tema pre programado\n# para quitar elementos indesejables\ng &lt;- g + theme_classic()\n\n# Cambiamos el color\ng &lt;- g + scale_color_manual(\n                values=c(\"red3\",\n                         \"orange\",\n                         \"blue\"))\n\n# A√±adimos un t√≠tulo y cambiamos\n# los nombres de los ejes\ng &lt;- g + labs(title=\"Relaci√≥n entre esperanza de vida y nivel de democracia\",\n              x=\"Esperanza de vida\",\n              y=\"Nivel de democracia\")\n\n# Cambiamos el t√≠tulo de las\n# leyendas\ng &lt;- g + guides(\n            color = guide_legend(title=\"PIB per c√°pita\"),\n            size = guide_legend(title=\"IDH\")\n            )\n\n# Aumentamos el tama√±o del t√≠tulo\ng &lt;- g + theme(plot.title = \n                 element_text(size=16, \n                              face=\"bold\")) \n\n# Visualizamos el gr√°fico\ng"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "",
    "text": "Esta p√°gina web forma parte del curso ‚ÄúCiencia de datos pol√≠ticos con R‚Äù. En ella, se recogen los materiales y ejemplos que se desarrollar√°n durante las sesiones."
  },
  {
    "objectID": "index.html#el-curso",
    "href": "index.html#el-curso",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "",
    "text": "Esta p√°gina web forma parte del curso ‚ÄúCiencia de datos pol√≠ticos con R‚Äù. En ella, se recogen los materiales y ejemplos que se desarrollar√°n durante las sesiones."
  },
  {
    "objectID": "index.html#el-profesor",
    "href": "index.html#el-profesor",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "El profesor",
    "text": "El profesor\nRodrigo Rodrigues-Silveira \nrodrodr@usal.es\nProfesor de ciencia pol√≠tica de la USAL. Director del proyecto ‚ÄúComportamiento legislativo y erosi√≥n democr√°tica en Am√©rica Latina‚Äù (PELA Comportamiento)."
  },
  {
    "objectID": "index.html#el-contenido",
    "href": "index.html#el-contenido",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "El contenido",
    "text": "El contenido\nDurante el curso se abordar√°n los siguientes temas:\n\nIntroducci√≥n a la la ciencia de datos en R\nManipulaci√≥n y an√°lisis de datos sociales\nCreaci√≥n de gr√°ficos y narrativas visuales\nAn√°lisis de textos y modelos de IA generativa"
  },
  {
    "objectID": "index.html#sesiones",
    "href": "index.html#sesiones",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "Sesiones",
    "text": "Sesiones\nLas sesiones tendr√°n una duraci√≥n de 5 horas y se llevar√°n a cabo en el CIEPS.\nD√çA 1 - 20/01/2025 de 8 a 13h\nD√çA 2 - 21/01/2025 de 8 a 13h\nD√çA 3 - 22/01/2025 de 8 a 13h\nD√çA 4 - 23/01/2025 de 8 a 13h"
  },
  {
    "objectID": "index.html#servicio-t√©cnico",
    "href": "index.html#servicio-t√©cnico",
    "title": "Ciencia de datos pol√≠ticos en R",
    "section": "ü§ñ Servicio t√©cnico ü§ñ",
    "text": "ü§ñ Servicio t√©cnico ü§ñ\nPara que pod√°is reproducir los ejemplos de an√°lisis presentados durante el curso deb√©is instalar en vuestros ordenadores el R y el RStudio Desktop.\nPara los modelos de inteligencia artificial, deben instalar Ollama.\nTambi√©n deb√©is ejecutar el siguiente c√≥digo en R que instala los paquetes necesarios:\n\n\nCode\n# Crea un vector con los paquetes a instalar\npc &lt;- c(\"devtools\",\"ggplot2\",\"ggrepel\",\"ggdist\",\n        \"ggiraph\",\"giraphExtra\",\"ggridges\",\"dplyr\",\n        \"vdemdata\",\"sf\",\"cowplot\",\"poliscidata\",\n        \"treemap\",\"treemapify\",\"plotly\",\"networkD3\",\n        \"gapminder\",\"patchwork\",\"ggcorrplot\",\"rollama\",\n        \"ggnetwork\",\"ggridges\",\"ggbeeswarm\",\"ggtext\",\n        \"netrankr\",\"igraph\",\"reactable\",\"RColorBrewer\",\n        \"hrbrthemes\",\"ggthemes\",\"tvthemes\",\"broom\",\n        \"tidyverse\",\"knittr\",\"kableExtra\",\"rmarkdown\",\n        \"poliscidata\",\"psych\",\"crosstable\",\"corrplot\",\n        \"ggpomological\",\"igraph\",\"netrankr\",\"ggpmisc\",\n        \"forestplot\",\"jtools\",\"stargazer\",\"distributional\",\n        \"tibble\",\"purrr\",\"forcats\",\"stringr\",\"httr\",\n        \"readtext\",\"stringi\",\"pdftools\",\"bibtex\",\n        \"quanteda\",\"quanteda.textstats\",\"quanteda.textplots\",\n        \"quanteda.textmodels\",\"jsonlite\",\"wordcloud\",\n        \"gridExtra\",\"grid\",\"htmltools\",\"wordshoal\")\n\n# Instala los paquetes\ninstall.packages(pc)\n\n# Instala el paquete tenet que no est√° en CRAN\n# (si ya no lo hab√©is instalado en el curso \n# anterior de introducci√≥n al R)\ndevtools::install_github(\"rodrodr/tenet\", force=T)\ndevtools::install_github(\"rstudio/learnr\")\ndevtools::install_github(\"rundel/learnrhash\")\ndevtools::install_github('bbc/bbplot')\ndevtools::install_github(\"vdeminstitute/vdemdata\")\ndevtools::install_github(\"JBGruber/rollama\")\n\n\n# Instala este paquete despu√©s de haber instalado los anteriores\ndevtools::install_github(\"gadenbuie/ggpomological\")"
  },
  {
    "objectID": "interactivo.html",
    "href": "interactivo.html",
    "title": "Interactividaden los gr√°ficos",
    "section": "",
    "text": "Una de las grandes ventajas de la visualizaci√≥n de datos viene de la posibilidad de interactuar con los gr√°ficos. En este sentido, la interactividad permite a los usuarios explorar los datos de manera m√°s profunda, y a menudo, de una manera m√°s intuitiva. En este cap√≠tulo veremos c√≥mo crear gr√°ficos interactivos en R a partir de un conjunto de paquetes especializados."
  },
  {
    "objectID": "interactivo.html#introducci√≥n",
    "href": "interactivo.html#introducci√≥n",
    "title": "Interactividaden los gr√°ficos",
    "section": "",
    "text": "Una de las grandes ventajas de la visualizaci√≥n de datos viene de la posibilidad de interactuar con los gr√°ficos. En este sentido, la interactividad permite a los usuarios explorar los datos de manera m√°s profunda, y a menudo, de una manera m√°s intuitiva. En este cap√≠tulo veremos c√≥mo crear gr√°ficos interactivos en R a partir de un conjunto de paquetes especializados."
  },
  {
    "objectID": "interactivo.html#tipos-de-interacci√≥n",
    "href": "interactivo.html#tipos-de-interacci√≥n",
    "title": "Interactividaden los gr√°ficos",
    "section": "Tipos de interacci√≥n",
    "text": "Tipos de interacci√≥n\nExisten diferentes formas de interacci√≥n en los gr√°ficos interactivos. En este curso exploraremos las siguientes: tooltips, cliques, hover (pasar el cursor sobre un elemento) y zoom. A continuaci√≥n, describiremos cada una de ellas.\n\nTooltips\nLos tooltips son peque√±as ventanas emergentes que aparecen cuando el usuario pasa el rat√≥n sobre un elemento interactivo. En estos tooltips se pueden mostrar datos adicionales que complementan la informaci√≥n que se muestra en el gr√°fico. En R, podemos crear tooltips con solamente definir una variable como contenido o crear versiones m√°s complejas a partir de pocas l√≠neas de c√≥digo html.\nEl c√≥digo abajo muestra c√≥mo crear dos gr√°ficos de dispersi√≥n con tooltips en R. El primero con un tooltip simple y el segundo con uno m√°s complejo. Para hacerlo emplearemos el paquete ggiraph y la geometr√≠a geom_point_interactive, que permite crear gr√°ficos de dispersi√≥n interactivos.\nPrimer gr√°fico: tooltip solo con el nombre del pa√≠s.\n\n\nCode\nlibrary(poliscidata)\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n# Carga los datos\nw &lt;- world\n\n# Genera el gr√°fico\np &lt;- ggplot(w, \n            aes(x=lifeex_total, \n                y=dem_score14))+\n    geom_point_interactive(\n            aes(tooltip=country))\n\n# Visualiza el gr√°fico\n# interactivo\ngirafe(ggobj = p)\n\n\n\n\n\n\nSegundo gr√°fico: tooltip simple con poco c√≥digo html y datos de nuevas variables.\n\n\nCode\n# Versi√≥n A - Saltos de l√≠nea\n\n# Crea una variable en el data.frame\n# con el contenido del tooltip\nw$tooltip_text &lt;- paste0(\"&lt;h5 style='color:red;'&gt;&lt;strong&gt;\", \n                         w$country, \"&lt;/strong&gt;&lt;/h5&gt;\",\n                         \"&lt;strong&gt;Esperanza de vida:&lt;/strong&gt; \",\n                         w$lifeex_total,\n                         \"&lt;br&gt;&lt;strong&gt;Democracia:&lt;/strong&gt; \",\n                         w$dem_score14,\n                         \"&lt;br&gt;&lt;strong&gt;Religi√≥n:&lt;/strong&gt; \",\n                         w$religoin)\n\n# Genera el gr√°fico\np &lt;- ggplot(w, \n            aes(x=lifeex_total, \n                y=dem_score14))+\n    geom_point_interactive(\n            aes(tooltip=tooltip_text))\n\n# Visualiza el gr√°fico\n# interactivo\ngirafe(ggobj = p)\n\n\n\n\n\n\nTercer gr√°fico: tooltip m√°s elaborado con una tabla html.\n\n\nCode\n# Versi√≥n B - tabla\n\n# Crea una variable en el data.frame\n# con el contenido del tooltip\nw$tooltip_text &lt;- paste0(\"&lt;style&gt;.row{border-bottom:1px solid;}&lt;/style&gt;\",\n                        \"&lt;h5 style='color:red;'&gt;&lt;strong&gt;\", \n                         w$country, \n                         \"&lt;/strong&gt;&lt;/h5&gt;\",\n                         \"&lt;table&gt;\",\"\n                         &lt;col width='180px' /&gt;\",\n                         \"&lt;col width='40px' /&gt;\",\n                         \"&lt;tr class='row' style='color:orange;'&gt;\",\n                         \"&lt;td&gt;Esperanza de vida&lt;/td&gt;\",\n                         \"&lt;td&gt;\", round(w$lifeex_total,1),\"&lt;/td&gt;\",\n                         \"&lt;/tr&gt;\",\n                         \"&lt;tr class='row' style='color:yellow;'&gt;\",\n                         \"&lt;td&gt;Democracia&lt;/td&gt;\",\n                         \"&lt;td&gt;\", round(w$dem_score14,1),\"&lt;/td&gt;\",\n                         \"&lt;/tr&gt;\",\n                         \"&lt;tr&gt;\",\n                         \"&lt;td valign='top'&gt;Religi√≥n&lt;/td&gt;\",\n                         \"&lt;td&gt;\", w$religoin,\"&lt;/td&gt;\",\n                         \"&lt;/tr&gt;\",\n                         \"&lt;/table&gt;\")\n\n# Genera el gr√°fico\np &lt;- ggplot(w, \n            aes(x=lifeex_total, \n                y=dem_score14))+\n    geom_point_interactive(\n            aes(tooltip=tooltip_text))\n\n# Visualiza el gr√°fico\n# interactivo\ngirafe(ggobj = p)\n\n\n\n\n\n\n\n\n\nCliques\nLa segunda forma de interacci√≥n que veremos es a trav√©s de cliques. En este caso, el usuario puede hacer clic en un elemento del gr√°fico y ser redirigido a una p√°gina web. En el siguiente ejemplo, al hacer clic en un pa√≠s, se abrir√° una p√°gina de Wikipedia con informaci√≥n sobre el pa√≠s.\nEn este caso, combinamos la instrucci√≥n javascriptde windows.open(), con la direcci√≥n de la p√°gina de Wikipedia del pa√≠s. Para ello, creamos una nueva variable en el data.frame con el c√≥digo javascript direccionando a la p√°gina web. Luego, en la geometr√≠a geom_point_interactive a√±adimos la instrucci√≥n onclick con el nombre de la variable click que contiene el c√≥digo javascript.\n\n\nCode\n# Retira las comillas simples\n# del nombre de los pa√≠ses\nw$country &lt;- gsub(\"'\",\" \",w$country)\n\n# Crea un c√≥digo para abrir la\n# p√°gina de wikipedia del pa√≠s\nw$click &lt;- sprintf(\n              paste0('window.open(\"http://en.wikipedia.org/wiki/', \n                     w$country, \n                     '\")'))\n\n\n# Genera el gr√°fico\np &lt;- ggplot(w, \n            aes(x=lifeex_total, \n                y=dem_score14))+\n    geom_point_interactive(\n            aes(onclick=click,\n                tooltip=country))\n\n# Visualiza el gr√°fico\n# interactivo\ngirafe(ggobj = p)\n\n\n\n\n\n\n\n\nHover\nLa tercera forma de interacci√≥n es a trav√©s del hover, que se activa al pasar el cursor sobre un elemento del gr√°fico. En este caso, se puede mostrar informaci√≥n adicional sobre el elemento sin necesidad de hacer clic. En el c√≥digo abajo, al pasar el cursor sobre un pa√≠s, se cambiar√° el color de los pa√≠ses de un mismo continente y los dem√°s se pondr√°n semitransparentes.\n\n\nCode\nlibrary(poliscidata)\n\nw &lt;- world\n\n# Crea un tooltip con algunos datos\n# del pa√≠s\nw$tooltip_text &lt;- paste0(\"&lt;strong&gt;\", w$country, \"&lt;/strong&gt;&lt;br&gt;\",\n                         \"&lt;strong&gt;Esperanza de vida:&lt;/strong&gt; \",\n                         w$lifeex_total,\n                         \"&lt;br&gt;&lt;strong&gt;Democracia:&lt;/strong&gt; \",\n                         w$dem_score14)\n\n\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n# Capa de datos\np &lt;- ggplot(w)\n\n# A√±ade la capa de est√©tica\np &lt;- p +\n   aes(x = lifeex_total, \n       y = dem_score14,\n       data_id=regionun)\n\n# A√±ade la capa geom√©trica interactiva\np &lt;- p + geom_point_interactive(\n              aes(tooltip = tooltip_text)\n              )\n\n# Visualiza el gr√°fico interactivo\nx &lt;- girafe(ggobj = p, \n            options = \n              list(\n                opts_hover_inv(css = \"opacity:0.1;\")\n              )\n            )\n\nx\n\n\n\n\n\n\n\n\nZoom\nLa cuarta forma de interacci√≥n es a trav√©s del zoom, que permite al usuario acercar o alejar una parte del gr√°fico. En el siguiente ejemplo, se muestra un gr√°fico de dispersi√≥n con la posibilidad de hacer zoom en una regi√≥n espec√≠fica del gr√°fico por medio de un bot√≥n que aparecer√° en la parte superior derecha.\n\n\nCode\nlibrary(poliscidata)\n\nw &lt;- world\n\n# Crea un tooltip con algunos datos\n# del pa√≠s\nw$tooltip_text &lt;- paste0(\"&lt;strong&gt;\", w$country, \"&lt;/strong&gt;&lt;br&gt;\",\n                         \"&lt;strong&gt;Esperanza de vida:&lt;/strong&gt; \",\n                         w$lifeex_total,\n                         \"&lt;br&gt;&lt;strong&gt;Democracia:&lt;/strong&gt; \",\n                         w$dem_score14)\n\n\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n# Capa de datos\np &lt;- ggplot(w)\n\n# A√±ade la capa de est√©tica\np &lt;- p +\n   aes(x = lifeex_total, \n       y = dem_score14,\n       data_id=regionun)\n\n# A√±ade la capa geom√©trica interactiva\np &lt;- p + geom_point_interactive(\n              aes(tooltip = tooltip_text)\n              )\n\n# Visualiza el gr√°fico interactivo\nx &lt;- girafe(ggobj = p, \n            options = \n              list(\n                opts_hover_inv(css = \"opacity:0.1;\"),\n                opts_zoom(min=1, max=3)\n              )\n            )\n\nx"
  },
  {
    "objectID": "interactivo.html#paquetes-de-gr√°ficos-interactivos",
    "href": "interactivo.html#paquetes-de-gr√°ficos-interactivos",
    "title": "Interactividaden los gr√°ficos",
    "section": "Paquetes de gr√°ficos interactivos",
    "text": "Paquetes de gr√°ficos interactivos\nEn esta secci√≥n mencionaremos algunos de los paquetes de gr√°ficos interactivos con los que pod√©is crear diferentes formas de visualizaci√≥n de datos. No se trata de un recuento exhaustivo, sino de una selecci√≥n de paquetes que consideramos √∫tiles y f√°ciles de usar. Tambi√©n menciono el paquete tenet que desarrollo para el an√°lisis de textos en R, pero que contiene una serie de gr√°ficos interactivos.\n\nggiraph\nEl primer paquete que mencionaremos es ggiraph, que permite crear gr√°ficos interactivos con la librer√≠a ggplot2. Este paquete es muy √∫til para crear gr√°ficos con la misma sintaxis de ggplot2. Trabaja con geometr√≠as interactivas, como geom_sf_interactive, geom_point_interactive, geom_bar_interactive, entre otras, que se comportan exactamente como sus contrapartes no interactivas, pero con la posibilidad de a√±adir interactividad.\nPara activar la interactividad, se debe a√±adir la funci√≥n girafe() al final del gr√°fico. En el siguiente ejemplo, se muestra un mapa interactivo hecho con ggiraph. Ah√≠ queda evidente la sintaxe de ggplot2 y la facilidad de a√±adir interactividad a un gr√°fico.\n\n\nCode\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(ggiraph)\n\n# Lee los datos de Carolina del Norte\nnc &lt;- sf::st_read(system.file(\"shape/nc.shp\", \n                              package = \"sf\"), \n                  quiet = TRUE)\n\n# Crea un gr√°fico interactivo, con tooltip,\n# hover y click\ngg &lt;- ggplot(nc) +\n  geom_sf_interactive(aes(fill = AREA, \n                          tooltip = NAME, \n                          data_id = NAME,\n                          onclick =  sprintf(\"window.open(\\\"http://en.wikipedia.org/wiki/%s_County,_North_Carolina\\\")\", NAME)))+\n  theme_map()+\n  theme(legend.position = \"none\")+\n  scale_fill_continuous_tableau(palette=\"Purple\")\n  \n# Genera la versi√≥n interactiva  \nx &lt;- girafe(ggobj = gg, \n            options = \n              list(\n                opts_hover(css = ''), \n                opts_hover_inv(css = \"opacity:0.1;\")\n    )\n  )\n\n# Visualiza el gr√°fico\nx\n\n\n\n\n\n\n\n\nplotly\nEl paquete plotly es otro paquete muy √∫til para crear gr√°ficos interactivos en R. Como ggiraph, Este paquete permite crear gr√°ficos interactivos con la misma sintaxis de ggplot2, pero con la posibilidad de a√±adir interactividad. Adem√°s, plotly permite crear gr√°ficos 3D, mapas, gr√°ficos de barras, gr√°ficos de dispersi√≥n, entre otros.\nAbajo vemos un ejemplo de un gr√°fico de dispersi√≥n interactivo hecho con plotly. En este caso, se a√±ade un tooltip con informaci√≥n de cada punto y se a√±ade un efecto de zoom para acercar o alejar una parte del gr√°fico.\n\n\nCode\nlibrary(plotly)\nlibrary(ggplot2)\n\n# Capa de datos\np &lt;- ggplot(w)\n\n# A√±ade la capa de est√©tica\np &lt;- p +\n   aes(x = lifeex_total, \n       y = dem_score14,\n       fill=regionun)\n\n# A√±ade la capa geom√©trica\np &lt;- p + geom_point(color=\"transparent\")\n\nggplotly(p)\n\n\n\n\n\n\n\n\nVisNetwork\nSe trata de una librer√≠a de gr√°ficos de redes interactivos. Permite crear gr√°ficos de redes con nodos y enlaces, y a√±adir interactividad a trav√©s de zoom, arrastrar y soltar, y otros efectos. Permite mucho control de la interactividad y es muy √∫til para visualizar redes complejas.\n\n\nNetworkD3\nEl paquete networkD3 es otra librer√≠a de gr√°ficos de redes interactivos. Basada en D3.js, permite crear gr√°ficos de redes con nodos y enlaces, y a√±adir interactividad a trav√©s de zoom, arrastrar y soltar, y otros efectos. Permite mucho control de la interactividad y es muy √∫til para visualizar redes complejas.\n\n\nleaflet\nEl paquete leaflet es una librer√≠a de mapas interactivos. Permite crear mapas con diferentes capas, a√±adir marcadores, pol√≠gonos, l√≠neas, y a√±adir interactividad a trav√©s de zoom, arrastrar y soltar, y otros efectos. Es muy √∫til para visualizar datos geoespaciales.\n\n\ntmap\nLa librer√≠a tmap es otra librer√≠a de mapas interactivos. Consiste en una alternativa eficiente a leaflet para la visualizaci√≥n de datos geoespaciales.\n\n\ntenet\nEl paquete tenet es un paquete que he desarrollado para el an√°lisis de textos en R. Contiene una serie de gr√°ficos interactivos que permiten explorar los textos de una manera m√°s profunda. A continuaci√≥n, se muestran algunos ejemplos de gr√°ficos.\nforceDirecterTree\nEste gr√°fico muestra un √°rbol de palabras clave con un dise√±o de fuerza directa. Es √∫til para visualizar la relaci√≥n entre las palabras clave y su frecuencia en un texto.\n\n\nCode\n# Carga los paquetes\nlibrary(tenet)\nlibrary(quanteda)\n\n# Crea un objeto corpus con\n# los discursos de investidura\n# de los presidentes espa√±oles\ncp &lt;- corpus(spa.inaugural)\n    \n# Carga el diccionario de palabras\ndic &lt;- dic.pol.es\n\n# Cuenta la frecuencia\nxx &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = F, \n                    group.var = \"President\",\n                    quiet=T)\n\n# Agrega los resultados    \nxx &lt;- aggregate(list(frequency=xx$frequency), \n                by=list(groups=xx$groups, \n                        level1=xx$level1,\n                        level2=xx$level2), \n                sum, na.rm=T)\n\n# Crea el gr√°fico\nforceDirectedTree(data = xx, \n                  height = 500, \n                  max.radius = 40,\n                  value_col = \"frequency\")\n\n\n\n\n\n\nplotVoronoiTree\nComo el gr√°fico anterior, este gr√°fico muestra un √°rbol de palabras clave, pero con un dise√±o de Voronoi. Se trata de una forma de treemap, pero con un dise√±o distinto.\n\n\nCode\n# Con los mismos datos, genera\n# un diagrama de √°rbol de voronoi\nplotVoronoiTree(xx, \n                value_col = \"frequency\")\n\n\n\n\n\n\nplotGrid\nLa funci√≥n plotGrid permite crear una cuadr√≠cula de gr√°ficos interactivos. En el siguiente ejemplo, se muestra c√≥mo crear una cuadr√≠cula de gr√°ficos de dispersi√≥n interactivos con plotGrid.\n\n\nCode\n# Carga los paquetes\nlibrary(tenet)\nlibrary(quanteda)\n\n# Crea un corpus con los \n# discursos de investidura\n# de los presidentes espa√±oles\ncp &lt;- corpus(spa.inaugural)\n\n# Cuenta las palabras clave\n# del diccionario dic.pol.es \n# que he preparado como ejemplo\nxz &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = T, \n                    group.var = \"President\",\n                    quietly = TRUE)\n\n# Agrega las frecuencias por grupo\n# del diccionario\nxx &lt;- aggregate(list(frequency=xz$frequency), \n                by=list(groups=xz$groups,\n                        level1=xz$level1,\n                        level2=xz$level2), \n                sum, na.rm=T)\n\n# Elimina los valores no\n# encontrados\nxx &lt;- xx[xx$frequency&gt;0,]\n\n# Ordena los valores por \n# level1 y level2\nxx &lt;- xx[order(xx$level1, \n               xx$level2),]\n\nxx$level2 &lt;- factor(xx$level2, \n                    levels=unique(xx$level2))\n\n\n# Crea el gr√°fico (estandarizado)\nplotGrid(xx, \n         x=\"groups\", \n         y=\"level2\", \n         size=\"frequency\",\n         palette=pal$cat.cartocolor.bold.11,\n         color=\"level1\", \n         standardize = TRUE,\n         interactive=TRUE,\n         height_svg = 9,\n         width_svg = 8,\n         leg.size = \"Media (%)\",\n         leg.color = \"Categor√≠a\"\n         )\n\n\n\n\n\n\nplotChord\nLa funci√≥n plotChord permite crear un gr√°fico de cuerdas interactivos. En el siguiente ejemplo, se muestra c√≥mo crear un gr√°fico de cuerdas con plotChord.\n\n\nCode\n# Crea un corpus con los\n# discursos de investidura\ncp &lt;- quanteda::corpus(spa.inaugural)\n\n# Carga el diccionario\ndic &lt;- dic.pol.es\n\n# Genera los datos de las \n# coincidencias entre los t√©rminos\n# del diccionario en el corpus\nd &lt;- matchCodes(cp, dic, quietly = T)\n\n# Crea el gr√°fico de cordas\nplotChord(d, \n          from=\"term1\", \n          to=\"term2\", \n          value=\"value\")\n\n\n\n\n\n\nplotKeyness\nLa funci√≥n plotKeyness permite crear un gr√°fico de keyness interactivos. Se trata de entender cu√°les son las palabras m√°s destacadas de un texto de referencia con relaci√≥n a un corpus de otros textos.\n\n\nCode\n# Selecciona solo la\n# sesi√≥n 124 del corpus\n# de debates legislativos de\n# la XIV legislatura\n# \"Ley del S√≠ es S√≠\"\nspa &lt;- spa.sessions[spa.sessions$session.number==124,]\n\n# Agrega los debates por partido\nre &lt;- aggregate(list(text=spa$speech.text), \n                by=list(rep.party=spa$rep.party),\n                FUN=paste, \n                collapse=\"\\n\")\n\n# Crea un corpus con los resultados\ncp &lt;- corpus(re)\n\n# Agrupa por partido\nci &lt;- corpus_group(cp, groups = rep.party)\n\n# Visualiza el gr√°fico\nplotKeyness(corpus = ci,\n            ref.cat = \"Vox\", \n            title = \"\")\n\n\n\n\n\n\nplotSpike\nLa funci√≥n plotSpike permite crear un gr√°fico de dispersi√≥n l√©xica interactivo.\n\n\nCode\n# Agrega los debates por sesi√≥n\nag &lt;- aggregate(list(text=spa.sessions$speech.text),\n                by=list(session_number=spa.sessions$session.number),\n                paste, \n                collapse=\"\\n\")\n\n# A√±ade ceros para ordenar de modo correcto\n# las sesiones por n√∫meros\nag$session_number[nchar(ag$session_number)==1] &lt;- \npaste0(\"00\", ag$session_number[nchar(ag$session_number)==1])\n\nag$session_number[nchar(ag$session_number)==2] &lt;- \npaste0(\"0\", ag$session_number[nchar(ag$session_number)==2])\n\n# Convierte los resultados en un corpus\nlibrary(quanteda)\ncp &lt;- corpus(ag, \n             docid_field = \"session_number\")\n\n\n# Crea un diccionario con los temas\n# territorio, g√©nero y memoria\ndic &lt;- dictionary(\n  list(Territorio=c(\"federal\",\"estatuto\",\"nacionalismo\",\n                    \"regionalismo\",\"catalu√±a\",\"lengua\"),\n       G√©nero=c(\"violencia machista\",\"mujer\",\"violencia sexual\",\n                \"aborto\",\"reproductivo\",\"g√©nero\",\"\\\\btrans\\\\b\"),\n       Memoria=c(\"memoria\",\"franquismo\",\"franquista\",\"dictadura\")))\n\n\n# Busca la posici√≥n de cada palabra\n# en las sesiones\nter &lt;- filterWords(cp, dic)\n\n# Define los nombres de las sesiones.\nter$name &lt;- paste0(\"Session \", ter$name)\n\n# Crea el gr√°fico\nplotSpike(data=ter, \n          legend.title=\"Tema:\",\n          title=\"Congreso de los Diputados - XIV Legislatura (2019-2023)\",\n          subtitle=\"Territorio, g√©nero y memoria en los debates de los plenos.\")\n\n\n\n\n\n\nplotSankey\nLa funci√≥n plotSankey permite crear un gr√°fico interactivo de Sankey o de aluvi√≥n. Resulta excelente para acompa√±ar flujos o transiciones.\n\n\nCode\n# Crea un corpus con los\n# discursos de investidura\ncp &lt;- corpus(spa.inaugural)\n\n# Carga el diccionario\ndic &lt;- dic.pol.es\n\n# Cuenta las palabras clave\nxx &lt;- countKeywords(cp, \n                    dic.pol.es, \n                    rel.freq = F, \n                    group.var = \"President\",\n                    quiet=T)\n\n# Agrega las frecuencias por grupo\nxx &lt;- aggregate(list(frequency=xx$frequency), \n                by=list(groups=xx$groups, \n                        level1=xx$level1,\n                        level2=xx$level2), \n                sum, na.rm=T)\n          \n# Crea el gr√°fico\nplotSankey(data=xx,\n           from=\"groups\",\n           to=\"level1\",\n           value=\"frequency\")\n\n\n\n\n\n\nplotStream\nLa funci√≥n plotStream permite crear un gr√°fico de flujo interactivo. Es ideal para visualizar la evoluci√≥n de las palabras clave en un corpus a lo largo del tiempo.\n\n\nCode\n# Selecciona los diputaos m√°s  \n# representativos de Vox\nag &lt;- spa.sessions[\n        spa.sessions$rep.name%in%\n          c(\"Abascal Conde, Santiago\",\n            \"Espinosa de los Monteros de Sim√≥n, Iv√°n\",\n            \"Olona Chocl√°n, Macarena\",                \n            \"Ortega Smith-Molina, Francisco Javier\"),]\n\n# Crea una variable de mes para \n# facilitar la visualizaci√≥n de los datos\nag$month &lt;- substr(ag$session.date,3,7)\n\n# Agrega las palabras por diputado\n# y mes\nag &lt;- aggregate(\n    list(words=ag$speech.tokens), \n      by=list(\n        month=ag$month, \n        rep=ag$rep.name, \n        party=ag$rep.party), \n      sum, \n      na.rm=T)\n\n# Ordena los datos por mes\nag &lt;- ag[order(ag$month),]\n\n# Crea el gr√°fico\nplotStream(ag, \n           x=\"month\", \n           y=\"words\", \n           group = \"rep\")"
  },
  {
    "objectID": "personalizacion.html",
    "href": "personalizacion.html",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "",
    "text": "En esta parte del curso, aprenderemos a personalizar los gr√°ficos y hacerlos m√°s atractivos. Como en las partes anteriores, utilizaremos la gram√°tica de los gr√°ficos incorporada en la librer√≠a ggplot2 para hacerlo. El prop√≥sito consiste en cambiar diversos elementos relacionados al aspecto y la presentaci√≥n de los gr√°ficos que facilita su interpretaci√≥n y que ayudan mucho en la comunicaci√≥n de los resultados."
  },
  {
    "objectID": "personalizacion.html#introducci√≥n",
    "href": "personalizacion.html#introducci√≥n",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "",
    "text": "En esta parte del curso, aprenderemos a personalizar los gr√°ficos y hacerlos m√°s atractivos. Como en las partes anteriores, utilizaremos la gram√°tica de los gr√°ficos incorporada en la librer√≠a ggplot2 para hacerlo. El prop√≥sito consiste en cambiar diversos elementos relacionados al aspecto y la presentaci√≥n de los gr√°ficos que facilita su interpretaci√≥n y que ayudan mucho en la comunicaci√≥n de los resultados."
  },
  {
    "objectID": "personalizacion.html#personalizaci√≥n-de-los-gr√°ficos",
    "href": "personalizacion.html#personalizaci√≥n-de-los-gr√°ficos",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "Personalizaci√≥n de los gr√°ficos",
    "text": "Personalizaci√≥n de los gr√°ficos"
  },
  {
    "objectID": "personalizacion.html#las-variables-b√°sicas-color-forma-y-tama√±o",
    "href": "personalizacion.html#las-variables-b√°sicas-color-forma-y-tama√±o",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "Las variables b√°sicas: color, forma y tama√±o",
    "text": "Las variables b√°sicas: color, forma y tama√±o\n\nColor\nEl elemento m√°s evidente en la personalizaci√≥n de los gr√°ficos es el color. En ggplot2, los colores se pueden modificar de diversas maneras. Por ejemplo, se pueden cambiar los colores de las l√≠neas, los puntos, las barras, los textos, los fondos, entre otros.\nAdem√°s, los colores no van solos, sino que se combinan en paletas o escalas de colores. Las paletas de colores son conjuntos de colores que se combinan de manera armoniosa y que se utilizan para representar diferentes categor√≠as o variables en un gr√°fico. Existen tres tipos fundamentales de escala de colores:\n\nsequencial - se utilizan para representar variables num√©ricas cont√≠nuas que van de un valor bajo a un valor alto. Por ejemplo, la poblaci√≥n, el porcentaje de voto o el PIB per c√°pita.\n\n\n\n\n\n\nLa figura arriba muestra las paletas de colores secuenciales disponibles en el paquete RColorBrewer que incorpora las escalas desarrolladas por Cynthia Brewer y que se pueden explorar en ColorBrewer. Como podemos ver, los colores van de los tonos m√°s claros a los m√°s oscuros. En general, los colores m√°s claros representan valores bajos y los colores m√°s oscuros representan valores altos.\n\ndivergente - se utilizan para representar variables num√©ricas que tienen un punto medio o un valor de referencia. Por ejemplo, la diferencia entre dos valores, la temperatura, el cambio porcentual o la correlaci√≥n.\n\n\n\n\n\n\nAhora, el punto medio de la escala tiene su centro en un color neutro -como el blanco, el gris o el amarillo- y dos escalas contrarias que marcan posiciones antag√≥nicas. Los colores de cada una de ellas se hace m√°s intensos a medida que se alejan del centro.\n\ncualitativo - se utilizan para representar variables categ√≥ricas o nominales. Por ejemplo, los pa√≠ses, los partidos pol√≠ticos, los tipos de productos o los colores.\n\n\n\n\n\n\nTales escalas permiten representar valores que no poseen un orden o una jerarqu√≠a. Por lo tanto, los colores se utilizan para diferenciar las categor√≠as y no para representar valores num√©ricos. De ese modo, no hay un patr√≥n jer√°rquico ascendiente, descendiente o centr√≠fugo. El objetivo consiste en diferenciar al m√°ximo las categor√≠as entre s√≠, sin establecer una relaci√≥n de jerarqu√≠a entre ellas.\nDe ese modo, debemos emplear diferentes escalas de color de acuerdo con el tipo de informaci√≥n que disponemos. Por ejemplo, si queremos representar la evoluci√≥n de una variable a lo largo del tiempo, es mejor utilizar una escala de color secuencial. Si queremos representar la diferencia entre dos valores, es mejor utilizar una escala de color divergente. Si queremos representar diferentes categor√≠as, es mejor utilizar una escala de color cualitativa.\nAdem√°s, en un gr√°fico de ggplot2 hay dos elementos que se somente a la manipulaci√≥n del color: el fill y el color. El fill se utiliza para rellenar √°reas -de las barras, l√≠neas, puntos, pol√≠gonos, entre otros-. El color, por otra parte, se utiliza para cambiar el color de los bordes.\nLas funciones relacionadas a las escalas de color, por lo tanto, respetan eso dos ejes: el tipo de escala (secuencial, divergente o cualitativa) y si se trata de color (color) o relleno (fill).\nEl gr√°fico de cajas (boxplot) abajo es el mismo de la secci√≥n anterior. No obstante, ahora a√±adimos un elemento m√°s al gr√°fico: la escala de color scale_color_brewer y seleccionamos la paleta cualitativa llamada Dark2. Aprovechamos tambi√©n para cambiar el t√≠tulo de la leyenda para ‚ÄúRegi√≥n‚Äù (name=‚ÄúRegi√≥n‚Äù). Vemos que los colores de relleno de las cajas cambian para corresponder a la nueva escala de color.\nEl gr√°fico original:\n\n\nCode\n# carga los datos y\n# el paquete ggplot2\nlibrary(poliscidata)\nlibrary(ggplot2)\n\n# Datos sobre los estados\n# de EE. UU.\nd &lt;- states \n\n# Crea el gr√°fico de cajas (boxplot)\np &lt;- ggplot(data = d,\n            mapping = aes(x=unemploy, \n                          y=region,\n                          color=region,\n                          group=region)) + \n        geom_boxplot(width=0.1)\n\np\n\n\n\n\n\n\nEl gr√°fico con la nueva escala:\n\n\nCode\np &lt;- p + scale_color_brewer(name=\"Regi√≥n\",\n                           palette=\"Dark2\")\n\np\n\n\n\n\n\n\nAhora, emplearemos el atributo fill para cambiar el color de relleno. Para ello, en lugar de emplear color en la capa de est√©tica, cambiaremos para fill y a scale_fill_brewer. Veamos la diferencia en un nuevo gr√°fico:\n\n\nCode\n# carga los datos y\n# el paquete ggplot2\nlibrary(poliscidata)\nlibrary(ggplot2)\n\n# Datos sobre los estados\n# de EE. UU.\nd &lt;- states \n\n# Crea el gr√°fico de cajas (boxplot)\np &lt;- ggplot(data = d,\n            mapping = aes(x=unemploy, \n                          y=region,\n                          fill=region,\n                          group=region)) + \n        geom_boxplot(width=0.1)\n\np\n\n\n\n\n\nCode\np &lt;- p + scale_color_brewer(name=\"Regi√≥n\", \n                            palette=\"Dark2\")\n\np\n\n\n\n\n\nY si quiero elegir los colores, ¬øqu√© hago? Sencillo, debes elegir la escala de color o relleno manual:\n\n\nCode\np &lt;- p + scale_fill_manual(values=c(\"red3\",\n                                     \"steelblue\",\n                                     \"darkgreen\",\n                                     \"purple\"))\n\np\n\n\n\n\n\n\n\nFormas y s√≠mbolos\nOtro elemento visual que podemos adaptar a nuestros intereses son las formas o los s√≠mbolos. Por ejemplo, en algunas publicaciones, piden a los autores que generen gr√°ficos en blanco y negro o escala de grises. En esos casos, toca emplear otros recursos visuales. En un diagrama de dispersi√≥n podemos querer emplear distintos tipos de s√≠mbolo (c√≠rculos, cuadrados, tri√°ngulos o rombos, por ejemplo) para diferencias entre categor√≠as.\nPara ello, empleamos el par√°metro shape en la capa est√©tica para definir que a una variable determinada corresponder√° un s√≠mbolo √∫nico. Reutilizaremos el c√≥digo para el gr√°fico de dispersi√≥n de la secci√≥n anterior para establecer el continente (regionun) como variable que determinar√° la forma de los puntos en el gr√°fico:\n\n\nCode\nlibrary(poliscidata)\n\n# Empleamos los datos de paises\n# y excluimos los casos en los\n# que no hay informaci√≥n sobre\n# la religi√≥n\nw &lt;- world\nw &lt;- w[! is.na(w$religoin),]\n\nlibrary(ggplot2)\n\n# Crea el gr√°fico\np &lt;- ggplot(w)\n\n# Capa est√©tica con la religi√≥n\n# como color\np &lt;- p + aes(x=hdi, \n            y=dem_score14,\n            shape=regionun)\n\n# Capa geom√©trica\np &lt;- p + geom_point()\n\n# Visualiza el gr√°fico\np\n\n\n\n\n\n\n\nTama√±o\nFinalmente, el tama√±o representa la tercera variable visual que nos ocuparemos aqu√≠. El par√°metro sizepermite escalonar las observaciones del gr√°fico para que se destaquen en funci√≥n de una variable num√©rica. En el siguiente gr√°fico de dispersi√≥n, empleamos el tama√±o de los puntos para representar la poblaci√≥n total de los pa√≠ses.\n\n\nCode\nlibrary(ggplot2)\n\n# Crea el gr√°fico\np &lt;- ggplot(w)\n\n# Capa est√©tica con la religi√≥n\n# como color\np &lt;- p + aes(x=hdi, \n            y=dem_score14,\n            size=pop_total)\n\n# Capa geom√©trica\np &lt;- p + geom_point()\n\n# Visualiza el gr√°fico\np"
  },
  {
    "objectID": "personalizacion.html#texto",
    "href": "personalizacion.html#texto",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "Texto",
    "text": "Texto\nLa gran mayor√≠a de los gr√°ficos incluye un conjunto de elementos de texto: t√≠tulos, ejes, etiquetas, leyendas, entre otros. Una buena elecci√≥n de t√≠tulo, su tama√±o y posici√≥n, por ejemplo, puede hacer que el gr√°fico sea m√°s f√°cil de entender. En gr√°ficos cient√≠ficos, resulta obligatorio a√±adir informaci√≥n las fuentes de los datos. El tipo de fuente tambi√©n puede ser manipulado para mejorar la legibilidad del gr√°fico o para atraer la atenci√≥n. Por esa raz√≥n, en este apartado veremos c√≥mo manipular los elementos textuales de los gr√°ficos. Nos concentraremos en tres elementos concretos: las fuentes o tipograf√≠as, los t√≠tulos y las etiquetas.\n\nFuentes\nLas fuentes tipogr√°ficas pueden personalizar un gr√°fico y ayudar a convertirlo en algo m√°s atractivo. En ggplot2, la funci√≥n theme permite manipular los elementos textuales de un gr√°fico. Para cambiar la fuente de un gr√°fico, empleamos el atributo family en la funci√≥n element_text. No obstante, muchas geometr√≠as de ggplot2 tienen un atributo family que permite cambiar la fuente de un elemento espec√≠fico.\nA continuaci√≥n, mostramos c√≥mo cambiar la fuente de un gr√°fico de dispersi√≥n con dos fuentes descargadas de Google Fonts: Griffy y Mr Bedfort. Para ello, empleamos la funci√≥n theme y element_text para cambiar la fuente de los elementos textuales del gr√°fico:\n\n\nCode\np + theme(text=element_text(family=\"Griffy\",\n                            size=20,\n                            face=\"bold\"))\n\n\n\n\n\nCode\np + theme(text=element_text(family=\"Mr Bedfort\", \n                            size=16))\n\n\n\n\n\n\n\nT√≠tulos\n¬øQu√© hacemos con un gr√°fico sin t√≠tulos? Pues, no sabr√≠amos qu√© estamos viendo. Los t√≠tulos son esenciales para la interpretaci√≥n de los gr√°ficos. Los ejes tambi√©n deben estar bien etiquetados para que el lector pueda entender qu√© est√° viendo.\nEn ggplot2, los t√≠tulos se pueden a√±adir a trav√©s de la funci√≥n labs. Esta funci√≥n permite a√±adir t√≠tulos a los ejes, la leyenda y el gr√°fico en general. A continuaci√≥n, mostramos c√≥mo a√±adir un t√≠tulo al gr√°fico de dispersi√≥n de la secci√≥n anterior:\n\n\nCode\np &lt;- p + labs(title=\"√çndice de Desarrollo Humano vs. Democracia\",\n               subtitle= \"Pa√≠ses del mundo\",\n               x=\"√çndice de Desarrollo Humano\",\n               y=\"Democracia\",\n               caption=\"Fuente: paquete poliscidata.\",\n               size=\"Poblaci√≥n\")\n\np\n\n\n\n\n\nUna curiosidad. Si os hab√©is fijado bien, hemos a√±adido un par√°metro size=‚ÄúPoblaci√≥n‚Äù a los textos. Este par√°metro permite a√±adir un t√≠tulo a la leyenda de tama√±o del gr√°fico. Si hubi√©ramos a√±adido una variable de color, podr√≠amos a√±adir el t√≠tulo de la leyenda de color con el par√°metro color=‚ÄúReligi√≥n‚Äù. Hag√°moslo:\n\n\nCode\n# A√±ade la religi√≥n como color en\n# la capa de est√©tica\np &lt;- p + aes(color=religoin)\n\n# A√±ade el t√≠tulo de la leyenda de color\np &lt;- p + labs(color=\"Religi√≥n\")\n\n# Muestra el gr√°fico\np\n\n\n\n\n\nComo pod√©is ver, lo que hab√≠a hecho antes se qued√≥ y he ido a√±adiendo cosas. Esa es una de las principales ventajas de ggplot2: la capacidad de a√±adir elementos a un gr√°fico de forma sencilla y r√°pida.\n\n\nEtiquetas de valores\nEn algunos casos, es necesario a√±adir etiquetas a los valores de un gr√°fico. Por ejemplo, en un gr√°fico de dispersi√≥n, puede ser √∫til a√±adir el nombre de los pa√≠ses a los puntos. Para ello, empleamos la funci√≥n geom_text o geom_text_repel del paquete ggrepel. La funci√≥n geom_text a√±ade etiquetas a los puntos del gr√°fico, mientras que geom_text_repel a√±ade etiquetas que no se solapan entre s√≠. A continuaci√≥n, mostramos c√≥mo a√±adir etiquetas a los puntos del gr√°fico de dispersi√≥n de la secci√≥n anterior:\n\n\nCode\np &lt;- ggplot(d, aes(x=abort_rate08, \n                   y=obama08))+\n        geom_point()\n\n\np + geom_text(aes(label=stateid), \n              hjust=0, \n              vjust=0)\n\n\n\n\n\nEl pr√≥ximo gr√°fico muestra c√≥mo utilizar la funci√≥n geom_text_repel para a√±adir etiquetas a los puntos del gr√°fico de dispersi√≥n. En este caso, las etiquetas no se solapan entre s√≠:\n\n\nCode\n# Carga el paquete\nlibrary(ggrepel)\n\n# A√±ade las etiquetas\np + geom_text_repel(\n        aes(label=stateid), \n            hjust=0, \n            vjust=0,\n            check_overlap = TRUE)"
  },
  {
    "objectID": "personalizacion.html#temas",
    "href": "personalizacion.html#temas",
    "title": "AparienciaPersonalizaci√≥n y temas",
    "section": "Temas",
    "text": "Temas\nLos temas son una forma de personalizar la apariencia de un gr√°fico. Tienen una enorme utilidad, porque permiten cambiar la apariencia de un gr√°fico de forma r√°pida y sencilla y, adem√°s, garantizar un estilo √∫nico para los gr√°ficos de un proyecto. Por ejemplo, si estoy escribiendo la tesis doctoral y quiero garantizar que todos mis gr√°ficos tengan la misma apariencia, puedo crear un tema personalizado y aplicarlo a todos los gr√°ficos. Este trabajo ser√≠a mucho m√°s laborioso sin el uso de los temas.\nEn ggplot2, los temas permiten cambiar la apariencia de los elementos del gr√°fico, como el fondo, los ejes, las etiquetas, entre otros. La funci√≥n theme permite cambiar el tema de un gr√°fico. Existe una cantidad enorme de temas predefinidos en ggplot2 o en paquetes adicionales como ggthemes o tvthemes, pero tambi√©n es posible crear un tema personalizado.\n\nTemas predefinidos\nEn paquete ggplot2 posee una serie de temas predefinidos que permiten cambiar la apariencia de un gr√°fico. Son conjunto de instrucciones que definen la apariencia de los elementos de un gr√°fico, como la fuente, los colores, el fondo, los ejes, entre otros.El c√≥digo abajo muestra c√≥mo cambiar el tema de un gr√°fico de dispersi√≥n a un tema predefinido de ggplot2:\n\n\nCode\np &lt;- ggplot(d, aes(x=abort_rate08, \n                   y=obama08))+\n        geom_point()+\n        labs(title=\"Aborto y voto en Obama\",\n             subtitle=\"Tasa de aborto y voto en Obama en los estados de EE. UU. en 2008.\",\n             x=\"Tasa de aborto\",\n             y=\"Votos para Obama\",\n             caption=\"Fuente: paquete poliscidata.\")\n\np &lt;- p + theme_classic()\n\np + geom_text_repel(\n        aes(label=stateid), \n            hjust=0, \n            vjust=0,\n            check_overlap = TRUE)\n\n\n\n\n\nSi comparamos con la versi√≥n anterior del mismo gr√°fico, vemos que hay una mejor√≠a significativa en la presentaci√≥n. El tema theme_classic es uno de los temas predefinidos de ggplot2. Otros temas predefinidos son theme_minimal, theme_light, theme_dark, theme_bw, entre otros. No hay colores y muy pocos elementos decorativos, algo que convierte el gr√°fico en particularmente atractivo para visualizar los patrones.\nPodemos utilizar el tema de los Simpsons del paquete tvthemes para cambiar la apariencia de un gr√°fico.\n\n\nCode\nlibrary(tvthemes)\n\np + theme_simpsons()\n\n\n\n\n\n\n\nPersonalizaci√≥n de los temas\nSi los temas predefinidos no son suficientes, es posible personalizar un tema detalle por detalle. Para ello, se utiliza la funci√≥n theme y se a√±aden los elementos que se desean personalizar. Tomemos como ejemplo el ridge plot que creamos anteriormente.\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Crea el gr√°fico\n# con la relaci√≥n entre \n# fraccionamiento √©tnico y religi√≥n\np &lt;- ggplot(w,\n            aes(x=frac_eth, \n                y=religoin, \n                fill=religoin))\n\n# A√±ade la capa de geometr√≠a\np &lt;- p + geom_density_ridges()\n\n# Visualiza los resultados\np\n\n\n\n\n\nCambiemos una serie de elementos para hacerlo m√°s atractivo:\n\n\nCode\n# A√±adimos un t√≠tulo y los nombres de los ejes\np &lt;- p + labs(title=\"**Fraccionamiento √©tnico y religi√≥n**\",\n              x=\"Fraccionamiento √©tnico\",\n              y=\"\",\n              caption=\"Fuente: paquete poliscidata.\",\n              fill=\"Religi√≥n\")\n\n# Cargamos el paquete ggtext\n# que permite personalizar la \n# apariencia de los textos\nlibrary(ggtext)\n\n# Personalizamos la aparencia\np &lt;- p + theme(text=element_text(family=\"Kranky\"), # Fuente\n        legend.position = \"bottom\", # Leyenda abajo\n        plot.title = element_markdown(size=20), # T√≠tulo en markdown\n        panel.background = element_rect(fill=\"white\")\n)\n\n# Cambiamos la escala de color\n# para la de juego de tronos\n# del paquete tvthemes\np + scale_fill_westeros()"
  },
  {
    "objectID": "recursos.html",
    "href": "recursos.html",
    "title": "Recursos √∫tiles para la visualizaci√≥n de datos",
    "section": "",
    "text": "Existen muchos proyectos que nos ayudan a crear visualizaciones de datos hermosas y efectivas. Algunos de ellos son recursos extremadamente √∫tiles y repositorios de c√≥digo disponibles para nosotros.\n\n\nLa p√°gina web Dataviz inspiration provee hermosos gr√°ficos e historias de datos. Estos ejemplos curados nos ayudan a visualizar el potencial completo de la visualizaci√≥n de datos y a obtener algunas ideas que podemos usar para nuestros propios an√°lisis. Uno de los ejemplos sobresalientes es Ailing Brussels, un an√°lisis de la desigualdad en Bruselas por la revista belga de investigaci√≥n Med√≥r. El proyecto emplea mapas, gr√°ficos, animaci√≥n y una narrativa convincente a trav√©s de im√°genes, textos y videos para describir la divisi√≥n espacial de Bruselas en cuanto a oportunidades y niveles de precariedad.\n\n\n\n\n\nVisite ambos sitios, Dataviz Inspirations y Ailing Brussels, para tener una maravillosa experiencia de las posibilidades de la visualizaci√≥n de datos.\n\n\n\nEl segundo recurso es el Proyecto Data to Viz. Es el resultado de un gran esfuerzo de sistematizaci√≥n. Yan Holtz, el creador, organiz√≥ gr√°ficos seg√∫n el tipo de datos o el tipo de an√°lisis. Cada gr√°fico tiene su propia p√°gina explicando c√≥mo y en qu√© ocasi√≥n se debe usar o evitar. Tambi√©n proporciona acceso a R Graph Gallery con c√≥digo detallado que muestra c√≥mo replicarlo en R.\n\n\n\n\n\n\n\n\nComo se mencion√≥ anteriormente, esta p√°gina web es un repositorio que contiene c√≥digo para que los usuarios reproduzcan muchos tipos diferentes de gr√°ficos en R. ¬øC√≥mo puedo hacer un gr√°fico de dispersi√≥n en R? Mire la galer√≠a y lo descubrir√°. ¬øY un gr√°fico de barras? Lo mismo. Este es un lugar obligatorio para buscar cuando se aprende visualizaci√≥n de datos."
  },
  {
    "objectID": "recursos.html#introducci√≥n",
    "href": "recursos.html#introducci√≥n",
    "title": "Recursos √∫tiles para la visualizaci√≥n de datos",
    "section": "",
    "text": "Existen muchos proyectos que nos ayudan a crear visualizaciones de datos hermosas y efectivas. Algunos de ellos son recursos extremadamente √∫tiles y repositorios de c√≥digo disponibles para nosotros.\n\n\nLa p√°gina web Dataviz inspiration provee hermosos gr√°ficos e historias de datos. Estos ejemplos curados nos ayudan a visualizar el potencial completo de la visualizaci√≥n de datos y a obtener algunas ideas que podemos usar para nuestros propios an√°lisis. Uno de los ejemplos sobresalientes es Ailing Brussels, un an√°lisis de la desigualdad en Bruselas por la revista belga de investigaci√≥n Med√≥r. El proyecto emplea mapas, gr√°ficos, animaci√≥n y una narrativa convincente a trav√©s de im√°genes, textos y videos para describir la divisi√≥n espacial de Bruselas en cuanto a oportunidades y niveles de precariedad.\n\n\n\n\n\nVisite ambos sitios, Dataviz Inspirations y Ailing Brussels, para tener una maravillosa experiencia de las posibilidades de la visualizaci√≥n de datos.\n\n\n\nEl segundo recurso es el Proyecto Data to Viz. Es el resultado de un gran esfuerzo de sistematizaci√≥n. Yan Holtz, el creador, organiz√≥ gr√°ficos seg√∫n el tipo de datos o el tipo de an√°lisis. Cada gr√°fico tiene su propia p√°gina explicando c√≥mo y en qu√© ocasi√≥n se debe usar o evitar. Tambi√©n proporciona acceso a R Graph Gallery con c√≥digo detallado que muestra c√≥mo replicarlo en R.\n\n\n\n\n\n\n\n\nComo se mencion√≥ anteriormente, esta p√°gina web es un repositorio que contiene c√≥digo para que los usuarios reproduzcan muchos tipos diferentes de gr√°ficos en R. ¬øC√≥mo puedo hacer un gr√°fico de dispersi√≥n en R? Mire la galer√≠a y lo descubrir√°. ¬øY un gr√°fico de barras? Lo mismo. Este es un lugar obligatorio para buscar cuando se aprende visualizaci√≥n de datos."
  },
  {
    "objectID": "recursos.html#proyectos-hermosos",
    "href": "recursos.html#proyectos-hermosos",
    "title": "Recursos √∫tiles para la visualizaci√≥n de datos",
    "section": "Proyectos hermosos",
    "text": "Proyectos hermosos\nEn esta secci√≥n, presentamos algunos proyectos que nos inspiran y nos muestran c√≥mo la visualizaci√≥n de datos puede ser hermosa y efectiva.\n\nDear Data\nSe trata de un proyecto de dos dise√±adoras, Giorgia Lupi y Stefanie Posavec, que consiste en enviar postales semanales con datos personales dibujados a mano. Cada semana, durante un a√±o, las dos dise√±adoras recopilaron datos sobre sus vidas cotidianas y los representaron en postales. El proyecto resultante es una colecci√≥n de visualizaciones de datos dibujadas a mano que revelan la belleza de los datos y la creatividad de las dise√±adoras. El proyecto tambi√©n se convirti√≥ en un libro, Dear Data, que recopila las postales y las visualizaciones de datos.\nUn breve video explicando el proyecto:\n\nLa metodolog√≠a empleada explicada con m√°s detalle:\n\n\n\n\nEspa√±a vive en pisos (El Diario.es)\nEste proyecto de El Diario.es es un ejemplo de c√≥mo la visualizaci√≥n de datos puede ser utilizada para contar historias complejas. El proyecto visualiza la distribuci√≥n de la poblaci√≥n en Espa√±a y c√≥mo la mayor√≠a de la gente vive en pisos. La visualizaci√≥n combina mapas, gr√°ficos y narrativa para contar la historia de c√≥mo la mayor√≠a de la gente en Espa√±a vive en pisos y c√≥mo esto afecta a la calidad de vida y la desigualdad en el pa√≠s.\nNo se trata de la √∫nica visualizaci√≥n premiada. A d√≠a de hoy, el peri√≥dico posee el equipo de periodismo de datos m√°s destacado de Espa√±a y uno de los m√°s reconocidos a nivel internacional.\n\n\n\n\n\n\n\nEl Atlas de los ODS\nEl Atlas de los Objetivos de Desarrollo Sostenible (ODS) es un proyecto de la Divisi√≥n de Datos del Banco Mundial que visualiza los datos de los ODS en un formato interactivo y accesible. El Atlas proporciona visualizaciones de datos sobre los 17 ODS y los 169 objetivos espec√≠ficos de los ODS. Los datos se presentan en mapas, gr√°ficos y tablas interactivas que permiten a los usuarios explorar los datos y comparar los indicadores de los ODS en diferentes pa√≠ses y regiones. El Atlas es una herramienta valiosa para los responsables de la toma de decisiones, los investigadores y el p√∫blico en general que deseen comprender mejor los desaf√≠os y las oportunidades relacionados con los ODS.\n\n\n\n\n\n\n\nPoppy field\nValentina D‚ÄôFillipo cre√≥ una visualizaci√≥n para conmemorar el centenario de la Primera Guerra Mundial. La visualizaci√≥n muestra la cantidad de soldados que murieron en las guerras ocurridas durante el per√≠odo comprendido entre 1914 y 2014, representados por amapolas. La visualizaci√≥n es interactiva y permite a los usuarios explorar la cantidad de soldados que murieron en cada pa√≠s y en cada a√±o en las distintas guerras. La visualizaci√≥n es hermosa y efectiva, y nos recuerda la importancia de la visualizaci√≥n de datos para contar historias y evitar el olvido de eventos hist√≥ricos importantes.\n\n\n\n\n\n\n\nVisual Cinnamon\nVisual Cinnamon es la p√°gina personal de la dise√±adora visual Nadieh Bremer. Se trata de una fuente de inspiraci√≥n para cualquier persona interesada en la visualizaci√≥n de datos. Nadieh es conocida por su estilo √∫nico y su habilidad para combinar datos y dise√±o de una manera hermosa y efectiva. Su portafolio incluye visualizaciones de datos sobre temas como la m√∫sica, la astronom√≠a y la historia.\nAlgunos ejemplos de su trabajo que me gustan particularmente:\n\nPatrimonio cultural intangible (UNESCO)\nSe trata de una visualizaci√≥n interactiva que muestra el patrimonio cultural intangible de la UNESCO. Incorpora diversos tipos de gr√°fico y nos permite sacar ideas de qu√© podemos hacer con diferentes tipos de dato.\n\n\n\n\n\n\n\n¬øPor qu√© los gatos y perros‚Ä¶? (Google)\nEn esta visualizaci√≥n, Nadieh explora las preguntas m√°s comunes sobre gatos y perros en Google. Nos recuerda la estructura jer√°rquica del lenguaje y c√≥mo podemos representar las alternativas variantes de forma visualmente impactante y efectiva."
  },
  {
    "objectID": "tipos.html",
    "href": "tipos.html",
    "title": "Tiposde gr√°fico",
    "section": "",
    "text": "En esta parte del curso examinaremos algunos de los tipos m√°s comunes de gr√°fico. Los organizaremos seg√∫n el tipo de an√°lisis que se desea realizar con ellos. Por ejemplo, si queremos saber si una variable cuantitativa afecta otra igual, realizamos un gr√°fico de dispersi√≥n o un correlograma. si el objetivo es saber la frecuencia de una variable categ√≥rica, un gr√°fico de barras puede ser la mejor opci√≥n."
  },
  {
    "objectID": "tipos.html#introducci√≥n",
    "href": "tipos.html#introducci√≥n",
    "title": "Tiposde gr√°fico",
    "section": "",
    "text": "En esta parte del curso examinaremos algunos de los tipos m√°s comunes de gr√°fico. Los organizaremos seg√∫n el tipo de an√°lisis que se desea realizar con ellos. Por ejemplo, si queremos saber si una variable cuantitativa afecta otra igual, realizamos un gr√°fico de dispersi√≥n o un correlograma. si el objetivo es saber la frecuencia de una variable categ√≥rica, un gr√°fico de barras puede ser la mejor opci√≥n."
  },
  {
    "objectID": "tipos.html#tipos-de-dato-y-tipos-de-gr√°ficos",
    "href": "tipos.html#tipos-de-dato-y-tipos-de-gr√°ficos",
    "title": "Tiposde gr√°fico",
    "section": "Tipos de dato y tipos de gr√°ficos",
    "text": "Tipos de dato y tipos de gr√°ficos\nCada tipo de gr√°fico suele corresponder a un tipo de dato o a una combinaci√≥n entre tipos de dato. Por esa raz√≥n, resulta √∫til conocer la clasificaci√≥n de los gr√°ficos seg√∫n los diferentes tipos de informaci√≥n para sacar los mejores resultados.\nLa p√°gina from Data to Viz resulta muy √∫til, pues ofrece una doble clasificaci√≥n de los datos: por tipo de dato y el tipo de representaci√≥n que se desea realizar. Recomiendo fuertemente que la estudi√©is con detenimiento para tener una idea general de qu√© opciones ten√©is. Luego, podr√©is regresar a la p√°gina para refrescar los conceptos y encontrar ejemplos, as√≠ como los c√≥digos. Se trata de una herramienta muy √∫til a la hora de elegir el tipo de visualizaci√≥n que queremos para nuestros datos."
  },
  {
    "objectID": "tipos.html#distribuci√≥n",
    "href": "tipos.html#distribuci√≥n",
    "title": "Tiposde gr√°fico",
    "section": "Distribuci√≥n",
    "text": "Distribuci√≥n\nLos gr√°ficos de distribuci√≥n son √∫tiles para entender c√≥mo se distribuyen los datos. ¬øCu√°l categor√≠a es la m√°s frecuente? ¬øLos votos en un partido X en las mesas de Sevilla se encuentran concentrados alrededor de la media o var√≠an mucho? Las visualizaciones de este apartado ayudan a responder a dichas preguntas. En este grupo se encuentran los histogramas, los gr√°ficos de densidad, los diagramas de caja (boxplots) o los de viol√≠n (violin).\n\nGr√°ficos de barras\nEl gr√°fico de barras es uno de los m√°s comunes y √∫tiles. Se utiliza para representar la frecuencia de una variable categ√≥rica. Por ejemplo, si queremos saber cu√°ntos votos ha obtenido cada partido en una elecci√≥n, un gr√°fico de barras es la mejor opci√≥n. Esto nos permite comparar los valores y sacar conclusiones y patrones a partir de ellos.\nEl c√≥digo abajo crea un gr√°fico de barra para la variable pot_policy de la base de datos de los estados de EE. UU. La variable pot_policy representa la pol√≠tica relacionada a la legalizaci√≥n de la marijuana dominante en cada estado.\nAdem√°s, para no aburrirnos, tambi√©n vamos a crear un gr√°fico de barras polar. Este tipo de gr√°fico es √∫til cuando queremos comparar la frecuencia de una variable categ√≥rica en un c√≠rculo. En este caso, la variable pot_policy se encuentra en el eje x y el eje y representa la frecuencia de cada categor√≠a. Como ver√©is, se trata del mismo gr√°fico. Lo √∫nico que cambia es el sistema de coordenadas.\n\n\nCode\n# Carga los datos\nlibrary(poliscidata)\n\n# Crea un data.frame d\n# con los datos de los estados\nd &lt;- states\n\n\n# reordena de modo decreciente de \n# la frecuencia\nd$pot_policy &lt;- reorder(\n                       d$pot_policy, \n                       d$pot_policy, \n                       function(x) -length(x))\n\n#\nlibrary(ggplot2)\n\n# 1) Crea la capa de datos\np &lt;- ggplot(data = d)\n\n# 2 ) A√±ade la capa de est√©tica\np &lt;- p + aes(x=pot_policy) \n\n# 3) A√±ade la capa de geometr√≠a\np &lt;- p + geom_bar()\n\n# Visualiza el gr√°fico\np\n\n\n\n\n\nCode\n# 4) A√±ade la capa de coordenadas \n# (en este caso polares)\np + coord_polar()\n\n\n\n\n\n\n\nHistograma\nEl histograma es una visualizaci√≥n muy √∫til para entender la distribuci√≥n de una variable cuantitativa. Se divide en intervalos que contienen el n√∫mero de observaciones (en nuestro caso estados) con valores entre los l√≠mites de cada uno de ellos.\nEn el siguiente c√≥digo, creamos un histograma para la variable pop2010 de la base de datos de los estados de EE. UU. La variable pop2010 representa la poblaci√≥n de cada estado en el a√±o 2010.\n\n\nCode\nlibrary(ggplot2)\n\n# Crea el histograma para pop2010\np &lt;- ggplot(d, aes(pop2010))+\n  \n      # Adicional la geometr√≠a con 8 intervalos\n      geom_histogram(bins = 8)\n\n# Visualiza\np\n\n\n\n\n\nComo podemos ver, el patr√≥n com√∫n de los datos de poblaci√≥n se revela: muchos estados con poca poblaci√≥n y unos pocos con mucha. Ese comportamiento suele pasar tambi√©n en municipios, pa√≠ses, etc.\n\n\nDensidad\nEl gr√°fico de densidad es similar al histograma, pero en lugar de contar el n√∫mero de observaciones en un intervalo, muestra una curva que representa la densidad de probabilidad de la variable. En otras palabras, el √°rea bajo la curva es igual a 1.\n\n\nCode\nlibrary(ggplot2)\n\n# Crea el gr√°fico de densidad de pop2010\np &lt;- ggplot(d, aes(pop2010))+\n  \n      # Adiciona la geometr√≠a de densidad\n      geom_density()\n\n# Visualiza\np\n\n\n\n\n\nComo vemos, la curva de densidad nos muestra que la mayor√≠a de los estados tienen una poblaci√≥n baja, pero hay algunos con una poblaci√≥n muy alta. Se trata de la misma informaci√≥n que en el histograma anterior, pero no hay cortes bruscos como los generados por los intervalos. Esa caracter√≠stica evita posibles distorsiones ocasionadas por la elecci√≥n del n√∫mero o del tama√±o de los intervalos.\n\n\nBoxplot\nOtro gr√°fico de distribuci√≥n muy √∫til es el boxplot. Este gr√°fico muestra la distribuci√≥n de una variable cuantitativa a trav√©s de cinco estad√≠sticas: el m√≠nimo, el primer cuartil, la mediana, el tercer cuartil y el m√°ximo. Adem√°s, tambi√©n muestra los valores at√≠picos (outliers). Se emplea para analizar la dispersi√≥n y la simetr√≠a de los datos. Un diagrama donde las partes son sim√©tricas y la caja resulta muy peque√±a indica que los datos est√°n muy concentrados alrededor de la mediana. Por otro lado, una caja grande y asim√©trica indica que los datos est√°n dispersos y que hay una mayor dispersi√≥n hacia los mayores o menores valores.\nEl gr√°fico abajo crea un boxplot para la variable que mide el porcentaje de desempleo (unemploy) en cada estado. Para a√±adir valor, elegimos agrupar los estados por regi√≥n para saber si existe alg√∫n patr√≥n territorial en la distribuci√≥n del paro en EE. UU.\nLos par√°metros fill y group son necesarios para que el gr√°fico muestre una caja por cada regi√≥n. En el primer caso, se atribuye un color a cada regi√≥n y group se encarga de que cada regi√≥n tenga su propia caja.\n\n\nCode\np &lt;- ggplot(data = d,\n            mapping = aes(x=unemploy, \n                          y=region,\n                          fill=region,\n                          group=region)) + \n        geom_boxplot(width=0.1)\n\np\n\n\n\n\n\nVemos claramente dos patrones. De un lado, se encuentra el Oeste con estados con poco paro y otros con una tasa elevada. La dispersi√≥n resulta alta, tanto por los ‚Äúbigotes‚Äù como por el tama√±o de la caja. Adem√°s, los valores altos se encuentran m√°s dispersos, pues la caja es m√°s grande en la parte derecha. Por otro lado, el Noreste tiene una tasa de paro m√°s concentrada, aunque la dispersi√≥n resulta mayor en la parte superior de la caja.\n\n\nViolin plot\nEl violin plot es una combinaci√≥n de un boxplot y un density plot. Muestra la distribuci√≥n de una variable cuantitativa y la densidad de probabilidad de la misma. Es √∫til para comparar distribuciones entre diferentes grupos. En el siguiente gr√°fico, creamos un violin plot para la variable unemploy (tasa de paro) agrupada por regi√≥n. Vemos que resulta muy parecido al boxplot anterior, pero con la ventaja de mostrar la densidad de probabilidad de la variable, es decir, d√≥nde se concentran los valores. Aprovechamos para a√±adir los puntos de cada observaci√≥n con geom_jitter. As√≠ queda m√°s f√°cil entender por qu√© el gr√°fico tiene la forma que tiene.\n\n\nCode\np &lt;- ggplot(data = d,\n            mapping = aes(x=unemploy, \n                          y=region,\n                          group=region)) + \n        geom_violin()+\n        geom_jitter(aes(color=region))\n\np\n\n\n\n\n\n\n\nLollipop\nEl gr√°fico de lollipop es una variante del gr√°fico de barras. En lugar de barras, se utilizan segmentos de l√≠nea para representar las frecuencias de las categor√≠as. Es √∫til cuando se quiere resaltar una categor√≠a en particular. En el siguiente gr√°fico, creamos un lollipop para la variable abort_rank3, que representa la clasificaci√≥n de los estados seg√∫n su legislaci√≥n sobre el aborto.\nMientras que en los casos anteriores, cada gr√°fico ten√≠a una sola geometr√≠a, en el lollipop se combinan dos: geom_point (punto) y geom_segment (segmento de l√≠nea). Esta estrategia resulta muy com√∫n en la creaci√≥n de visualizaciones originales y personalizadas. Dominar la combinaci√≥n entre geometr√≠as puede ser muy √∫til para crear gr√°ficos m√°s complejos y atractivos.\n\n\nCode\nlibrary(ggplot2)\n\n# Crea una tabla ordenada con los\n# valores de abort_rank3\ntb &lt;- sort(table(d$abort_rank3))\n\n# La convierte en base de datos\n# para la funci√≥n ggplot\ntb &lt;- data.frame(tb)\n\n# Crea el gr√°fico de lollipop\np &lt;- ggplot(tb, \n            aes(y=Var1, \n                x=Freq)) +\n  \n  # A√±ade los puntos rojos\n  geom_point(color=\"red\") + \n  \n  # A√±ade los segmentos\n  geom_segment( aes(y=Var1, \n                    yend=Var1, \n                    x=0, \n                    xend=Freq))\n\n# Dibuja el gr√°fico\np\n\n\n\n\n\n\n\nTreemap\nUn treemap es un gr√°fico de proporciones representadas por √°reas o rect√°ngulos. Cuanto mayor sea el √°rea, mayor ser√° la frecuencia de una categor√≠a dada (representada por un rect√°ngulo). La principal ventaja de los treemaps es que permite representar datos jer√°rquicos. Por lo tanto, los grupos y subgrupos dentro de ellos pueden visualizarse f√°cilmente. Adem√°s, los treemaps permiten sintetizar muchos datos en un espacio relativamente peque√±o.\n\n\nCode\nlibrary(ggplot2)\n\n# Carga el paquete treemapify\nlibrary(treemapify)\n\n# Crea una tabla ordenada con\n# las pol√≠ticas de control de\n# la marijuana\ntb &lt;- sort(table(d$pot_policy))\n\n# Convierte en base de datos\ntb &lt;- data.frame(tb)\n\n# Crea el treemap usando la\n# geometr√≠a geom_treemap()\n# del paquete teemapify\n\n# Inicialmente, define\n# el gr√°fico con el √°rea, color\n# y etiqueta\np &lt;- ggplot(tb, \n            aes(area = Freq, \n                fill = Var1, \n                label=Var1)) +\n  \n  # A√±ade la geometr√≠a de\n  # treemap al gr√°fico\n  geom_treemap()\n\n# Visualiza el resultado\np\n\n\n\n\n\n\n\nBeeSwarm\nEl gr√°fico de beeswarm es una variante del scatter plot que permite visualizar la distribuci√≥n de una variable cuantitativa en funci√≥n de una variable categ√≥rica. Es √∫til para comparar la distribuci√≥n de una variable cuantitativa entre diferentes grupos. En el siguiente gr√°fico, creamos un beeswarm para la variable pop_65_older (poblaci√≥n de 65 a√±os o m√°s) agrupada por el nivel de democracia de los pa√≠ses. Adem√°s, a√±adimos el color seg√∫n la religi√≥n de los pa√≠ses.\nComo vemos, tambi√©n se parece mucho al violin plot anterior. Sin embargo, el beeswarm tiene la ventaja de mostrar cada observaci√≥n individual, lo que puede ser √∫til para detectar patrones o valores at√≠picos. Adem√°s, resulta m√°s atractivo visualmente, pues los puntos no se superponen y se distribuyen de forma m√°s uniforme. En este caso, a√±adimos la religi√≥n como informaci√≥n adicional para intentar encontrar alg√∫n patr√≥n en los datos.\n\n\nCode\nw &lt;- world\n\n# Carga los paquetes necesarios\nlibrary(ggplot2)        \nlibrary(ggbeeswarm)      \n\n# Crea el gr√°fico con el nivel de democracia\n# y la poblaci√≥n de 65 a√±os o m√°s\n# con color seg√∫n la religi√≥n\np &lt;- ggplot(data = w,\n            mapping = aes(x=dem_level4, \n                          y=pop_65_older, \n                          color=religoin)) \n\n# A√±adimos la geometr√≠a: geom_quasirandom()\np &lt;- p + geom_quasirandom(size=1.5)\n\n# Visualizamos los resultados\np\n\n\n\n\n\nComo vemos, las poblaciones de las democracias plenas presentan una mayor proporci√≥n de personas de 65 a√±os o m√°s. La autocracia, por otro lado, presenta una poblaci√≥n m√°s joven. Adem√°s, parece que la religi√≥n predominantes en los pa√≠ses con mayor proporci√≥n de personas de 65 a√±os y m√°s democr√°ticos es el cristianismo, mientras que los m√°s j√≥venes y autoritarios son en su mayor parte de mayor√≠a musulmana.\n\n\nRidge Plot\nEl gr√°fico de ridge es una variante del density plot que permite visualizar la distribuci√≥n de una variable cuantitativa en funci√≥n de una variable categ√≥rica. Es √∫til para comparar la distribuci√≥n de una variable cuantitativa entre diferentes grupos. En el siguiente gr√°fico, creamos un ridge para la variable frac_eth (fracci√≥n de etnias) agrupada por la religi√≥n de los pa√≠ses.\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Crea el gr√°fico\n# con la relaci√≥n entre \n# fraccionamiento √©tnico y religi√≥n\np &lt;- ggplot(w,\n            aes(x=frac_eth, \n                y=religoin, \n                fill=religoin))\n\n# A√±ade la capa de geometr√≠a\np &lt;- p + geom_density_ridges()\n\n# Visualiza los resultados\np\n\n\n\n\n\nComo vemos, la distribuci√≥n de la fracci√≥n √©tnica var√≠a seg√∫n la religi√≥n predominante en los pa√≠ses. Los pa√≠ses con mayor√≠a musulmana presentan una mayor fracci√≥n √©tnica, mientras que los pa√≠ses con mayor√≠a cat√≥lica presentan una menor fracci√≥n √©tnica. Adem√°s, los pa√≠ses con mayor√≠a musulmana presentan una distribuci√≥n m√°s dispersa, mientras que los pa√≠ses con mayor√≠a budista presentan una distribuci√≥n m√°s concentrada. La categor√≠a ‚Äúotros cristianos‚Äù presenta una distribuci√≥n m√°s dispersa, con dos picos.\n\n\nRaincloud Chart\nEl gr√°fico de raincloud resulta muy divertido. Combina un violin plot, un box plot y un scatter plot en un solo gr√°fico. Se llama as√≠, porque las curvas de densidad se asemejan a nubes y los puntos dispersos representados abajo parecen gotas de lluvia. Como en versiones anteriores que hemos elaborado m√°s arriba, tenemos una representaci√≥n sint√©tica (una curva que describe la densidad o el comportamiento de los datos) y unos puntos que representa la posici√≥n aproximada de cada observaci√≥n. En el siguiente gr√°fico, creamos un raincloud para la variable pop_65_older (poblaci√≥n de 65 a√±os o m√°s) agrupada por el nivel de democracia de los pa√≠ses.\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggridges)\n\n# Creamos el gr√°fico, los datos son w, y las\n# variables: y=dem_level4 y x=pop_65_older,\n# el color es fill=dem_level4\np &lt;- ggplot(w,\n       aes(y = dem_level4, \n           x = pop_65_older, \n           fill = dem_level4)) \n\n# Ahora adiciona la geometr√≠a, \n# que incorpora los pujntos y\n# las l√≠neas que identifica los\n# cuartiles\np &lt;- p + geom_density_ridges(\n              jittered_points = TRUE,\n              position = \"raincloud\",\n              alpha=0.6,                            \n              quantile_lines = TRUE)\n\n# Visualiza el resultado\np"
  },
  {
    "objectID": "tipos.html#asociaci√≥n-o-correlaci√≥n",
    "href": "tipos.html#asociaci√≥n-o-correlaci√≥n",
    "title": "Tiposde gr√°fico",
    "section": "Asociaci√≥n o correlaci√≥n",
    "text": "Asociaci√≥n o correlaci√≥n\nLos gr√°ficos de asociaci√≥n o correlaci√≥n son √∫tiles para visualizar la relaci√≥n entre dos o m√°s variables cuantitativas. Nos ayudan a identificar los v√≠nculos entre fen√≥menos medidos de forma continua y formular hip√≥tesis sobre su relaci√≥n.\n\nDiagrama de dispersi√≥n\nUn diagrama de dispersi√≥n o scatterplot es una de las formas m√°s sencillas y efectivas de visualizar la relaci√≥n entre dos variables cuantitativas. Cada punto en el gr√°fico representa una observaci√≥n y su posici√≥n en los ejes x e y indica los valores de las dos variables. Resulta tan com√∫n que su interpretaci√≥n es bastante intuitiva. Permite, adem√°s, que a√±adamos dos o tres variables m√°s, como el color, el tama√±o o la forma de los puntos, para representar informaci√≥n adicional.\nEn el siguiente ejemplo, creamos un diagrama de dispersi√≥n para visualizar la relaci√≥n entre la variable hdi (√≠ndice de desarrollo humano) y la variable dem_score14 (puntuaci√≥n de democracia). Adem√°s, coloreamos los puntos seg√∫n la religi√≥n mayoritaria (religoin), cada continente (regionun) estar√° representado por una forma distinta y definiremos el tama√±o empleando el porcentaje de personas con 65 a√±os o m√°s (pop_65_older).\n\n\nCode\nlibrary(ggplot2)\n\n# Crea el gr√°fico\np &lt;- ggplot(w)\n\n# Capa est√©tica con la religi√≥n\n# como color\np &lt;- p+ aes(x=hdi, \n            y=dem_score14,\n            color=religoin,\n            size=pop_65_older,\n            shape=regionun)\n\n\n# Capa geom√©trica\np &lt;- p +geom_point()\n\n# Visualiza el gr√°fico\np\n\n\n\n\n\nTenemos un gr√°fico verdaderamente horrible. No obstante, solo quer√≠a demostraros que es posible a√±adir m√°s de dos variables a un diagrama de dispersi√≥n. En este caso, tenemos cinco: desarrollo humano, democracia, continente, religi√≥n y porcentaje de personas mayores de 65 a√±os. Aunque se pueda hacer, como hab√©is visto, ni siempre es recomendable o √∫til. En este caso, la visualizaci√≥n resulta confusa y poco informativa. Por tanto, es mejor limitar el n√∫mero de variables a dos o tres para que el gr√°fico sea m√°s f√°cil de interpretar:\n\n\nCode\nlibrary(ggplot2)\n\n# Crea el gr√°fico\np &lt;- ggplot(w)\n\n# Capa est√©tica con la religi√≥n\n# como color\np &lt;- p+ aes(x=hdi, \n            y=dem_score14,\n            color=religoin)\n\n\n# Capa geom√©trica\np &lt;- p +geom_point()\n\n# Visualiza el gr√°fico\np\n\n\n\n\n\n\n\nCorrelograma\n¬øQu√© pasa cuando queremos comparar el grado de asociaci√≥n entre muchas variables cuantitativas de una sola vez? En este caso, el correlograma es una herramienta muy √∫til. Un correlograma es una matriz en la que cada celda representa el coeficiente de correlaci√≥n entre dos variables. Los valores de la correlaci√≥n pueden variar entre -1 y 1. Un valor de 1 indica una correlaci√≥n positiva perfecta, un valor de -1 indica una correlaci√≥n negativa perfecta y un valor de 0 indica que no hay correlaci√≥n entre las variables. Los correlogramas son √∫tiles para identificar patrones de correlaci√≥n entre variables y seleccionar las variables m√°s relevantes para un an√°lisis m√°s detallado.\nEn el siguiente ejemplo, creamos un correlograma para visualizar la correlaci√≥n entre las variables gini10, dem_score14, literacy, lifeex_total, hdi, pop_urban, frac_eth y gdppcap08.\n\n\nCode\n# Carga el paquete necesario\nlibrary(ggcorrplot)\n\n# Crea una lista de variables\n# de inter√©s\nvar &lt;- c(\"gini10\",\"dem_score14\",\n         \"literacy\",\"lifeex_total\",\n         \"hdi\",\"pop_urban\",\"frac_eth\",\n         \"gdppcap08\")\n\n# Calcula la matriz de correlaci√≥n\ncorr &lt;- round(cor(w[,var], \n                  use=\"pairwise.complete.obs\"), \n              3)\n\n# Visualiza los resultados\nggcorrplot(corr, \n           lab_size = 3,\n           show.diag = F,\n           hc.order = T,\n           lab=T)\n\n\n\n\n\nEl patr√≥n que emerge resulta claro: el fraccionamiento √©tnico (frac_eth) y el √≠ndice de desigualdad de renta (gini10) est√°n negativamente correlacionados con todas las dem√°s variables (que presentan una asociaci√≥n positiva). Es decir, la fraccionalizaci√≥n √©tnica y la desigualdad no ‚Äúcasan‚Äù muy bien con la riqueza (gdppcap08), la urbanizaci√≥n (pop_urban), el desarrollo humano (hdi), la esperanza de vida (lifeex_total), la alfabetizaci√≥n (literacy) o la democracia (dem_score14)."
  },
  {
    "objectID": "tipos.html#conexi√≥n",
    "href": "tipos.html#conexi√≥n",
    "title": "Tiposde gr√°fico",
    "section": "Conexi√≥n",
    "text": "Conexi√≥n\nLos gr√°ficos de conexi√≥n son √∫tiles para visualizar datos de red. Nos permiten representar las relaciones entre diferentes entidades (nodos) y las interacciones entre ellas (v√≠nculos). Los gr√°ficos de conexi√≥n son √∫tiles para visualizar flujos de informaci√≥n, rutas de transporte, relaciones comerciales, interpersonales, etc.\n\nRed\nUn gr√°fico de red o sociograma es una representaci√≥n visual de una red social. Se compone de dos unidades b√°sicas: los nodos (o v√©rtices) y los v√≠nculos (o aristas). Los nodos son los puntos de la red y pueden representar a individuos, organizaciones, pa√≠ses, ciudades, etc. Los v√≠nculos son las conexiones entre ellos y pueden se√±alar relaciones de amistad, colaboraci√≥n, intercambio. Puede ser una red de ciudades, de empresas, de personas, de p√°ginas web, entre muchos otras aplicaciones.\nEn el siguiente ejemplo, creamos un gr√°fico de red para visualizar los flujos de visitas de la presidenta Dilma Rousseff entre diferentes ciudades de Brasil durante el mes anterior a las elecci√≥nes presidenciales de 2014. La base de datos contiene informaci√≥n sobre el n√∫mero de visitas entre diferentes ciudades, as√≠ como el n√∫mero total de viajes realizados. Se ha obtenido a partir del an√°lisis de los peri√≥dicos que cubrieron la campa√±a electoral.\n\n\nCode\n# Abre la base de datos\ndi &lt;- read.delim(\"https://www.dropbox.com/s/r8309gzg3rymajr/Visitas_Dilma_redux.csv?dl=1\", \n                 sep=\";\", \n                 dec=\",\")\n\n# Seleccoiona las variables\ndi &lt;- unique(di[,c(\"NOM_O\",\"NOM_D\",\n                   \"FREQ\",\"VISITS\")])\n\n\nnames(di) &lt;- c(\"Origen\",\"Destino\",\n               \"Viajes\",\"Visitas\")\n\n\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggnetwork)\n\n# Convierte la base de datos\n# en un layout de red\nn &lt;- ggnetwork(di)\n\n# Crea el gr√°fico con las\n# capas de datos y est√©tica\np &lt;- ggplot(n, \n       aes(x = x, \n           y = y, \n           xend = xend, \n           yend = yend))\n\n# A√±ade la capa de v√≠nculos (aristas)\np &lt;- p + geom_edges(\n          aes(size=Viajes),\n               color = \"red3\", \n               alpha=0.1,           \n               curvature = 0.25)    \n\n# Ahora, a√±ade los puntos (nodos)\n# a la red anterior\np &lt;- p + geom_nodes(aes(size=Visitas), \n            color=\"red3\")\n\n# Adiciona los nombres de las ciudades\np &lt;- p + geom_nodetext_repel(\n  aes(\n    label = vertex.names))\n\n# Elimina el tema y la leyenda\np &lt;- p + theme_blank() +\n         theme(legend.position = \"none\")\n\n# Visualiza los resultados\np\n\n\n\n\n\nSe observa que la candidata se desplaza principalmente entre las ciudades de S√£o Paulo, Bras√≠lia, R√≠o de Janeiro y Porto Alegre. Los constantes regresos a Bras√≠lia revelan la necesidad de conciliar las agendas de candidata con la de presidenta. R√≠o y S√£o Paulo, por su parte, son los principales centros econ√≥micos y pol√≠ticos del pa√≠s, mientras que Porto Alegre es la ciudad natal de la candidata. Vemos tambi√©n que ha visitado otras ciudades, pero estas ocupan un lugar m√°s perif√©rico en la red."
  },
  {
    "objectID": "tipos.html#tiempo-flujo-evoluci√≥n",
    "href": "tipos.html#tiempo-flujo-evoluci√≥n",
    "title": "Tiposde gr√°fico",
    "section": "Tiempo / Flujo / Evoluci√≥n",
    "text": "Tiempo / Flujo / Evoluci√≥n\nLos gr√°ficos de tiempo o flujo son √∫tiles para visualizar la evoluci√≥n de una variable a lo largo del tiempo. Nos permiten identificar tendencias, patrones y ciclos en los datos. Entre las aplicaciones posibles encontramos las series temporales, flujos de informaci√≥n, movimientos de poblaci√≥n, entre otros.\nPrepara la base de Brasil\n\n\nCode\nYear &lt;- c(1985:2019)\n\nGini &lt;- c(55.6,58.5,59.7,61.4,63.3,60.5,60.3,60.2,60.1,59.9,59.6,59.9,59.8,59.6,59.0,58.7,58.4,58.1,57.6,56.5,56.3,55.6,54.9,54.0,53.7,53.3,52.9,53.4,52.7,52.0,51.9,53.3,53.3,53.9,53.5)\n\nAdministration &lt;- c(\"Sarney\",\"Sarney\",\"Sarney\",\"Sarney\",\"Sarney\",\"Collor\",\"Collor\",\"Collor\",\"Itamar\",\"Itamar\",\"FHC\",\"FHC\",\"FHC\",\"FHC\",\"FHC\",\"FHC\",\"FHC\",\"FHC\",\"Lula\",\"Lula\",\"Lula\",\"Lula\",\"Lula\",\"Lula\",\"Lula\",\"Lula\",\"Dilma\",\"Dilma\",\"Dilma\",\"Dilma\",\"Dilma\",\"Dilma\",\"Temer\",\"Temer\",\"Bolsonaro\")\n\nGrowth &lt;- c(7.9,7.5,3.5,-0.1,3.2,-4.4,1.0,-0.5,4.9,5.9,4.2,2.2,3.4,0.3,0.5,4.4,1.4,3.1,1.1,5.8,3.2,4.0,6.1,5.1,-0.1,7.5,4.0,1.9,3.0,0.5,-3.5,-3.3,1.3,1.8,1.2)\n\nGDP &lt;- c(836,898,930,930,959,917,927,922,967,1024,1067,1090,1127,1131,1137,1186,1203,1240,1254,1326,1368,1423,1509,1586,1584,1703,1771,1805,1859,1868,1802,1743,1766,1798,1820)\n\nbr &lt;- data.frame(Year=Year, \n                 GDP=GDP, \n                 Growth=Growth, \n                 Gini=Gini, \n                 Administration=Administration)\n\n\nbrs &lt;- data.frame()\n\nfor(i in 1:nrow(br)){\n  \n  if (i&lt;nrow(br)){\n    k &lt;- i+1\n  }else{\n    k &lt;- i\n  }\n  \n  brs &lt;- rbind(brs,\n               data.frame(\n                      x1=br$Year[i],\n                    xend=br$Year[k],\n                      y1=br$Gini[i],\n                      yend=br$Gini[k],\n Administration=br$Administration[i])\n              )\n  \n}\n\nbrs2 &lt;- data.frame()\n\nfor(i in 1:nrow(br)){\n  \n  if (i&lt;nrow(br)){\n    k &lt;- i+1\n  }else{\n    k &lt;- i\n  }\n  \n  brs2 &lt;- rbind(brs2,\n               data.frame(\n                      x1=br$GDP[i],\n                    xend=br$GDP[k],\n                      y1=br$Gini[i],\n                      yend=br$Gini[k],\n Administration=br$Administration[i],\n                      Year=Year[i])\n              )\n  \n}\n\n\n\nL√≠nea\nEl gr√°fico de l√≠neas es una de las formas m√°s comunes de visualizar datos temporales. Se compone de dos ejes: el eje horizontal representa el tiempo y el eje vertical la variable de inter√©s. Se utiliza para visualizar la evoluci√≥n de una variable a lo largo del tiempo, identificar tendencias, patrones y ciclos.\nEl c√≥digo abajo muestra c√≥mo crear un gr√°fico de l√≠neas para visualizar la evoluci√≥n del √≠ndice de desigualdad de renta en Brasil entre 1985 y 2019. La base de datos contiene informaci√≥n sobre el √≠ndice de Gini en Brasil, as√≠ como el a√±o correspondiente. Se ha obtenido a partir de la base de datos del Banco Mundial.\n\n\nCode\n# Prepara el gr√°fico\np &lt;- ggplot(br, \n            aes(x=Year, y=Gini))+\n      geom_line()\n\n# Visualiza los resultados\np\n\n\n\n\n\n\n\nConnected scatterplot\nEl gr√°fico de dispersi√≥n conectado es una variante del gr√°fico de l√≠neas que permite visualizar la relaci√≥n entre dos variables a lo largo del tiempo. Se trata de conectar los puntos por medio de segmentos de l√≠nea para resaltar la evoluci√≥n de la variable en el tiempo. El gr√°fico abajo muestra la evoluci√≥n de la desigualdad en Brasil entre 1985 y 2019, pero ahora, marca los cambios de gobierno en el pa√≠s.\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\nlibrary(ggrepel)\n\n# Crea el gr√°fico\np &lt;- ggplot(brs, \n            aes(x=Year, \n                y=Gini,\n                fill=Administration))\n\n# A√±ade segmentos de l√≠nea para\n# cada gobierno\np &lt;- p + geom_segment(\n                      aes(x=x1,\n                          xend=xend,\n                          y=y1,\n                          yend=yend,\n                          color=Administration))\n\n\n# Visualiza los resultados\np\n\n\n\n\n\n\n\nArea\nEl gr√°fico de √°rea es una variante del gr√°fico de l√≠neas que rellena el √°rea entre la l√≠nea y el eje horizontal. El cambio puede parecer insignificante, pero posibilita la percepci√≥n de cambios importantes en vol√∫menes. En el ejemplo abajo, se muestra la evoluci√≥n del crecimiento econ√≥mico en Brasil entre 1985 y 2019.\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\n\n# Prepara el gr√°fico\np &lt;- ggplot(br, \n            aes(y=Growth, \n                x=Year))+\n      geom_area(fill=\"darkgreen\")\n\n\n# Visualiza los resultados\np\n\n\n\n\n\n\n\nDumbbell\nEl gr√°fico de pesas rusas (dumbbell) es una variante del gr√°fico de l√≠neas que permite visualizar la evoluci√≥n de dos variables a lo largo del tiempo. Se compone de dos o m√°s puntos conectados por un segmento de l√≠nea. Es √∫til para comparar dos valores en diferentes momentos y visualizar la evoluci√≥n de la variable en el tiempo. El gr√°fico abajo muestra la evoluci√≥n de la proporci√≥n de la riqueza concentrada por el 10% m√°s rico de en los pa√≠ses de Am√©rica Latina en 2000, 2010 y 2019.\nPrimero, prepara los datos:\n\n\nCode\nlibrary(vdemdata)\n\ndem&lt;- vdem\n\ndm &lt;- dem[,c(\"country_name\",\"year\",\"v2x_polyarchy\",\"v2x_libdem\",\"v2x_partipdem\",\"v2x_delibdem\",\"v2x_egaldem\")]\n\nnames(dm) &lt;- c(\"Country\",\"Year\",\"Electoral\",\"Liberal\",\"Participative\",\"Deliberative\",\"Egalitarian\")\n\n\nco &lt;- c(\"Argentina\",\"Bolivia\",\"Brazil\",\"Chile\",\"Colombia\",\"Costa Rica\",\"Dominican Republic\",\"Ecuador\",\"Honduras\",\"Mexico\",\"Panama\",\"Peru\",\"Paraguay\",\"El Salvador\",\"Uruguay\")\n\ndml &lt;- dm[dm$Country%in%c(co,\"Nicaragua\",\"Venezuela\"),]\n\nye &lt;- c(rep(2000,length(co)),rep(2010,length(co)),\n        rep(2020,length(co)))\n\ntop &lt;- c(37.7,47.8,47,42.6,47,35.7,40.2,45.9,41.9,42,43.2,36.8,42.1,39,35.4,31.7,36.9,42.2,38.2,43.4,36.8,36.5,37.5,40.2,37.1,39.7,34.2,40.5,33.2,33.6,30.3,32.6,39.4,35.8,42.2,37,30.5,36,34.6,35.5,38,32.9,33.3,29.8,29.9)\n\nlat &lt;- data.frame(Country=c(co,co,co), Year=as.character(ye), Share=top)\n\n\nLuego, el gr√°fico:\n\n\nCode\n# Carga los paquetes\nlibrary(ggplot2)\n\n# Obtiene el orden de los pa√≠ses seg√∫n\n# la proporci√≥n de riqueza apropiada por\n# los 10% m√°s ricos (de los m√°s a los menos).\nlevels &lt;- lat[\n              order(\n                lat$Share[lat$Year==2000], \n                decreasing = T),\n              c(\"Country\")]\n\n# Reordena la base de datos seg√∫n los niveles\n# obtenidos en 2000 (esto es importante para que el \n# gr√°fico salga bonito y f√°cil de interpretar)\nlat$Country &lt;- factor(lat$Country, \n                      levels=levels)\n\n# Genera el gr√°fico\np &lt;- ggplot(lat,\n            aes(y=Country, \n                x=Share))\n\n# Adiciona los segmentos de l√≠nea\n# conectando cada per√≠odo\np &lt;- p + geom_line(color=\"grey85\")\n\n# A√±ade puntos y los colorea de\n# acuerdo al a√±o (Year)\np &lt;- p + geom_point(aes(color=Year))\n\n# Visualiza los resultados\np\n\n\n\n\n\nSe observa que la mayor√≠a de los pa√≠ses han experimentado una reducci√≥n en la concentraci√≥n de la riqueza en manos del 10% m√°s rico, con excepci√≥n de Costa Rica, que ha experimentado un aumento en el mismo per√≠odo. Resulta notable el caso de Bolivia, que ha experimentado una reducci√≥n significativa en la concentraci√≥n de la riqueza en manos del 10% m√°s rico en el per√≠odo analizado, que pasa de ser el pa√≠s m√°s desigual al quinto menos desigual en la regi√≥n en 2020."
  },
  {
    "objectID": "tipos.html#espacio",
    "href": "tipos.html#espacio",
    "title": "Tiposde gr√°fico",
    "section": "Espacio",
    "text": "Espacio\nLos gr√°ficos espaciales son √∫tiles para visualizar la distribuci√≥n geogr√°fica de una variable. Nos permiten identificar patrones, tendencias y relaciones espaciales en los datos. Entre las aplicaciones posibles encontramos la distribuci√≥n de la poblaci√≥n, la concentraci√≥n de la riqueza, la distribuci√≥n de la pobreza, entre otros.\n\nMapa de coropletas\nUn mapa de coropletas es una forma de visualizaci√≥n espacial que consiste en colorear √°reas geogr√°ficas de acuerdo a una variable de inter√©s. Es √∫til para visualizar la distribuci√≥n geogr√°fica de una variable y compararla entre diferentes √°reas. En el ejemplo abajo, se muestra la distribuci√≥n de los condados de Carolina del Norte seg√∫n su √°rea. Los condados m√°s grandes se muestran en tonos m√°s oscuros, mientras que los m√°s peque√±os aparecen m√°s claros.\n\n\nCode\n# Carga los paquetes\nlibrary(ggthemes)\nlibrary(ggplot2)\nlibrary(sf)\n\n# Carga los datos de\n# los condados de Carolina \n# del Norte\nnc &lt;- st_read(system.file(\"shape/nc.shp\", \n                          package = \"sf\"), \n              quiet = TRUE)\n\n# Crea el gr√°fico y lo colorea\n# seg√∫n el √°rea\ngg &lt;- ggplot(nc) +\n  geom_sf(aes(fill = AREA))\n  \n# Visualiza los resultados  \ngg"
  }
]